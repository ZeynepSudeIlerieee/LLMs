{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMVJIT92wFJ8rU/Vowndce7",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "97f4db8607d54f048476af8cceaf8199": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_3b9ec5dd94fe450f92b0bc6f0cb6e38c",
              "IPY_MODEL_7d2bb2503c5348dc92a7db60b255fa47",
              "IPY_MODEL_3806d59c24b34c01a9212f642bc2364e"
            ],
            "layout": "IPY_MODEL_077e678c11d5423681a64a6195e5344c"
          }
        },
        "3b9ec5dd94fe450f92b0bc6f0cb6e38c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d2ecdebb1add41c78f428d43cd0a8a35",
            "placeholder": "​",
            "style": "IPY_MODEL_7e4ee02b747f4a3f9429721a7bbdf063",
            "value": "tokenizer_config.json: 100%"
          }
        },
        "7d2bb2503c5348dc92a7db60b255fa47": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ea33c0c89dc44052ab1c02a55c69efbd",
            "max": 26,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_203f1e43712b4ca881e4ed788127ea87",
            "value": 26
          }
        },
        "3806d59c24b34c01a9212f642bc2364e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b256744e3e8d4f068b2177e24a829dc5",
            "placeholder": "​",
            "style": "IPY_MODEL_d8e53c9b378747bc8f7c6d6aaa3ccb8c",
            "value": " 26.0/26.0 [00:00&lt;00:00, 1.15kB/s]"
          }
        },
        "077e678c11d5423681a64a6195e5344c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d2ecdebb1add41c78f428d43cd0a8a35": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7e4ee02b747f4a3f9429721a7bbdf063": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "ea33c0c89dc44052ab1c02a55c69efbd": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "203f1e43712b4ca881e4ed788127ea87": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "b256744e3e8d4f068b2177e24a829dc5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d8e53c9b378747bc8f7c6d6aaa3ccb8c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "0c34e4eaa3644212ab6b978881ffbe76": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_826cd540cea849c6abb6c9d8deaaf972",
              "IPY_MODEL_51c5d389ac6745b99a5c2aafbb87d75c",
              "IPY_MODEL_b31624eed66f46858adc0e3f7ae166ff"
            ],
            "layout": "IPY_MODEL_c1aa003e19234bca8a3756784043f70d"
          }
        },
        "826cd540cea849c6abb6c9d8deaaf972": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6ba897ba58de441ebf7c1ea08eff2847",
            "placeholder": "​",
            "style": "IPY_MODEL_92bc8c54152e4eb2b2daa6c75d8494c5",
            "value": "vocab.json: 100%"
          }
        },
        "51c5d389ac6745b99a5c2aafbb87d75c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_005b968c2a664bbe850f802e0f3c2dc6",
            "max": 1042301,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_f7513437efb4410b8e2528d77187a03b",
            "value": 1042301
          }
        },
        "b31624eed66f46858adc0e3f7ae166ff": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2eb3618b2c88453a9d7d5af15103c041",
            "placeholder": "​",
            "style": "IPY_MODEL_11a880fd0ab241d9b57c56de7434c7ac",
            "value": " 1.04M/1.04M [00:00&lt;00:00, 11.3MB/s]"
          }
        },
        "c1aa003e19234bca8a3756784043f70d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6ba897ba58de441ebf7c1ea08eff2847": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "92bc8c54152e4eb2b2daa6c75d8494c5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "005b968c2a664bbe850f802e0f3c2dc6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f7513437efb4410b8e2528d77187a03b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "2eb3618b2c88453a9d7d5af15103c041": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "11a880fd0ab241d9b57c56de7434c7ac": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "17a1e7ea26e243d4a2df7f9430fe5704": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_c8475a300873406a8672a8d1544be6a5",
              "IPY_MODEL_a16b86e25b9d442486d02ad6b7536f22",
              "IPY_MODEL_f9f12eca72db48b889a923f1912cdfec"
            ],
            "layout": "IPY_MODEL_24505f14d81545dfb505baa880f93c7e"
          }
        },
        "c8475a300873406a8672a8d1544be6a5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9a79c946d5834934a50fd11ef606f517",
            "placeholder": "​",
            "style": "IPY_MODEL_c7a0e3d881154ebda3932217d6ed12c6",
            "value": "merges.txt: 100%"
          }
        },
        "a16b86e25b9d442486d02ad6b7536f22": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e3a4dee326b5435e97b60527b1b70399",
            "max": 456318,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_c580bc23f7b04914a08fd0f0209c1183",
            "value": 456318
          }
        },
        "f9f12eca72db48b889a923f1912cdfec": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_97eeca4b78164908a99a24bb7b09a642",
            "placeholder": "​",
            "style": "IPY_MODEL_374b8c952e0340c0a4d87df330e09b5b",
            "value": " 456k/456k [00:00&lt;00:00, 7.15MB/s]"
          }
        },
        "24505f14d81545dfb505baa880f93c7e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9a79c946d5834934a50fd11ef606f517": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c7a0e3d881154ebda3932217d6ed12c6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "e3a4dee326b5435e97b60527b1b70399": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c580bc23f7b04914a08fd0f0209c1183": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "97eeca4b78164908a99a24bb7b09a642": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "374b8c952e0340c0a4d87df330e09b5b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "02e1b944a3704bf492f9f800d016de73": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_b26ce0409d9f40fa8009b3b1792b8b4f",
              "IPY_MODEL_6b559ab698684ac7bfe400b0823ae105",
              "IPY_MODEL_ac7b0ab63fc140f5bbc0c340384e7066"
            ],
            "layout": "IPY_MODEL_cd9772351b1f40679ac5f28366b93444"
          }
        },
        "b26ce0409d9f40fa8009b3b1792b8b4f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_cb6976f276944361a7f59a9170f81864",
            "placeholder": "​",
            "style": "IPY_MODEL_c43e51853a784e70a8e1ab925c5f8795",
            "value": "tokenizer.json: 100%"
          }
        },
        "6b559ab698684ac7bfe400b0823ae105": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_79432f3cf975416bac41aab6aa682fa8",
            "max": 1355256,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_6e6f9d4c2c204c4881258e546368d870",
            "value": 1355256
          }
        },
        "ac7b0ab63fc140f5bbc0c340384e7066": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_fa580e05d1e048a189ec5da6bd991542",
            "placeholder": "​",
            "style": "IPY_MODEL_cd4767c74eab45d99168871fcc581e0d",
            "value": " 1.36M/1.36M [00:00&lt;00:00, 12.9MB/s]"
          }
        },
        "cd9772351b1f40679ac5f28366b93444": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "cb6976f276944361a7f59a9170f81864": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c43e51853a784e70a8e1ab925c5f8795": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "79432f3cf975416bac41aab6aa682fa8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6e6f9d4c2c204c4881258e546368d870": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "fa580e05d1e048a189ec5da6bd991542": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "cd4767c74eab45d99168871fcc581e0d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "dff27d7a93d6430f8b5b418c83b5f8d1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_d16b805b32aa47c1a3952f747c98848d",
              "IPY_MODEL_82a5c73977f442e5ad5b05742bec0e10",
              "IPY_MODEL_3782160397824e9eab0358968e692bc5"
            ],
            "layout": "IPY_MODEL_0a8b76664b97465f86609f1ce88d719d"
          }
        },
        "d16b805b32aa47c1a3952f747c98848d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6d6c72e6ae2d4fe18c18ad1d807d3648",
            "placeholder": "​",
            "style": "IPY_MODEL_7f7485deea9241988071ded72b187548",
            "value": "config.json: 100%"
          }
        },
        "82a5c73977f442e5ad5b05742bec0e10": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a2d2f8947a904d08a725cea81a8d7668",
            "max": 665,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_47c1128d47ad4b4ba81a8ef8ece7cf62",
            "value": 665
          }
        },
        "3782160397824e9eab0358968e692bc5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a8a742355e5d492fa3415a5b5b4b51af",
            "placeholder": "​",
            "style": "IPY_MODEL_55fadf53ba5246c1b9018cd958e38683",
            "value": " 665/665 [00:00&lt;00:00, 13.5kB/s]"
          }
        },
        "0a8b76664b97465f86609f1ce88d719d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6d6c72e6ae2d4fe18c18ad1d807d3648": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7f7485deea9241988071ded72b187548": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "a2d2f8947a904d08a725cea81a8d7668": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "47c1128d47ad4b4ba81a8ef8ece7cf62": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "a8a742355e5d492fa3415a5b5b4b51af": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "55fadf53ba5246c1b9018cd958e38683": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ZeynepSudeIlerieee/LLMs/blob/main/llmChapter_2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lEW9cfbhHnnA",
        "outputId": "0a482364-7dff-46de-8f29-89a404b0b17d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting tiktoken\n",
            "  Downloading tiktoken-0.9.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.7 kB)\n",
            "Requirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.11/dist-packages (from tiktoken) (2024.11.6)\n",
            "Requirement already satisfied: requests>=2.26.0 in /usr/local/lib/python3.11/dist-packages (from tiktoken) (2.32.3)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.26.0->tiktoken) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests>=2.26.0->tiktoken) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.26.0->tiktoken) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests>=2.26.0->tiktoken) (2025.1.31)\n",
            "Downloading tiktoken-0.9.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m11.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: tiktoken\n",
            "Successfully installed tiktoken-0.9.0\n",
            "torch version: 2.6.0+cu124\n",
            "tiktoken version: 0.9.0\n"
          ]
        }
      ],
      "source": [
        "!pip install tiktoken\n",
        "\n",
        "from importlib.metadata import version\n",
        "\n",
        "print(\"torch version:\", version(\"torch\"))\n",
        "print(\"tiktoken version:\", version(\"tiktoken\"))"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "zkP5E1F72LAz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import urllib.request\n",
        "\n",
        "if not os.path.exists(\"the-verdict.txt\"):\n",
        "    url = (\"https://raw.githubusercontent.com/rasbt/\"\n",
        "           \"LLMs-from-scratch/main/ch02/01_main-chapter-code/\"\n",
        "           \"the-verdict.txt\")\n",
        "    file_path = \"the-verdict.txt\"\n",
        "    urllib.request.urlretrieve(url, file_path)"
      ],
      "metadata": {
        "id": "l0c1A5MoIulI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "with open(\"the-verdict.txt\", \"r\", encoding=\"utf-8\") as f:\n",
        "    raw_text = f.read()\n",
        "\n",
        "print(\"Total number of character:\", len(raw_text))\n",
        "print(raw_text[:99])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2JMzzi25I5Tw",
        "outputId": "f74f9f9d-63f7-40bb-8e13-e763b5bef19f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total number of character: 20479\n",
            "I HAD always thought Jack Gisburn rather a cheap genius--though a good fellow enough--so it was no \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "\n",
        "text = \"Hello, world. This, is a test.\"\n",
        "result = re.split(r'(\\s)', text)\n",
        "\n",
        "print(result)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "znQM3zlHJDht",
        "outputId": "f107760d-3eed-4e12-f74e-33d5c9871a96"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['Hello,', ' ', 'world.', ' ', 'This,', ' ', 'is', ' ', 'a', ' ', 'test.']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "result = re.split(r'([,.]|\\s)', text)\n",
        "\n",
        "print(result)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gerWevkGJMSn",
        "outputId": "87101c96-b4c0-4584-d2de-a67eba49029b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['Hello', ',', '', ' ', 'world', '.', '', ' ', 'This', ',', '', ' ', 'is', ' ', 'a', ' ', 'test', '.', '']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Strip whitespace from each item and then filter out any empty strings.\n",
        "result = [item for item in result if item.strip()]\n",
        "print(result)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Vl6Q5WpIJQiC",
        "outputId": "ade5e0c6-58d2-4159-d373-33a74625c1c1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['Hello', ',', 'world', '.', 'This', ',', 'is', 'a', 'test', '.']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "text = \"Hello, world. Is this-- a test?\"\n",
        "\n",
        "result = re.split(r'([,.:;?_!\"()\\']|--|\\s)', text)\n",
        "result = [item.strip() for item in result if item.strip()]\n",
        "print(result)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HeAoRhqRJYQq",
        "outputId": "677d04fa-7a93-4f83-ac51-73adae7d9aa1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['Hello', ',', 'world', '.', 'Is', 'this', '--', 'a', 'test', '?']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "preprocessed = re.split(r'([,.:;?_!\"()\\']|--|\\s)', raw_text)\n",
        "preprocessed = [item.strip() for item in preprocessed if item.strip()]\n",
        "print(preprocessed[:30])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dHgt8UiOJd3v",
        "outputId": "1e723480-271e-4436-afde-7a2e07f054fd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['I', 'HAD', 'always', 'thought', 'Jack', 'Gisburn', 'rather', 'a', 'cheap', 'genius', '--', 'though', 'a', 'good', 'fellow', 'enough', '--', 'so', 'it', 'was', 'no', 'great', 'surprise', 'to', 'me', 'to', 'hear', 'that', ',', 'in']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(len(preprocessed))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "O6qSm0RmJlwl",
        "outputId": "011037e2-423c-4b08-fab9-91bbcbbb50cf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "4690\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "all_words = sorted(set(preprocessed))\n",
        "vocab_size = len(all_words)\n",
        "\n",
        "print(vocab_size)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Cqyi3yegJsav",
        "outputId": "26089906-44e9-4f8c-930f-d36e8b5e54bf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1130\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "vocab = {token:integer for integer,token in enumerate(all_words)}"
      ],
      "metadata": {
        "id": "MmO2W3YvJwC-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for i, item in enumerate(vocab.items()):\n",
        "    print(item)\n",
        "    if i >= 50:\n",
        "        break"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0IYoWCoYJ_Xx",
        "outputId": "48047cfa-e1c6-4c4a-fd74-f1a8538c451c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "('!', 0)\n",
            "('\"', 1)\n",
            "(\"'\", 2)\n",
            "('(', 3)\n",
            "(')', 4)\n",
            "(',', 5)\n",
            "('--', 6)\n",
            "('.', 7)\n",
            "(':', 8)\n",
            "(';', 9)\n",
            "('?', 10)\n",
            "('A', 11)\n",
            "('Ah', 12)\n",
            "('Among', 13)\n",
            "('And', 14)\n",
            "('Are', 15)\n",
            "('Arrt', 16)\n",
            "('As', 17)\n",
            "('At', 18)\n",
            "('Be', 19)\n",
            "('Begin', 20)\n",
            "('Burlington', 21)\n",
            "('But', 22)\n",
            "('By', 23)\n",
            "('Carlo', 24)\n",
            "('Chicago', 25)\n",
            "('Claude', 26)\n",
            "('Come', 27)\n",
            "('Croft', 28)\n",
            "('Destroyed', 29)\n",
            "('Devonshire', 30)\n",
            "('Don', 31)\n",
            "('Dubarry', 32)\n",
            "('Emperors', 33)\n",
            "('Florence', 34)\n",
            "('For', 35)\n",
            "('Gallery', 36)\n",
            "('Gideon', 37)\n",
            "('Gisburn', 38)\n",
            "('Gisburns', 39)\n",
            "('Grafton', 40)\n",
            "('Greek', 41)\n",
            "('Grindle', 42)\n",
            "('Grindles', 43)\n",
            "('HAD', 44)\n",
            "('Had', 45)\n",
            "('Hang', 46)\n",
            "('Has', 47)\n",
            "('He', 48)\n",
            "('Her', 49)\n",
            "('Hermia', 50)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class SimpleTokenizerV1:\n",
        "    def __init__(self, vocab):\n",
        "        self.str_to_int = vocab\n",
        "        self.int_to_str = {i:s for s,i in vocab.items()}\n",
        "\n",
        "    def encode(self, text):\n",
        "        preprocessed = re.split(r'([,.:;?_!\"()\\']|--|\\s)', text)\n",
        "\n",
        "        preprocessed = [\n",
        "            item.strip() for item in preprocessed if item.strip()\n",
        "        ]\n",
        "        ids = [self.str_to_int[s] for s in preprocessed]\n",
        "        return ids\n",
        "\n",
        "    def decode(self, ids):\n",
        "        text = \" \".join([self.int_to_str[i] for i in ids])\n",
        "        # Replace spaces before the specified punctuations\n",
        "        text = re.sub(r'\\s+([,.?!\"()\\'])', r'\\1', text)\n",
        "        return text"
      ],
      "metadata": {
        "id": "f_ly3L-FKDad"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer = SimpleTokenizerV1(vocab)\n",
        "\n",
        "text = \"\"\"\"It's the last he painted, you know,\"\n",
        "           Mrs. Gisburn said with pardonable pride.\"\"\"\n",
        "ids = tokenizer.encode(text)\n",
        "print(ids)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Zvmq3TpTKJEk",
        "outputId": "03f6fc12-38a6-4bd4-e014-a4b60ed02efa"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[1, 56, 2, 850, 988, 602, 533, 746, 5, 1126, 596, 5, 1, 67, 7, 38, 851, 1108, 754, 793, 7]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer.decode(ids)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "f_yw9BEsKQUx",
        "outputId": "fbf21383-1f21-4a6c-b358-f0d93f3fa35d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\" It\\' s the last he painted, you know,\" Mrs. Gisburn said with pardonable pride.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 106
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer.decode(tokenizer.encode(text))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "kJNX9hIxKYHx",
        "outputId": "aacd51eb-9082-4d89-8530-dfbe8a238f96"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\" It\\' s the last he painted, you know,\" Mrs. Gisburn said with pardonable pride.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 107
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer = SimpleTokenizerV1(vocab)\n",
        "\n",
        "text = \"Hello, do you like tea. Is this-- a test?\"\n",
        "\n",
        "tokenizer.encode(text)\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 338
        },
        "id": "8uMoYtHxKfTg",
        "outputId": "28ba7410-59d0-4b50-e754-361df68438d4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "KeyError",
          "evalue": "'Hello'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-110-9f0a6bbf4240>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mtext\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"Hello, do you like tea. Is this-- a test?\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mtokenizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-104-ba585d2f18cc>\u001b[0m in \u001b[0;36mencode\u001b[0;34m(self, text)\u001b[0m\n\u001b[1;32m     10\u001b[0m             \u001b[0mitem\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstrip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mitem\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpreprocessed\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mitem\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstrip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m         ]\n\u001b[0;32m---> 12\u001b[0;31m         \u001b[0mids\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstr_to_int\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0ms\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpreprocessed\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mids\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-104-ba585d2f18cc>\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     10\u001b[0m             \u001b[0mitem\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstrip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mitem\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpreprocessed\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mitem\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstrip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m         ]\n\u001b[0;32m---> 12\u001b[0;31m         \u001b[0mids\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstr_to_int\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0ms\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpreprocessed\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mids\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyError\u001b[0m: 'Hello'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "all_tokens = sorted(list(set(preprocessed)))\n",
        "all_tokens.extend([\"<|endoftext|>\", \"<|unk|>\"])\n",
        "\n",
        "vocab = {token:integer for integer,token in enumerate(all_tokens)}"
      ],
      "metadata": {
        "id": "V6Xwv1EIKlux"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(vocab.items())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dPRLVuuYKt5B",
        "outputId": "59922a88-ced3-4c47-e8f3-aed366ff726d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1132"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for i, item in enumerate(list(vocab.items())[-5:]):\n",
        "    print(item)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZsWlfDhmKwN5",
        "outputId": "efae9437-4fc1-44d9-a639-a1612274a698"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "('younger', 1127)\n",
            "('your', 1128)\n",
            "('yourself', 1129)\n",
            "('<|endoftext|>', 1130)\n",
            "('<|unk|>', 1131)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class SimpleTokenizerV2:\n",
        "    def __init__(self, vocab):\n",
        "        self.str_to_int = vocab\n",
        "        self.int_to_str = { i:s for s,i in vocab.items()}\n",
        "\n",
        "    def encode(self, text):\n",
        "        preprocessed = re.split(r'([,.:;?_!\"()\\']|--|\\s)', text)\n",
        "        preprocessed = [item.strip() for item in preprocessed if item.strip()]\n",
        "        preprocessed = [\n",
        "            item if item in self.str_to_int\n",
        "            else \"<|unk|>\" for item in preprocessed\n",
        "        ]\n",
        "\n",
        "        ids = [self.str_to_int[s] for s in preprocessed]\n",
        "        return ids\n",
        "\n",
        "    def decode(self, ids):\n",
        "        text = \" \".join([self.int_to_str[i] for i in ids])\n",
        "        # Replace spaces before the specified punctuations\n",
        "        text = re.sub(r'\\s+([,.:;?!\"()\\'])', r'\\1', text)\n",
        "        return text"
      ],
      "metadata": {
        "id": "fOohojR7KzEW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer = SimpleTokenizerV2(vocab)\n",
        "\n",
        "text1 = \"Hello, do you like tea?\"\n",
        "text2 = \"In the sunlit terraces of the palace.\"\n",
        "\n",
        "text = \" <|endoftext|> \".join((text1, text2))\n",
        "\n",
        "print(text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HWdqr22uK5wk",
        "outputId": "b0e312d1-8611-461e-8688-d39f15b7f1a3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Hello, do you like tea? <|endoftext|> In the sunlit terraces of the palace.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer.encode(text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-oukRvgFK9Y0",
        "outputId": "7b6807c3-8e19-4ebd-93f3-79fe383c86b3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[1131, 5, 355, 1126, 628, 975, 10, 1130, 55, 988, 956, 984, 722, 988, 1131, 7]"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer.decode(tokenizer.encode(text))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "hntBZ52TLAnF",
        "outputId": "82855dc7-1438-4d80-f756-62315152ae1c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'<|unk|>, do you like tea? <|endoftext|> In the sunlit terraces of the <|unk|>.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# pip install tiktoken\n",
        "import importlib\n",
        "import tiktoken\n",
        "\n",
        "print(\"tiktoken version:\", importlib.metadata.version(\"tiktoken\"))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-lLbuEu3LG-e",
        "outputId": "1f60bcbd-2039-4de2-c8b6-cad5825f282e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tiktoken version: 0.9.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer = tiktoken.get_encoding(\"gpt2\")"
      ],
      "metadata": {
        "id": "nWZyMZKwLSX8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "text = (\n",
        "    \"Hello, do you like tea? <|endoftext|> In the sunlit terraces\"\n",
        "     \"of someunknownPlace.\"\n",
        ")\n",
        "\n",
        "integers = tokenizer.encode(text, allowed_special={\"<|endoftext|>\"})\n",
        "\n",
        "print(integers)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uJDHFay-LTqh",
        "outputId": "05c7560b-8237-41a3-8594-663ba5d6729a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[15496, 11, 466, 345, 588, 8887, 30, 220, 50256, 554, 262, 4252, 18250, 8812, 2114, 1659, 617, 34680, 27271, 13]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "strings = tokenizer.decode(integers)\n",
        "\n",
        "print(strings)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OrOQg2M0LWk-",
        "outputId": "6e67e26d-dadf-4136-cfa4-f971eaf63c5c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Hello, do you like tea? <|endoftext|> In the sunlit terracesof someunknownPlace.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "with open(\"the-verdict.txt\", \"r\", encoding=\"utf-8\") as f:\n",
        "    raw_text = f.read()\n",
        "\n",
        "enc_text = tokenizer.encode(raw_text)\n",
        "print(len(enc_text))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2YeYeuUYLZa2",
        "outputId": "b465ee3f-953d-45ae-fdce-102aae791c2a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5145\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "enc_sample = enc_text[50:]"
      ],
      "metadata": {
        "id": "qr0TSGIbLgnc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "context_size = 4\n",
        "\n",
        "x = enc_sample[:context_size]\n",
        "y = enc_sample[1:context_size+1]\n",
        "\n",
        "print(f\"x: {x}\")\n",
        "print(f\"y:      {y}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sJ0e36YgLmA5",
        "outputId": "b6142600-5f5a-478c-ee46-789d0451eaa5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "x: [290, 4920, 2241, 287]\n",
            "y:      [4920, 2241, 287, 257]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for i in range(1, context_size+1):\n",
        "    context = enc_sample[:i]\n",
        "    desired = enc_sample[i]\n",
        "\n",
        "    print(context, \"---->\", desired)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "STALKM6XLtpm",
        "outputId": "c2c98f56-7b2e-461c-d19b-06ce9bcd725c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[290] ----> 4920\n",
            "[290, 4920] ----> 2241\n",
            "[290, 4920, 2241] ----> 287\n",
            "[290, 4920, 2241, 287] ----> 257\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for i in range(1, context_size+1):\n",
        "    context = enc_sample[:i]\n",
        "    desired = enc_sample[i]\n",
        "\n",
        "    print(tokenizer.decode(context), \"---->\", tokenizer.decode([desired]))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1hqgw6ABL1EZ",
        "outputId": "4507defd-6ce8-49a1-a601-1448f1590cd9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " and ---->  established\n",
            " and established ---->  himself\n",
            " and established himself ---->  in\n",
            " and established himself in ---->  a\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "print(\"PyTorch version:\", torch.__version__)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Gw-YULxqL2GQ",
        "outputId": "3eb8f17f-b3c7-451a-c3fd-f6af281d4fb9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "PyTorch version: 2.6.0+cu124\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.utils.data import Dataset, DataLoader\n",
        "\n",
        "\n",
        "class GPTDatasetV1(Dataset):\n",
        "    def __init__(self, txt, tokenizer, max_length, stride):\n",
        "        self.input_ids = []\n",
        "        self.target_ids = []\n",
        "\n",
        "        # Tokenize the entire text\n",
        "        token_ids = tokenizer.encode(txt, allowed_special={\"<|endoftext|>\"})\n",
        "\n",
        "        # Use a sliding window to chunk the book into overlapping sequences of max_length\n",
        "        for i in range(0, len(token_ids) - max_length, stride):\n",
        "            input_chunk = token_ids[i:i + max_length]\n",
        "            target_chunk = token_ids[i + 1: i + max_length + 1]\n",
        "            self.input_ids.append(torch.tensor(input_chunk))\n",
        "            self.target_ids.append(torch.tensor(target_chunk))\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.input_ids)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        return self.input_ids[idx], self.target_ids[idx]"
      ],
      "metadata": {
        "id": "76sCcIaoL5Wb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def create_dataloader_v1(txt, batch_size=4, max_length=256,\n",
        "                         stride=128, shuffle=True, drop_last=True,\n",
        "                         num_workers=0):\n",
        "\n",
        "    # Initialize the tokenizer\n",
        "    tokenizer = tiktoken.get_encoding(\"gpt2\")\n",
        "\n",
        "    # Create dataset\n",
        "    dataset = GPTDatasetV1(txt, tokenizer, max_length, stride)\n",
        "\n",
        "    # Create dataloader\n",
        "    dataloader = DataLoader(\n",
        "        dataset,\n",
        "        batch_size=batch_size,\n",
        "        shuffle=shuffle,\n",
        "        drop_last=drop_last,\n",
        "        num_workers=num_workers\n",
        "    )\n",
        "\n",
        "    return dataloader"
      ],
      "metadata": {
        "id": "BPgl0smjMGR9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "with open(\"the-verdict.txt\", \"r\", encoding=\"utf-8\") as f:\n",
        "    raw_text = f.read()"
      ],
      "metadata": {
        "id": "_Vm1EAq5MMHW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataloader = create_dataloader_v1(\n",
        "    raw_text, batch_size=1, max_length=4, stride=1, shuffle=False\n",
        ")\n",
        "\n",
        "data_iter = iter(dataloader)\n",
        "first_batch = next(data_iter)\n",
        "print(first_batch)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Kux_6aW4MQpx",
        "outputId": "2467b781-030c-4370-deb0-8dc58446e0a4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[tensor([[  40,  367, 2885, 1464]]), tensor([[ 367, 2885, 1464, 1807]])]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "second_batch = next(data_iter)\n",
        "print(second_batch)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "v6f9Pa5_MUTA",
        "outputId": "2b7b9ac9-ad56-4683-b67d-5a0ccaf303f0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[tensor([[ 367, 2885, 1464, 1807]]), tensor([[2885, 1464, 1807, 3619]])]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dataloader = create_dataloader_v1(raw_text, batch_size=8, max_length=4, stride=4, shuffle=False)\n",
        "\n",
        "data_iter = iter(dataloader)\n",
        "inputs, targets = next(data_iter)\n",
        "print(\"Inputs:\\n\", inputs)\n",
        "print(\"\\nTargets:\\n\", targets)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_-rkubNjMZ6G",
        "outputId": "a5a93b0d-7968-4a43-878c-77f2747c3675"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Inputs:\n",
            " tensor([[   40,   367,  2885,  1464],\n",
            "        [ 1807,  3619,   402,   271],\n",
            "        [10899,  2138,   257,  7026],\n",
            "        [15632,   438,  2016,   257],\n",
            "        [  922,  5891,  1576,   438],\n",
            "        [  568,   340,   373,   645],\n",
            "        [ 1049,  5975,   284,   502],\n",
            "        [  284,  3285,   326,    11]])\n",
            "\n",
            "Targets:\n",
            " tensor([[  367,  2885,  1464,  1807],\n",
            "        [ 3619,   402,   271, 10899],\n",
            "        [ 2138,   257,  7026, 15632],\n",
            "        [  438,  2016,   257,   922],\n",
            "        [ 5891,  1576,   438,   568],\n",
            "        [  340,   373,   645,  1049],\n",
            "        [ 5975,   284,   502,   284],\n",
            "        [ 3285,   326,    11,   287]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "input_ids = torch.tensor([2, 3, 5, 1])"
      ],
      "metadata": {
        "id": "xBEMSfj0McwY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "vocab_size = 6\n",
        "output_dim = 3\n",
        "\n",
        "torch.manual_seed(123)\n",
        "embedding_layer = torch.nn.Embedding(vocab_size, output_dim)"
      ],
      "metadata": {
        "id": "K4m-k35NMp33"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(embedding_layer.weight)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mDTpG0vaNEPf",
        "outputId": "5940f23f-7bf1-4865-aa43-854db1a61768"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Parameter containing:\n",
            "tensor([[ 0.3374, -0.1778, -0.1690],\n",
            "        [ 0.9178,  1.5810,  1.3010],\n",
            "        [ 1.2753, -0.2010, -0.1606],\n",
            "        [-0.4015,  0.9666, -1.1481],\n",
            "        [-1.1589,  0.3255, -0.6315],\n",
            "        [-2.8400, -0.7849, -1.4096]], requires_grad=True)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(embedding_layer(torch.tensor([3])))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0TrMWzMiNL0N",
        "outputId": "8b1368ea-3ede-4cbb-f5f0-96fe454ce32c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[-0.4015,  0.9666, -1.1481]], grad_fn=<EmbeddingBackward0>)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "vocab_size = 50257\n",
        "output_dim = 256\n",
        "\n",
        "token_embedding_layer = torch.nn.Embedding(vocab_size, output_dim)"
      ],
      "metadata": {
        "id": "2Sm106BYNfyz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "max_length = 4\n",
        "dataloader = create_dataloader_v1(\n",
        "    raw_text, batch_size=8, max_length=max_length,\n",
        "    stride=max_length, shuffle=False\n",
        ")\n",
        "data_iter = iter(dataloader)\n",
        "inputs, targets = next(data_iter)"
      ],
      "metadata": {
        "id": "jNfBDDghrRGl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Token IDs:\\n\", inputs)\n",
        "print(\"\\nInputs shape:\\n\", inputs.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UvxKRACfrUHj",
        "outputId": "abf3b43e-8cdd-4f64-ee16-129952833fd2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Token IDs:\n",
            " tensor([[   40,   367,  2885,  1464],\n",
            "        [ 1807,  3619,   402,   271],\n",
            "        [10899,  2138,   257,  7026],\n",
            "        [15632,   438,  2016,   257],\n",
            "        [  922,  5891,  1576,   438],\n",
            "        [  568,   340,   373,   645],\n",
            "        [ 1049,  5975,   284,   502],\n",
            "        [  284,  3285,   326,    11]])\n",
            "\n",
            "Inputs shape:\n",
            " torch.Size([8, 4])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "6EEynaarrkmr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "token_embeddings = token_embedding_layer(inputs)\n",
        "print(token_embeddings.shape)\n",
        "\n",
        "# uncomment & execute the following line to see how the embeddings look like\n",
        "# print(token_embeddings)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uCeETmkXrVWl",
        "outputId": "c7b9282a-e67f-4e98-fdb5-c2322d816f9a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([8, 4, 256])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "context_length = max_length\n",
        "pos_embedding_layer = torch.nn.Embedding(context_length, output_dim)\n",
        "\n",
        "# uncomment & execute the following line to see how the embedding layer weights look like\n",
        "# print(pos_embedding_layer.weight)"
      ],
      "metadata": {
        "id": "medo4BAlrZ-S"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pos_embeddings = pos_embedding_layer(torch.arange(max_length))\n",
        "print(pos_embeddings.shape)\n",
        "\n",
        "# uncomment & execute the following line to see how the embeddings look like\n",
        "# print(pos_embeddings)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KhlBLTMsrozK",
        "outputId": "0c3c8b86-3879-4782-b561-f341104c7b52"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([4, 256])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "input_embeddings = token_embeddings + pos_embeddings\n",
        "print(input_embeddings.shape)\n",
        "\n",
        "# uncomment & execute the following line to see how the embeddings look like\n",
        "# print(input_embeddings)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gl_w4chvrut4",
        "outputId": "8b8dc1bf-9a6e-4379-a5b0-2f7277b088c4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([8, 4, 256])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# NBVAL_SKIP\n",
        "from importlib.metadata import version\n",
        "\n",
        "print(\"torch version:\", version(\"torch\"))\n",
        "print(\"tiktoken version:\", version(\"tiktoken\"))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1gYLmeVmryCC",
        "outputId": "c422b677-0993-4a5a-b1fc-221ae1ee32b3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch version: 2.6.0+cu124\n",
            "tiktoken version: 0.9.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tiktoken\n",
        "import torch\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "\n",
        "\n",
        "class GPTDatasetV1(Dataset):\n",
        "    def __init__(self, txt, tokenizer, max_length, stride):\n",
        "        self.input_ids = []\n",
        "        self.target_ids = []\n",
        "\n",
        "        # Tokenize the entire text\n",
        "        token_ids = tokenizer.encode(txt, allowed_special={\"<|endoftext|>\"})\n",
        "\n",
        "        # Use a sliding window to chunk the book into overlapping sequences of max_length\n",
        "        for i in range(0, len(token_ids) - max_length, stride):\n",
        "            input_chunk = token_ids[i:i + max_length]\n",
        "            target_chunk = token_ids[i + 1: i + max_length + 1]\n",
        "            self.input_ids.append(torch.tensor(input_chunk))\n",
        "            self.target_ids.append(torch.tensor(target_chunk))\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.input_ids)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        return self.input_ids[idx], self.target_ids[idx]\n",
        "\n",
        "\n",
        "def create_dataloader_v1(txt, batch_size, max_length, stride,\n",
        "                         shuffle=True, drop_last=True, num_workers=0):\n",
        "    # Initialize the tokenizer\n",
        "    tokenizer = tiktoken.get_encoding(\"gpt2\")\n",
        "\n",
        "    # Create dataset\n",
        "    dataset = GPTDatasetV1(txt, tokenizer, max_length, stride)\n",
        "\n",
        "    # Create dataloader\n",
        "    dataloader = DataLoader(\n",
        "        dataset, batch_size=batch_size, shuffle=shuffle, drop_last=drop_last, num_workers=num_workers)\n",
        "\n",
        "    return dataloader\n",
        "\n",
        "\n",
        "with open(\"the-verdict.txt\", \"r\", encoding=\"utf-8\") as f:\n",
        "    raw_text = f.read()\n",
        "\n",
        "vocab_size = 50257\n",
        "output_dim = 256\n",
        "context_length = 1024\n",
        "\n",
        "\n",
        "token_embedding_layer = torch.nn.Embedding(vocab_size, output_dim)\n",
        "pos_embedding_layer = torch.nn.Embedding(context_length, output_dim)\n",
        "\n",
        "batch_size = 8\n",
        "max_length = 4\n",
        "dataloader = create_dataloader_v1(\n",
        "    raw_text,\n",
        "    batch_size=batch_size,\n",
        "    max_length=max_length,\n",
        "    stride=max_length\n",
        ")"
      ],
      "metadata": {
        "id": "6yWTwT8Lr_nl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for batch in dataloader:\n",
        "    x, y = batch\n",
        "\n",
        "    token_embeddings = token_embedding_layer(x)\n",
        "    pos_embeddings = pos_embedding_layer(torch.arange(max_length))\n",
        "\n",
        "    input_embeddings = token_embeddings + pos_embeddings\n",
        "\n",
        "    break"
      ],
      "metadata": {
        "id": "pnflBPR2sGTI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(input_embeddings.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gCEkqeZ0sJwB",
        "outputId": "be3369de-8ecc-44e0-8b7b-36d097e9952e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([8, 4, 256])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "Chapter 2 Exercise solutions\n"
      ],
      "metadata": {
        "id": "uAgiDeR22NMw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from importlib.metadata import version\n",
        "\n",
        "print(\"torch version:\", version(\"torch\"))\n",
        "print(\"tiktoken version:\", version(\"tiktoken\"))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z4TjnAoK2TOz",
        "outputId": "d92968e5-6db9-4a0f-fff3-fed31b1552a6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch version: 2.6.0+cu124\n",
            "tiktoken version: 0.9.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tiktoken\n",
        "\n",
        "tokenizer = tiktoken.get_encoding(\"gpt2\")"
      ],
      "metadata": {
        "id": "6aTUEoJ028wj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "integers = tokenizer.encode(\"Akwirw ier\")\n",
        "print(integers)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XcbZZCZm3HYr",
        "outputId": "4227593b-5390-4f3b-e09b-f004d6d167e1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[33901, 86, 343, 86, 220, 959]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for i in integers:\n",
        "    print(f\"{i} -> {tokenizer.decode([i])}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uXa5hcG_3NVf",
        "outputId": "ec4325a0-b51c-4e78-8b3e-e4ca26de829f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "33901 -> Ak\n",
            "86 -> w\n",
            "343 -> ir\n",
            "86 -> w\n",
            "220 ->  \n",
            "959 -> ier\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer.encode(\"Ak\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BfFSP-7q3QV0",
        "outputId": "e2e25d8d-cc79-46a3-a730-cca9b74d8018"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[33901]"
            ]
          },
          "metadata": {},
          "execution_count": 65
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer.encode(\"w\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uvnyFSVY3THn",
        "outputId": "398206b2-962c-4780-e44f-09306210d605"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[86]"
            ]
          },
          "metadata": {},
          "execution_count": 66
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer.encode(\"ir\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "g19lJQcZ3XuI",
        "outputId": "68bbb36d-3c80-40f3-f9f8-7c81748c0fdb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[343]"
            ]
          },
          "metadata": {},
          "execution_count": 67
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer.encode(\"w\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cqrIG0tW3cX-",
        "outputId": "6c89a159-f29e-4d38-886f-fc3b6b02aaa6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[86]"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "tokenizer.encode(\" \")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UgOK4NHT3e3G",
        "outputId": "410fe34b-04d9-4eb5-cfb6-a78c45eba046"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[220]"
            ]
          },
          "metadata": {},
          "execution_count": 68
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer.encode(\"ier\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l6CNqbcq3jWy",
        "outputId": "a91d097f-b48e-4c95-ecda-178d7abe0c49"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[959]"
            ]
          },
          "metadata": {},
          "execution_count": 69
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer.decode([33901, 86, 343, 86, 220, 959])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "fxQ78n3W3mg2",
        "outputId": "6bcb5913-32a9-466c-81c5-f0d734892750"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Akwirw ier'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Exercise 2.2"
      ],
      "metadata": {
        "id": "Z8x20aN_3sa4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tiktoken\n",
        "import torch\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "\n",
        "\n",
        "class GPTDatasetV1(Dataset):\n",
        "    def __init__(self, txt, tokenizer, max_length, stride):\n",
        "        self.input_ids = []\n",
        "        self.target_ids = []\n",
        "\n",
        "        # Tokenize the entire text\n",
        "        token_ids = tokenizer.encode(txt, allowed_special={\"<|endoftext|>\"})\n",
        "\n",
        "        # Use a sliding window to chunk the book into overlapping sequences of max_length\n",
        "        for i in range(0, len(token_ids) - max_length, stride):\n",
        "            input_chunk = token_ids[i:i + max_length]\n",
        "            target_chunk = token_ids[i + 1: i + max_length + 1]\n",
        "            self.input_ids.append(torch.tensor(input_chunk))\n",
        "            self.target_ids.append(torch.tensor(target_chunk))\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.input_ids)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        return self.input_ids[idx], self.target_ids[idx]\n",
        "\n",
        "\n",
        "def create_dataloader(txt, batch_size=4, max_length=256, stride=128):\n",
        "    # Initialize the tokenizer\n",
        "    tokenizer = tiktoken.get_encoding(\"gpt2\")\n",
        "\n",
        "    # Create dataset\n",
        "    dataset = GPTDatasetV1(txt, tokenizer, max_length, stride)\n",
        "\n",
        "    # Create dataloader\n",
        "    dataloader = DataLoader(dataset, batch_size=batch_size)\n",
        "\n",
        "    return dataloader\n",
        "\n",
        "\n",
        "with open(\"the-verdict.txt\", \"r\", encoding=\"utf-8\") as f:\n",
        "    raw_text = f.read()\n",
        "\n",
        "tokenizer = tiktoken.get_encoding(\"gpt2\")\n",
        "encoded_text = tokenizer.encode(raw_text)\n",
        "\n",
        "vocab_size = 50257\n",
        "output_dim = 256\n",
        "max_len = 4\n",
        "context_length = max_len\n",
        "\n",
        "token_embedding_layer = torch.nn.Embedding(context_length, output_dim)\n",
        "pos_embedding_layer = torch.nn.Embedding(vocab_size, output_dim)"
      ],
      "metadata": {
        "id": "ILr0jr_p3tHq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataloader = create_dataloader(raw_text, batch_size=4, max_length=2, stride=2)\n",
        "\n",
        "for batch in dataloader:\n",
        "    x, y = batch\n",
        "    break\n",
        "\n",
        "x"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gDy_R1Sf4a26",
        "outputId": "4fc91653-9b30-40d2-9bd9-8fbf2b7c3519"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[  40,  367],\n",
              "        [2885, 1464],\n",
              "        [1807, 3619],\n",
              "        [ 402,  271]])"
            ]
          },
          "metadata": {},
          "execution_count": 72
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dataloader = create_dataloader(raw_text, batch_size=4, max_length=8, stride=2)\n",
        "\n",
        "for batch in dataloader:\n",
        "    x, y = batch\n",
        "    break\n",
        "\n",
        "x"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Jpa-I3cS4dbc",
        "outputId": "a9540332-f9ba-4e87-8ca1-ef5ca21b2db0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[   40,   367,  2885,  1464,  1807,  3619,   402,   271],\n",
              "        [ 2885,  1464,  1807,  3619,   402,   271, 10899,  2138],\n",
              "        [ 1807,  3619,   402,   271, 10899,  2138,   257,  7026],\n",
              "        [  402,   271, 10899,  2138,   257,  7026, 15632,   438]])"
            ]
          },
          "metadata": {},
          "execution_count": 73
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Comparing Various Byte Pair Encoding (BPE) Implementations"
      ],
      "metadata": {
        "id": "DsSHTWGG98WR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from importlib.metadata import version\n",
        "\n",
        "print(\"tiktoken version:\", version(\"tiktoken\"))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-5Q6MRPw99J9",
        "outputId": "6d12d5ca-4006-4c0e-ad2d-0bde7ae4b6b2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tiktoken version: 0.9.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tiktoken\n",
        "\n",
        "tik_tokenizer = tiktoken.get_encoding(\"gpt2\")\n",
        "\n",
        "text = \"Hello, world. Is this-- a test?\""
      ],
      "metadata": {
        "id": "wApiV9Hw-Bz-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "integers = tik_tokenizer.encode(text, allowed_special={\"<|endoftext|>\"})\n",
        "\n",
        "print(integers)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AYf4q4lo-FFL",
        "outputId": "dfcbf48d-77ca-440d-d9a1-3c0d81df81f3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[15496, 11, 995, 13, 1148, 428, 438, 257, 1332, 30]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "strings = tik_tokenizer.decode(integers)\n",
        "\n",
        "print(strings)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "abqJPxWY-SwK",
        "outputId": "6ffdf52a-fbd2-47a9-e9d5-ec2f94318023"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Hello, world. Is this-- a test?\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(tik_tokenizer.n_vocab)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mjaksWWo-rbp",
        "outputId": "da521450-0c16-453b-8449-ec1343e1eeae"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "50257\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install tiktoken\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0gkHupKA-0Wi",
        "outputId": "c7901cef-9e61-4fe4-bbee-76aae6436ac7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: tiktoken in /usr/local/lib/python3.11/dist-packages (0.9.0)\n",
            "Requirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.11/dist-packages (from tiktoken) (2024.11.6)\n",
            "Requirement already satisfied: requests>=2.26.0 in /usr/local/lib/python3.11/dist-packages (from tiktoken) (2.32.3)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.26.0->tiktoken) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests>=2.26.0->tiktoken) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.26.0->tiktoken) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests>=2.26.0->tiktoken) (2025.1.31)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tiktoken\n",
        "\n",
        "encoder = tiktoken.get_encoding(\"gpt2\")\n",
        "\n",
        "text = \"Merhaba dünya!\"\n",
        "encoded = encoder.encode(text)\n",
        "decoded = encoder.decode(encoded)\n",
        "\n",
        "print(\"Encoded:\", encoded)\n",
        "print(\"Decoded:\", decoded)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WMtg44Sn_3Nh",
        "outputId": "408c1251-1e20-4a6d-bc37-1f47e535ff93"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Encoded: [13102, 5976, 64, 288, 9116, 3281, 64, 0]\n",
            "Decoded: Merhaba dünya!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import sys\n",
        "print(sys.path)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ugeG3Y1gAmgh",
        "outputId": "a539b199-483f-4a8a-c98e-ec4301127308"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['/content', '/env/python', '/usr/lib/python311.zip', '/usr/lib/python3.11', '/usr/lib/python3.11/lib-dynload', '', '/usr/local/lib/python3.11/dist-packages', '/usr/lib/python3/dist-packages', '/usr/local/lib/python3.11/dist-packages/IPython/extensions', '/root/.ipython']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip list | grep bpe_openai_gpt2\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "CVOaPks3Armf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install tiktoken\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HKSsPEDzBECi",
        "outputId": "7252c6b6-e05c-4fea-f523-a9d1244f27b6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: tiktoken in /usr/local/lib/python3.11/dist-packages (0.9.0)\n",
            "Requirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.11/dist-packages (from tiktoken) (2024.11.6)\n",
            "Requirement already satisfied: requests>=2.26.0 in /usr/local/lib/python3.11/dist-packages (from tiktoken) (2.32.3)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.26.0->tiktoken) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests>=2.26.0->tiktoken) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.26.0->tiktoken) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests>=2.26.0->tiktoken) (2025.1.31)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tiktoken\n",
        "\n",
        "encoder = tiktoken.get_encoding(\"gpt2\")\n",
        "text = \"Merhaba dünya!\"\n",
        "encoded = encoder.encode(text)\n",
        "decoded = encoder.decode(encoded)\n",
        "\n",
        "print(\"Encoded:\", encoded)\n",
        "print(\"Decoded:\", decoded)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PVjvcaJ2BQPI",
        "outputId": "9982ee3f-e639-4179-a123-0a39b1ae3cfa"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Encoded: [13102, 5976, 64, 288, 9116, 3281, 64, 0]\n",
            "Decoded: Merhaba dünya!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from bpe_openai_gpt2 import get_encoder, download_vocab"
      ],
      "metadata": {
        "id": "Toc7PdYPGAoK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "download_vocab()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9BFzxqwaGHTB",
        "outputId": "026b4b9c-1735-4881-c1b9-9a2f1ed73835"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Fetching encoder.json: 1.04Mit [00:00, 2.42Mit/s]                                                   \n",
            "Fetching vocab.bpe: 457kit [00:00, 1.65Mit/s]                                                       \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "orig_tokenizer = get_encoder(model_name=\"gpt2_model\", models_dir=\".\")"
      ],
      "metadata": {
        "id": "KbmzIbIBGOqf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "integers = orig_tokenizer.encode(text)\n",
        "\n",
        "print(integers)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0uwfJXoNGSx1",
        "outputId": "a5347c5d-ef29-477e-bef0-f2aff85c1b5b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[13102, 5976, 64, 288, 9116, 3281, 64, 0]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "strings = orig_tokenizer.decode(integers)\n",
        "\n",
        "print(strings)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N1qkBBVqGVPL",
        "outputId": "868f171a-0a0c-4eb4-8468-d784af1b59cc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Merhaba dünya!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Using the BPE via Hugging Face transformers"
      ],
      "metadata": {
        "id": "RUXNJSBkIwHn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import transformers\n",
        "\n",
        "transformers.__version__"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "mTmcqdXCGaR-",
        "outputId": "a80c78e1-c970-4df8-b0e6-e12fa971ca93"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'4.48.3'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 90
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import GPT2Tokenizer\n",
        "\n",
        "hf_tokenizer = GPT2Tokenizer.from_pretrained(\"gpt2\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 301,
          "referenced_widgets": [
            "97f4db8607d54f048476af8cceaf8199",
            "3b9ec5dd94fe450f92b0bc6f0cb6e38c",
            "7d2bb2503c5348dc92a7db60b255fa47",
            "3806d59c24b34c01a9212f642bc2364e",
            "077e678c11d5423681a64a6195e5344c",
            "d2ecdebb1add41c78f428d43cd0a8a35",
            "7e4ee02b747f4a3f9429721a7bbdf063",
            "ea33c0c89dc44052ab1c02a55c69efbd",
            "203f1e43712b4ca881e4ed788127ea87",
            "b256744e3e8d4f068b2177e24a829dc5",
            "d8e53c9b378747bc8f7c6d6aaa3ccb8c",
            "0c34e4eaa3644212ab6b978881ffbe76",
            "826cd540cea849c6abb6c9d8deaaf972",
            "51c5d389ac6745b99a5c2aafbb87d75c",
            "b31624eed66f46858adc0e3f7ae166ff",
            "c1aa003e19234bca8a3756784043f70d",
            "6ba897ba58de441ebf7c1ea08eff2847",
            "92bc8c54152e4eb2b2daa6c75d8494c5",
            "005b968c2a664bbe850f802e0f3c2dc6",
            "f7513437efb4410b8e2528d77187a03b",
            "2eb3618b2c88453a9d7d5af15103c041",
            "11a880fd0ab241d9b57c56de7434c7ac",
            "17a1e7ea26e243d4a2df7f9430fe5704",
            "c8475a300873406a8672a8d1544be6a5",
            "a16b86e25b9d442486d02ad6b7536f22",
            "f9f12eca72db48b889a923f1912cdfec",
            "24505f14d81545dfb505baa880f93c7e",
            "9a79c946d5834934a50fd11ef606f517",
            "c7a0e3d881154ebda3932217d6ed12c6",
            "e3a4dee326b5435e97b60527b1b70399",
            "c580bc23f7b04914a08fd0f0209c1183",
            "97eeca4b78164908a99a24bb7b09a642",
            "374b8c952e0340c0a4d87df330e09b5b",
            "02e1b944a3704bf492f9f800d016de73",
            "b26ce0409d9f40fa8009b3b1792b8b4f",
            "6b559ab698684ac7bfe400b0823ae105",
            "ac7b0ab63fc140f5bbc0c340384e7066",
            "cd9772351b1f40679ac5f28366b93444",
            "cb6976f276944361a7f59a9170f81864",
            "c43e51853a784e70a8e1ab925c5f8795",
            "79432f3cf975416bac41aab6aa682fa8",
            "6e6f9d4c2c204c4881258e546368d870",
            "fa580e05d1e048a189ec5da6bd991542",
            "cd4767c74eab45d99168871fcc581e0d",
            "dff27d7a93d6430f8b5b418c83b5f8d1",
            "d16b805b32aa47c1a3952f747c98848d",
            "82a5c73977f442e5ad5b05742bec0e10",
            "3782160397824e9eab0358968e692bc5",
            "0a8b76664b97465f86609f1ce88d719d",
            "6d6c72e6ae2d4fe18c18ad1d807d3648",
            "7f7485deea9241988071ded72b187548",
            "a2d2f8947a904d08a725cea81a8d7668",
            "47c1128d47ad4b4ba81a8ef8ece7cf62",
            "a8a742355e5d492fa3415a5b5b4b51af",
            "55fadf53ba5246c1b9018cd958e38683"
          ]
        },
        "id": "SrlWgWP-IMYU",
        "outputId": "b8a188f0-8a48-42bd-f87c-5f6ec4cfcaa5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer_config.json:   0%|          | 0.00/26.0 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "97f4db8607d54f048476af8cceaf8199"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "vocab.json:   0%|          | 0.00/1.04M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "0c34e4eaa3644212ab6b978881ffbe76"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "merges.txt:   0%|          | 0.00/456k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "17a1e7ea26e243d4a2df7f9430fe5704"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer.json:   0%|          | 0.00/1.36M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "02e1b944a3704bf492f9f800d016de73"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "config.json:   0%|          | 0.00/665 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "dff27d7a93d6430f8b5b418c83b5f8d1"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "hf_tokenizer(strings)[\"input_ids\"]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9G_9C6mQINqQ",
        "outputId": "bf83af0e-e658-4e0d-df8c-657928d2a22b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[13102, 5976, 64, 288, 9116, 3281, 64, 0]"
            ]
          },
          "metadata": {},
          "execution_count": 92
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import GPT2TokenizerFast\n",
        "\n",
        "hf_tokenizer_fast = GPT2TokenizerFast.from_pretrained(\"gpt2\")"
      ],
      "metadata": {
        "id": "D3rLQh_sIQyb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "hf_tokenizer_fast(strings)[\"input_ids\"]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B61BVrrrIYJ4",
        "outputId": "749ffe3d-9b13-4acc-da24-b0c62c8d14e6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[13102, 5976, 64, 288, 9116, 3281, 64, 0]"
            ]
          },
          "metadata": {},
          "execution_count": 94
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Using my own from-scratch BPE tokenizer"
      ],
      "metadata": {
        "id": "LN-OQIXAJFVu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import sys\n",
        "import io\n",
        "import nbformat\n",
        "import types\n",
        "\n",
        "def import_from_notebook():\n",
        "    def import_definitions_from_notebook(fullname, names):\n",
        "        current_dir = os.getcwd()\n",
        "        path = os.path.join(current_dir, \"bpe-from-scratch.ipynb\")\n",
        "        path = os.path.normpath(path)\n",
        "\n",
        "        # Load the notebook\n",
        "        if not os.path.exists(path):\n",
        "            raise FileNotFoundError(f\"Notebook file not found at: {path}\")\n",
        "\n",
        "        with io.open(path, \"r\", encoding=\"utf-8\") as f:\n",
        "            nb = nbformat.read(f, as_version=4)\n",
        "\n",
        "        # Create a module to store the imported functions and classes\n",
        "        mod = types.ModuleType(fullname)\n",
        "        sys.modules[fullname] = mod\n",
        "\n",
        "        # Go through the notebook cells and only execute function or class definitions\n",
        "        for cell in nb.cells:\n",
        "            if cell.cell_type == \"code\":\n",
        "                cell_code = cell.source\n",
        "                for name in names:\n",
        "                    # Check for function or class definitions\n",
        "                    if f\"def {name}\" in cell_code or f\"class {name}\" in cell_code:\n",
        "                        exec(cell_code, mod.__dict__)\n",
        "        return mod\n",
        "\n",
        "    fullname = \"bpe-from-scratch\"\n",
        "    names = [\"BPETokenizerSimple\"]\n",
        "\n",
        "    return import_definitions_from_notebook(fullname, names)"
      ],
      "metadata": {
        "id": "Iso2LCI_d3h4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "imported_module = import_from_notebook()\n",
        "BPETokenizerSimple = getattr(imported_module, \"BPETokenizerSimple\", None)\n",
        "\n",
        "tokenizer_gpt2 = BPETokenizerSimple()\n",
        "tokenizer_gpt2.load_vocab_and_merges_from_openai(\n",
        "    vocab_path=os.path.join(\"gpt2_model\", \"encoder.json\"),\n",
        "    bpe_merges_path=os.path.join(\"gpt2_model\", \"vocab.bpe\")\n",
        ")"
      ],
      "metadata": {
        "id": "kgsDmzibd32y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "integers = tokenizer_gpt2.encode(text)\n",
        "\n",
        "print(integers)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tMceZkyoeEiJ",
        "outputId": "3896ae5c-5096-4fb0-f89f-cf7e39b46d0c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[15496, 11, 466, 345, 588, 8887, 13, 1148, 428, 438, 257, 1332, 30]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "A quick performance benchmark"
      ],
      "metadata": {
        "id": "86w6BgfheIm_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "with open(\"the-verdict.txt\", \"r\", encoding=\"utf-8\") as f:\n",
        "    raw_text = f.read()"
      ],
      "metadata": {
        "id": "Ma0AlbhOeM_0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Original OpenAI GPT-2 tokenizer"
      ],
      "metadata": {
        "id": "WlmYxl2Le_K5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%timeit orig_tokenizer.encode(raw_text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s7ZE96WXe_xP",
        "outputId": "0e44b96a-6b5c-4cca-9037-c918a7c86e48"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "22.7 ms ± 783 µs per loop (mean ± std. dev. of 7 runs, 10 loops each)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Tiktoken OpenAI GPT-2 tokenizer"
      ],
      "metadata": {
        "id": "ujZ14189fDBR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%timeit tik_tokenizer.encode(raw_text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yUKCZu3dfGVw",
        "outputId": "9ec82bde-dc44-4e79-c085-56d9e0a83f14"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5.87 ms ± 1.49 ms per loop (mean ± std. dev. of 7 runs, 100 loops each)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Hugging Face OpenAI GPT-2 tokenizer"
      ],
      "metadata": {
        "id": "wQ_g6-44fJww"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%timeit hf_tokenizer(raw_text)[\"input_ids\"]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r4XywAzZfMiD",
        "outputId": "400f0448-c052-4067-db73-b7b8ffa13d10"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Token indices sequence length is longer than the specified maximum sequence length for this model (5145 > 1024). Running this sequence through the model will result in indexing errors\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "69.3 ms ± 11 ms per loop (mean ± std. dev. of 7 runs, 10 loops each)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%timeit hf_tokenizer(raw_text, max_length=5145, truncation=True)[\"input_ids\"]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rut6iSNDfRI0",
        "outputId": "15ef5a89-a2ce-4250-c945-60dbfbb39070"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "63.1 ms ± 1.29 ms per loop (mean ± std. dev. of 7 runs, 10 loops each)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%timeit hf_tokenizer_fast(raw_text)[\"input_ids\"]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vu7r6uLnfT5Q",
        "outputId": "3e8c2e87-b26c-42a1-82a6-cd39f2deb7da"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Token indices sequence length is longer than the specified maximum sequence length for this model (5145 > 1024). Running this sequence through the model will result in indexing errors\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "30.4 ms ± 1.27 ms per loop (mean ± std. dev. of 7 runs, 10 loops each)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%timeit hf_tokenizer_fast(raw_text, max_length=5145, truncation=True)[\"input_ids\"]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_0wuT7B9fYyM",
        "outputId": "ee0ebc0f-de91-406a-f8bc-c1b3ad564c16"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "30.5 ms ± 1.26 ms per loop (mean ± std. dev. of 7 runs, 10 loops each)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "My own GPT-2 tokenizer (for educational purposes)"
      ],
      "metadata": {
        "id": "-llm9ZBLfc4O"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%timeit tokenizer_gpt2.encode(raw_text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l4sQvrN_fdhH",
        "outputId": "59650b15-fd4b-4522-c1f5-4c4c53db98f8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "51.8 ms ± 2.59 ms per loop (mean ± std. dev. of 7 runs, 10 loops each)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Data sampling with a sliding window with number data"
      ],
      "metadata": {
        "id": "x_PmBtY1f0L7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from importlib.metadata import version\n",
        "import torch\n",
        "\n",
        "print(\"torch version:\", version(\"torch\"))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MsUiwx4xf05c",
        "outputId": "18f86f6b-497e-4eee-919b-a32b1bda8222"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch version: 2.6.0+cu124\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "with open(\"number-data.txt\", \"w\", encoding=\"utf-8\") as f:\n",
        "    for number in range(1001):\n",
        "        f.write(f\"{number} \")"
      ],
      "metadata": {
        "id": "fHGCkuRNf3Y2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.utils.data import Dataset, DataLoader\n",
        "\n",
        "\n",
        "class GPTDatasetV1(Dataset):\n",
        "    def __init__(self, txt, tokenizer, max_length, stride):\n",
        "        self.input_ids = []\n",
        "        self.target_ids = []\n",
        "\n",
        "        # Modification\n",
        "        # token_ids = tokenizer.encode(txt, allowed_special={\"<|endoftext|>\"})\n",
        "        token_ids = [int(i) for i in txt.strip().split()]\n",
        "\n",
        "        # Use a sliding window to chunk the book into overlapping sequences of max_length\n",
        "        for i in range(0, len(token_ids) - max_length, stride):\n",
        "            input_chunk = token_ids[i:i + max_length]\n",
        "            target_chunk = token_ids[i + 1: i + max_length + 1]\n",
        "            self.input_ids.append(torch.tensor(input_chunk))\n",
        "            self.target_ids.append(torch.tensor(target_chunk))\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.input_ids)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        return self.input_ids[idx], self.target_ids[idx]"
      ],
      "metadata": {
        "id": "wrANRLTCgAOL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def create_dataloader_v1(txt, batch_size=4, max_length=256, stride=128, shuffle=True, drop_last=True, num_workers=0):\n",
        "\n",
        "    # Initialize the tokenizer\n",
        "    # tokenizer = tiktoken.get_encoding(\"gpt2\")\n",
        "    tokenizer = None\n",
        "\n",
        "    # Create dataset\n",
        "    dataset = GPTDatasetV1(txt, tokenizer, max_length, stride)\n",
        "\n",
        "    # Create dataloader\n",
        "    dataloader = DataLoader(\n",
        "        dataset,\n",
        "        batch_size=batch_size,\n",
        "        shuffle=shuffle,\n",
        "        drop_last=drop_last,\n",
        "        num_workers=num_workers\n",
        "    )\n",
        "\n",
        "    return dataloader"
      ],
      "metadata": {
        "id": "iD09bMHkgBcf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "with open(\"number-data.txt\", \"r\", encoding=\"utf-8\") as f:\n",
        "    raw_text = f.read()"
      ],
      "metadata": {
        "id": "rXEhlqiWgEWi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataloader = create_dataloader_v1(raw_text, batch_size=1, max_length=4, stride=1, shuffle=False)\n",
        "\n",
        "data_iter = iter(dataloader)\n",
        "first_batch = next(data_iter)\n",
        "print(first_batch)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tjT1dbfsgI3N",
        "outputId": "9cfc4a0b-4a67-4852-d449-9940d01a44fe"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[tensor([[0, 1, 2, 3]]), tensor([[1, 2, 3, 4]])]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "second_batch = next(data_iter)\n",
        "print(second_batch)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BY97hd4ogLal",
        "outputId": "35c96807-e8cd-4397-a41b-ba6f85724d68"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[tensor([[1, 2, 3, 4]]), tensor([[2, 3, 4, 5]])]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "third_batch = next(data_iter)\n",
        "print(third_batch)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ABm0tvwhgN4I",
        "outputId": "a163cba2-9597-471b-f5d3-acb272a5a0ec"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[tensor([[2, 3, 4, 5]]), tensor([[3, 4, 5, 6]])]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for batch in dataloader:\n",
        "    pass\n",
        "\n",
        "last_batch = batch\n",
        "print(last_batch)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RBRAyY8HgTqe",
        "outputId": "a1cf3c9a-19ea-4a3b-8f64-e4f7c5d6ca19"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[tensor([[996, 997, 998, 999]]), tensor([[ 997,  998,  999, 1000]])]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dataloader = create_dataloader_v1(raw_text, batch_size=2, max_length=4, stride=4, shuffle=False)\n",
        "\n",
        "for inputs, targets in dataloader:\n",
        "    pass\n",
        "\n",
        "print(\"Inputs:\\n\", inputs)\n",
        "print(\"\\nTargets:\\n\", targets)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "D2Mp6a19gUm0",
        "outputId": "97609124-3bf8-4267-dcd6-845bf7d0a743"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Inputs:\n",
            " tensor([[992, 993, 994, 995],\n",
            "        [996, 997, 998, 999]])\n",
            "\n",
            "Targets:\n",
            " tensor([[ 993,  994,  995,  996],\n",
            "        [ 997,  998,  999, 1000]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "torch.manual_seed(123)\n",
        "dataloader = create_dataloader_v1(raw_text, batch_size=2, max_length=4, stride=4, shuffle=True)\n",
        "\n",
        "for inputs, targets in dataloader:\n",
        "    pass\n",
        "\n",
        "print(\"Inputs:\\n\", inputs)\n",
        "print(\"\\nTargets:\\n\", targets)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uNknez48gX4J",
        "outputId": "b2eaff2e-c539-4f93-90b0-7e655f091189"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Inputs:\n",
            " tensor([[880, 881, 882, 883],\n",
            "        [112, 113, 114, 115]])\n",
            "\n",
            "Targets:\n",
            " tensor([[881, 882, 883, 884],\n",
            "        [113, 114, 115, 116]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Byte Pair Encoding (BPE) Tokenizer From Scratch"
      ],
      "metadata": {
        "id": "wvTs1xIQg0bI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "text = \"This is some text\"\n",
        "byte_ary = bytearray(text, \"utf-8\")\n",
        "print(byte_ary)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1QX5xxyBg1X7",
        "outputId": "85538a5b-b79e-49fe-8066-91cb88d38284"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "bytearray(b'This is some text')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "ids = list(byte_ary)\n",
        "print(ids)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jWyJXvwZg4dU",
        "outputId": "a069a9bc-a319-49aa-dcf9-182c58623338"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[84, 104, 105, 115, 32, 105, 115, 32, 115, 111, 109, 101, 32, 116, 101, 120, 116]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Number of characters:\", len(text))\n",
        "print(\"Number of token IDs:\", len(ids))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NgElqVrDg655",
        "outputId": "279f7051-51ff-4bcd-9641-3db3935d0673"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of characters: 17\n",
            "Number of token IDs: 17\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tiktoken\n",
        "\n",
        "gpt2_tokenizer = tiktoken.get_encoding(\"gpt2\")\n",
        "gpt2_tokenizer.encode(\"This is some text\")\n",
        "# prints [1212, 318, 617, 2420]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sLIkW15cg9qk",
        "outputId": "ff8cac1e-a88e-40a1-b5b9-d84298be9e9b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[1212, 318, 617, 2420]"
            ]
          },
          "metadata": {},
          "execution_count": 193
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tiktoken\n",
        "gpt2_tokenizer = tiktoken.get_encoding(\"gpt2\")\n",
        "\n",
        "for i in range(300):\n",
        "    decoded = gpt2_tokenizer.decode([i])\n",
        "    print(f\"{i}: {decoded}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p_jqYwRkhA4J",
        "outputId": "8f035029-5a6e-4123-9666-b7784f9b0785"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0: !\n",
            "1: \"\n",
            "2: #\n",
            "3: $\n",
            "4: %\n",
            "5: &\n",
            "6: '\n",
            "7: (\n",
            "8: )\n",
            "9: *\n",
            "10: +\n",
            "11: ,\n",
            "12: -\n",
            "13: .\n",
            "14: /\n",
            "15: 0\n",
            "16: 1\n",
            "17: 2\n",
            "18: 3\n",
            "19: 4\n",
            "20: 5\n",
            "21: 6\n",
            "22: 7\n",
            "23: 8\n",
            "24: 9\n",
            "25: :\n",
            "26: ;\n",
            "27: <\n",
            "28: =\n",
            "29: >\n",
            "30: ?\n",
            "31: @\n",
            "32: A\n",
            "33: B\n",
            "34: C\n",
            "35: D\n",
            "36: E\n",
            "37: F\n",
            "38: G\n",
            "39: H\n",
            "40: I\n",
            "41: J\n",
            "42: K\n",
            "43: L\n",
            "44: M\n",
            "45: N\n",
            "46: O\n",
            "47: P\n",
            "48: Q\n",
            "49: R\n",
            "50: S\n",
            "51: T\n",
            "52: U\n",
            "53: V\n",
            "54: W\n",
            "55: X\n",
            "56: Y\n",
            "57: Z\n",
            "58: [\n",
            "59: \\\n",
            "60: ]\n",
            "61: ^\n",
            "62: _\n",
            "63: `\n",
            "64: a\n",
            "65: b\n",
            "66: c\n",
            "67: d\n",
            "68: e\n",
            "69: f\n",
            "70: g\n",
            "71: h\n",
            "72: i\n",
            "73: j\n",
            "74: k\n",
            "75: l\n",
            "76: m\n",
            "77: n\n",
            "78: o\n",
            "79: p\n",
            "80: q\n",
            "81: r\n",
            "82: s\n",
            "83: t\n",
            "84: u\n",
            "85: v\n",
            "86: w\n",
            "87: x\n",
            "88: y\n",
            "89: z\n",
            "90: {\n",
            "91: |\n",
            "92: }\n",
            "93: ~\n",
            "94: �\n",
            "95: �\n",
            "96: �\n",
            "97: �\n",
            "98: �\n",
            "99: �\n",
            "100: �\n",
            "101: �\n",
            "102: �\n",
            "103: �\n",
            "104: �\n",
            "105: �\n",
            "106: �\n",
            "107: �\n",
            "108: �\n",
            "109: �\n",
            "110: �\n",
            "111: �\n",
            "112: �\n",
            "113: �\n",
            "114: �\n",
            "115: �\n",
            "116: �\n",
            "117: �\n",
            "118: �\n",
            "119: �\n",
            "120: �\n",
            "121: �\n",
            "122: �\n",
            "123: �\n",
            "124: �\n",
            "125: �\n",
            "126: �\n",
            "127: �\n",
            "128: �\n",
            "129: �\n",
            "130: �\n",
            "131: �\n",
            "132: �\n",
            "133: �\n",
            "134: �\n",
            "135: �\n",
            "136: �\n",
            "137: �\n",
            "138: �\n",
            "139: �\n",
            "140: �\n",
            "141: �\n",
            "142: �\n",
            "143: �\n",
            "144: �\n",
            "145: �\n",
            "146: �\n",
            "147: �\n",
            "148: �\n",
            "149: �\n",
            "150: �\n",
            "151: �\n",
            "152: �\n",
            "153: �\n",
            "154: �\n",
            "155: �\n",
            "156: �\n",
            "157: �\n",
            "158: �\n",
            "159: �\n",
            "160: �\n",
            "161: �\n",
            "162: �\n",
            "163: �\n",
            "164: �\n",
            "165: �\n",
            "166: �\n",
            "167: �\n",
            "168: �\n",
            "169: �\n",
            "170: �\n",
            "171: �\n",
            "172: �\n",
            "173: �\n",
            "174: �\n",
            "175: �\n",
            "176: �\n",
            "177: �\n",
            "178: �\n",
            "179: �\n",
            "180: �\n",
            "181: �\n",
            "182: �\n",
            "183: �\n",
            "184: �\n",
            "185: �\n",
            "186: �\n",
            "187: �\n",
            "188: \u0000\n",
            "189: \u0001\n",
            "190: \u0002\n",
            "191: \u0003\n",
            "192: \u0004\n",
            "193: \u0005\n",
            "194: \u0006\n",
            "195: \u0007\n",
            "196: \b\n",
            "197: \t\n",
            "198: \n",
            "\n",
            "199: \u000b\n",
            "200: \f\n",
            "201: \r\n",
            "202: \u000e\n",
            "203: \u000f\n",
            "204: \u0010\n",
            "205: \u0011\n",
            "206: \u0012\n",
            "207: \u0013\n",
            "208: \u0014\n",
            "209: \u0015\n",
            "210: \u0016\n",
            "211: \u0017\n",
            "212: \u0018\n",
            "213: \u0019\n",
            "214: \u001a\n",
            "215: \u001b\n",
            "216: \u001c\n",
            "217: \u001d\n",
            "218: \u001e\n",
            "219: \u001f\n",
            "220:  \n",
            "221: \n",
            "222: �\n",
            "223: �\n",
            "224: �\n",
            "225: �\n",
            "226: �\n",
            "227: �\n",
            "228: �\n",
            "229: �\n",
            "230: �\n",
            "231: �\n",
            "232: �\n",
            "233: �\n",
            "234: �\n",
            "235: �\n",
            "236: �\n",
            "237: �\n",
            "238: �\n",
            "239: �\n",
            "240: �\n",
            "241: �\n",
            "242: �\n",
            "243: �\n",
            "244: �\n",
            "245: �\n",
            "246: �\n",
            "247: �\n",
            "248: �\n",
            "249: �\n",
            "250: �\n",
            "251: �\n",
            "252: �\n",
            "253: �\n",
            "254: �\n",
            "255: �\n",
            "256:  t\n",
            "257:  a\n",
            "258: he\n",
            "259: in\n",
            "260: re\n",
            "261: on\n",
            "262:  the\n",
            "263: er\n",
            "264:  s\n",
            "265: at\n",
            "266:  w\n",
            "267:  o\n",
            "268: en\n",
            "269:  c\n",
            "270: it\n",
            "271: is\n",
            "272: an\n",
            "273: or\n",
            "274: es\n",
            "275:  b\n",
            "276: ed\n",
            "277:  f\n",
            "278: ing\n",
            "279:  p\n",
            "280: ou\n",
            "281:  an\n",
            "282: al\n",
            "283: ar\n",
            "284:  to\n",
            "285:  m\n",
            "286:  of\n",
            "287:  in\n",
            "288:  d\n",
            "289:  h\n",
            "290:  and\n",
            "291: ic\n",
            "292: as\n",
            "293: le\n",
            "294:  th\n",
            "295: ion\n",
            "296: om\n",
            "297: ll\n",
            "298: ent\n",
            "299:  n\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "QnP8ClPDhGmG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "A simple BPE implementation"
      ],
      "metadata": {
        "id": "Gn5Sb2xghbkh"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Building the vocabulary"
      ],
      "metadata": {
        "id": "2bQRIn4ShIsI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from collections import Counter, deque\n",
        "from functools import lru_cache\n",
        "import json\n",
        "\n",
        "\n",
        "class BPETokenizerSimple:\n",
        "    def __init__(self):\n",
        "        # Maps token_id to token_str (e.g., {11246: \"some\"})\n",
        "        self.vocab = {}\n",
        "        # Maps token_str to token_id (e.g., {\"some\": 11246})\n",
        "        self.inverse_vocab = {}\n",
        "        # Dictionary of BPE merges: {(token_id1, token_id2): merged_token_id}\n",
        "        self.bpe_merges = {}\n",
        "\n",
        "        # For the official OpenAI GPT-2 merges, use a rank dict:\n",
        "        #  of form {(string_A, string_B): rank}, where lower rank = higher priority\n",
        "        self.bpe_ranks = {}\n",
        "\n",
        "    def train(self, text, vocab_size, allowed_special={\"<|endoftext|>\"}):\n",
        "        \"\"\"\n",
        "        Train the BPE tokenizer from scratch.\n",
        "\n",
        "        Args:\n",
        "            text (str): The training text.\n",
        "            vocab_size (int): The desired vocabulary size.\n",
        "            allowed_special (set): A set of special tokens to include.\n",
        "        \"\"\"\n",
        "\n",
        "        # Preprocess: Replace spaces with \"Ġ\"\n",
        "        # Note that Ġ is a particularity of the GPT-2 BPE implementation\n",
        "        # E.g., \"Hello world\" might be tokenized as [\"Hello\", \"Ġworld\"]\n",
        "        # (GPT-4 BPE would tokenize it as [\"Hello\", \" world\"])\n",
        "        processed_text = []\n",
        "        for i, char in enumerate(text):\n",
        "            if char == \" \" and i != 0:\n",
        "                processed_text.append(\"Ġ\")\n",
        "            if char != \" \":\n",
        "                processed_text.append(char)\n",
        "        processed_text = \"\".join(processed_text)\n",
        "\n",
        "        # Initialize vocab with unique characters, including \"Ġ\" if present\n",
        "        # Start with the first 256 ASCII characters\n",
        "        unique_chars = [chr(i) for i in range(256)]\n",
        "        unique_chars.extend(\n",
        "            char for char in sorted(set(processed_text))\n",
        "            if char not in unique_chars\n",
        "        )\n",
        "        if \"Ġ\" not in unique_chars:\n",
        "            unique_chars.append(\"Ġ\")\n",
        "\n",
        "        self.vocab = {i: char for i, char in enumerate(unique_chars)}\n",
        "        self.inverse_vocab = {char: i for i, char in self.vocab.items()}\n",
        "\n",
        "        # Add allowed special tokens\n",
        "        if allowed_special:\n",
        "            for token in allowed_special:\n",
        "                if token not in self.inverse_vocab:\n",
        "                    new_id = len(self.vocab)\n",
        "                    self.vocab[new_id] = token\n",
        "                    self.inverse_vocab[token] = new_id\n",
        "\n",
        "        # Tokenize the processed_text into token IDs\n",
        "        token_ids = [self.inverse_vocab[char] for char in processed_text]\n",
        "\n",
        "        # BPE steps 1-3: Repeatedly find and replace frequent pairs\n",
        "        for new_id in range(len(self.vocab), vocab_size):\n",
        "            pair_id = self.find_freq_pair(token_ids, mode=\"most\")\n",
        "            if pair_id is None:\n",
        "                break\n",
        "            token_ids = self.replace_pair(token_ids, pair_id, new_id)\n",
        "            self.bpe_merges[pair_id] = new_id\n",
        "\n",
        "        # Build the vocabulary with merged tokens\n",
        "        for (p0, p1), new_id in self.bpe_merges.items():\n",
        "            merged_token = self.vocab[p0] + self.vocab[p1]\n",
        "            self.vocab[new_id] = merged_token\n",
        "            self.inverse_vocab[merged_token] = new_id\n",
        "\n",
        "    def load_vocab_and_merges_from_openai(self, vocab_path, bpe_merges_path):\n",
        "        \"\"\"\n",
        "        Load pre-trained vocabulary and BPE merges from OpenAI's GPT-2 files.\n",
        "\n",
        "        Args:\n",
        "            vocab_path (str): Path to the vocab file (GPT-2 calls it 'encoder.json').\n",
        "            bpe_merges_path (str): Path to the bpe_merges file  (GPT-2 calls it 'vocab.bpe').\n",
        "        \"\"\"\n",
        "        # Load vocabulary\n",
        "        with open(vocab_path, \"r\", encoding=\"utf-8\") as file:\n",
        "            loaded_vocab = json.load(file)\n",
        "            # Convert loaded vocabulary to correct format\n",
        "            self.vocab = {int(v): k for k, v in loaded_vocab.items()}\n",
        "            self.inverse_vocab = {k: int(v) for k, v in loaded_vocab.items()}\n",
        "\n",
        "        # Handle newline character without adding a new token\n",
        "        if \"\\n\" not in self.inverse_vocab:\n",
        "            # Use an existing token ID as a placeholder for '\\n'\n",
        "            # Preferentially use \"<|endoftext|>\" if available\n",
        "            fallback_token = next((token for token in [\"<|endoftext|>\", \"Ġ\", \"\"] if token in self.inverse_vocab), None)\n",
        "            if fallback_token is not None:\n",
        "                newline_token_id = self.inverse_vocab[fallback_token]\n",
        "            else:\n",
        "                # If no fallback token is available, raise an error\n",
        "                raise KeyError(\"No suitable token found in vocabulary to map '\\\\n'.\")\n",
        "\n",
        "            self.inverse_vocab[\"\\n\"] = newline_token_id\n",
        "            self.vocab[newline_token_id] = \"\\n\"\n",
        "\n",
        "        # Load GPT-2 merges and store them with an assigned \"rank\"\n",
        "        self.bpe_ranks = {}  # reset ranks\n",
        "        with open(bpe_merges_path, \"r\", encoding=\"utf-8\") as file:\n",
        "            lines = file.readlines()\n",
        "            if lines and lines[0].startswith(\"#\"):\n",
        "                lines = lines[1:]\n",
        "\n",
        "            rank = 0\n",
        "            for line in lines:\n",
        "                pair = tuple(line.strip().split())\n",
        "                if len(pair) == 2:\n",
        "                    token1, token2 = pair\n",
        "                    # If token1 or token2 not in vocab, skip\n",
        "                    if token1 in self.inverse_vocab and token2 in self.inverse_vocab:\n",
        "                        self.bpe_ranks[(token1, token2)] = rank\n",
        "                        rank += 1\n",
        "                    else:\n",
        "                        print(f\"Skipping pair {pair} as one token is not in the vocabulary.\")\n",
        "\n",
        "    def encode(self, text):\n",
        "        \"\"\"\n",
        "        Encode the input text into a list of token IDs.\n",
        "\n",
        "        Args:\n",
        "            text (str): The text to encode.\n",
        "\n",
        "        Returns:\n",
        "            List[int]: The list of token IDs.\n",
        "        \"\"\"\n",
        "        tokens = []\n",
        "        # First split on newlines to preserve them\n",
        "        lines = text.split(\"\\n\")\n",
        "        for i, line in enumerate(lines):\n",
        "            if i > 0:\n",
        "                tokens.append(\"\\n\")  # Add newline token separately\n",
        "            words = line.split()\n",
        "            for j, word in enumerate(words):\n",
        "                if j == 0:\n",
        "                    if i > 0:  # Start of a new line but not the first line\n",
        "                        tokens.append(\"Ġ\" + word)  # Ensure it's marked as a new segment\n",
        "                    else:\n",
        "                        tokens.append(word)\n",
        "                else:\n",
        "                    # Prefix words in the middle of a line with \"Ġ\"\n",
        "                    tokens.append(\"Ġ\" + word)\n",
        "\n",
        "        token_ids = []\n",
        "        for token in tokens:\n",
        "            if token in self.inverse_vocab:\n",
        "                # token is contained in the vocabulary as is\n",
        "                token_ids.append(self.inverse_vocab[token])\n",
        "            else:\n",
        "                # Attempt to handle subword tokenization via BPE\n",
        "                sub_token_ids = self.tokenize_with_bpe(token)\n",
        "                token_ids.extend(sub_token_ids)\n",
        "\n",
        "        return token_ids\n",
        "\n",
        "    def tokenize_with_bpe(self, token):\n",
        "        \"\"\"\n",
        "        Tokenize a single token using BPE merges.\n",
        "\n",
        "        Args:\n",
        "            token (str): The token to tokenize.\n",
        "\n",
        "        Returns:\n",
        "            List[int]: The list of token IDs after applying BPE.\n",
        "        \"\"\"\n",
        "        # Tokenize the token into individual characters (as initial token IDs)\n",
        "        token_ids = [self.inverse_vocab.get(char, None) for char in token]\n",
        "        if None in token_ids:\n",
        "            missing_chars = [char for char, tid in zip(token, token_ids) if tid is None]\n",
        "            raise ValueError(f\"Characters not found in vocab: {missing_chars}\")\n",
        "\n",
        "        # If we haven't loaded OpenAI's GPT-2 merges, use my approach\n",
        "        if not self.bpe_ranks:\n",
        "            can_merge = True\n",
        "            while can_merge and len(token_ids) > 1:\n",
        "                can_merge = False\n",
        "                new_tokens = []\n",
        "                i = 0\n",
        "                while i < len(token_ids) - 1:\n",
        "                    pair = (token_ids[i], token_ids[i + 1])\n",
        "                    if pair in self.bpe_merges:\n",
        "                        merged_token_id = self.bpe_merges[pair]\n",
        "                        new_tokens.append(merged_token_id)\n",
        "                        # Uncomment for educational purposes:\n",
        "                        # print(f\"Merged pair {pair} -> {merged_token_id} ('{self.vocab[merged_token_id]}')\")\n",
        "                        i += 2  # Skip the next token as it's merged\n",
        "                        can_merge = True\n",
        "                    else:\n",
        "                        new_tokens.append(token_ids[i])\n",
        "                        i += 1\n",
        "                if i < len(token_ids):\n",
        "                    new_tokens.append(token_ids[i])\n",
        "                token_ids = new_tokens\n",
        "            return token_ids\n",
        "\n",
        "        # Otherwise, do GPT-2-style merging with the ranks:\n",
        "        # 1) Convert token_ids back to string \"symbols\" for each ID\n",
        "        symbols = [self.vocab[id_num] for id_num in token_ids]\n",
        "\n",
        "        # Repeatedly merge all occurrences of the lowest-rank pair\n",
        "        while True:\n",
        "            # Collect all adjacent pairs\n",
        "            pairs = set(zip(symbols, symbols[1:]))\n",
        "            if not pairs:\n",
        "                break\n",
        "\n",
        "            # Find the pair with the best (lowest) rank\n",
        "            min_rank = float(\"inf\")\n",
        "            bigram = None\n",
        "            for p in pairs:\n",
        "                r = self.bpe_ranks.get(p, float(\"inf\"))\n",
        "                if r < min_rank:\n",
        "                    min_rank = r\n",
        "                    bigram = p\n",
        "\n",
        "            # If no valid ranked pair is present, we're done\n",
        "            if bigram is None or bigram not in self.bpe_ranks:\n",
        "                break\n",
        "\n",
        "            # Merge all occurrences of that pair\n",
        "            first, second = bigram\n",
        "            new_symbols = []\n",
        "            i = 0\n",
        "            while i < len(symbols):\n",
        "                # If we see (first, second) at position i, merge them\n",
        "                if i < len(symbols) - 1 and symbols[i] == first and symbols[i+1] == second:\n",
        "                    new_symbols.append(first + second)  # merged symbol\n",
        "                    i += 2\n",
        "                else:\n",
        "                    new_symbols.append(symbols[i])\n",
        "                    i += 1\n",
        "            symbols = new_symbols\n",
        "\n",
        "            if len(symbols) == 1:\n",
        "                break\n",
        "\n",
        "        # Finally, convert merged symbols back to IDs\n",
        "        merged_ids = [self.inverse_vocab[sym] for sym in symbols]\n",
        "        return merged_ids\n",
        "\n",
        "    def decode(self, token_ids):\n",
        "        \"\"\"\n",
        "        Decode a list of token IDs back into a string.\n",
        "\n",
        "        Args:\n",
        "            token_ids (List[int]): The list of token IDs to decode.\n",
        "\n",
        "        Returns:\n",
        "            str: The decoded string.\n",
        "        \"\"\"\n",
        "        decoded_string = \"\"\n",
        "        for i, token_id in enumerate(token_ids):\n",
        "            if token_id not in self.vocab:\n",
        "                raise ValueError(f\"Token ID {token_id} not found in vocab.\")\n",
        "            token = self.vocab[token_id]\n",
        "            if token == \"\\n\":\n",
        "                if decoded_string and not decoded_string.endswith(\" \"):\n",
        "                    decoded_string += \" \"  # Add space if not present before a newline\n",
        "                decoded_string += token\n",
        "            elif token.startswith(\"Ġ\"):\n",
        "                decoded_string += \" \" + token[1:]\n",
        "            else:\n",
        "                decoded_string += token\n",
        "        return decoded_string\n",
        "\n",
        "    def save_vocab_and_merges(self, vocab_path, bpe_merges_path):\n",
        "        \"\"\"\n",
        "        Save the vocabulary and BPE merges to JSON files.\n",
        "\n",
        "        Args:\n",
        "            vocab_path (str): Path to save the vocabulary.\n",
        "            bpe_merges_path (str): Path to save the BPE merges.\n",
        "        \"\"\"\n",
        "        # Save vocabulary\n",
        "        with open(vocab_path, \"w\", encoding=\"utf-8\") as file:\n",
        "            json.dump(self.vocab, file, ensure_ascii=False, indent=2)\n",
        "\n",
        "        # Save BPE merges as a list of dictionaries\n",
        "        with open(bpe_merges_path, \"w\", encoding=\"utf-8\") as file:\n",
        "            merges_list = [{\"pair\": list(pair), \"new_id\": new_id}\n",
        "                           for pair, new_id in self.bpe_merges.items()]\n",
        "            json.dump(merges_list, file, ensure_ascii=False, indent=2)\n",
        "\n",
        "    def load_vocab_and_merges(self, vocab_path, bpe_merges_path):\n",
        "        \"\"\"\n",
        "        Load the vocabulary and BPE merges from JSON files.\n",
        "\n",
        "        Args:\n",
        "            vocab_path (str): Path to the vocabulary file.\n",
        "            bpe_merges_path (str): Path to the BPE merges file.\n",
        "        \"\"\"\n",
        "        # Load vocabulary\n",
        "        with open(vocab_path, \"r\", encoding=\"utf-8\") as file:\n",
        "            loaded_vocab = json.load(file)\n",
        "            self.vocab = {int(k): v for k, v in loaded_vocab.items()}\n",
        "            self.inverse_vocab = {v: int(k) for k, v in loaded_vocab.items()}\n",
        "\n",
        "        # Load BPE merges\n",
        "        with open(bpe_merges_path, \"r\", encoding=\"utf-8\") as file:\n",
        "            merges_list = json.load(file)\n",
        "            for merge in merges_list:\n",
        "                pair = tuple(merge[\"pair\"])\n",
        "                new_id = merge[\"new_id\"]\n",
        "                self.bpe_merges[pair] = new_id\n",
        "\n",
        "    @lru_cache(maxsize=None)\n",
        "    def get_special_token_id(self, token):\n",
        "        return self.inverse_vocab.get(token, None)\n",
        "\n",
        "    @staticmethod\n",
        "    def find_freq_pair(token_ids, mode=\"most\"):\n",
        "        pairs = Counter(zip(token_ids, token_ids[1:]))\n",
        "\n",
        "        if not pairs:\n",
        "            return None\n",
        "\n",
        "        if mode == \"most\":\n",
        "            return max(pairs.items(), key=lambda x: x[1])[0]\n",
        "        elif mode == \"least\":\n",
        "            return min(pairs.items(), key=lambda x: x[1])[0]\n",
        "        else:\n",
        "            raise ValueError(\"Invalid mode. Choose 'most' or 'least'.\")\n",
        "\n",
        "    @staticmethod\n",
        "    def replace_pair(token_ids, pair_id, new_id):\n",
        "        dq = deque(token_ids)\n",
        "        replaced = []\n",
        "\n",
        "        while dq:\n",
        "            current = dq.popleft()\n",
        "            if dq and (current, dq[0]) == pair_id:\n",
        "                replaced.append(new_id)\n",
        "                # Remove the 2nd token of the pair, 1st was already removed\n",
        "                dq.popleft()\n",
        "            else:\n",
        "                replaced.append(current)\n",
        "\n",
        "        return replaced"
      ],
      "metadata": {
        "id": "OnVYs8kVhJQn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Training, encoding, and decoding"
      ],
      "metadata": {
        "id": "9nmQCJ7Thc3f"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import urllib.request\n",
        "\n",
        "def download_file_if_absent(url, filename, search_dirs):\n",
        "    for directory in search_dirs:\n",
        "        file_path = os.path.join(directory, filename)\n",
        "        if os.path.exists(file_path):\n",
        "            print(f\"{filename} already exists in {file_path}\")\n",
        "            return file_path\n",
        "\n",
        "    target_path = os.path.join(search_dirs[0], filename)\n",
        "    try:\n",
        "        with urllib.request.urlopen(url) as response, open(target_path, \"wb\") as out_file:\n",
        "            out_file.write(response.read())\n",
        "        print(f\"Downloaded {filename} to {target_path}\")\n",
        "    except Exception as e:\n",
        "        print(f\"Failed to download {filename}. Error: {e}\")\n",
        "    return target_path\n",
        "\n",
        "verdict_path = download_file_if_absent(\n",
        "    url=(\n",
        "         \"https://raw.githubusercontent.com/rasbt/\"\n",
        "         \"LLMs-from-scratch/main/ch02/01_main-chapter-code/\"\n",
        "         \"the-verdict.txt\"\n",
        "    ),\n",
        "    filename=\"the-verdict.txt\",\n",
        "    search_dirs=\".\"\n",
        ")\n",
        "\n",
        "with open(verdict_path, \"r\", encoding=\"utf-8\") as f: # added ../01_main-chapter-code/\n",
        "    text = f.read()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sZFI8BVQhg1y",
        "outputId": "9a803f73-af6f-410b-8bf6-f2917738c259"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "the-verdict.txt already exists in ./the-verdict.txt\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer = BPETokenizerSimple()\n",
        "tokenizer.train(text, vocab_size=1000, allowed_special={\"<|endoftext|>\"})"
      ],
      "metadata": {
        "id": "c48Ytfcahn0E"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# print(tokenizer.vocab)\n",
        "print(len(tokenizer.vocab))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0V13bcWOhpkt",
        "outputId": "59fa0acc-8f26-4d46-f3a7-5546745b3850"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(len(tokenizer.bpe_merges))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xxkuGnLihr53",
        "outputId": "ffca055e-8c5e-4ed4-f3db-295c4cfe4dab"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "742\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "input_text = \"Jack embraced beauty through art and life.\"\n",
        "token_ids = tokenizer.encode(input_text)\n",
        "print(token_ids)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JUkYWZwwhuGV",
        "outputId": "2fe35d43-e74a-4bcc-dfa8-7cf2185bca75"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[424, 256, 654, 531, 302, 311, 256, 296, 97, 465, 121, 595, 841, 116, 287, 466, 256, 326, 972, 46]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Number of characters:\", len(input_text))\n",
        "print(\"Number of token IDs:\", len(token_ids))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ue081YzLhwj7",
        "outputId": "311ccd88-f534-4bed-f12a-7e33d314ae96"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of characters: 42\n",
            "Number of token IDs: 20\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(token_ids)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fW6MhGMNhzgB",
        "outputId": "c599dddc-15ff-424e-dbde-d39cf9ebbc74"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[424, 256, 654, 531, 302, 311, 256, 296, 97, 465, 121, 595, 841, 116, 287, 466, 256, 326, 972, 46]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(tokenizer.decode(token_ids))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iDS2TLybh3qV",
        "outputId": "024c33ca-1731-40e9-8774-6d8cf46fe191"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Jack embraced beauty through art and life.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for token_id in token_ids:\n",
        "    print(f\"{token_id} -> {tokenizer.decode([token_id])}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YbJa4DGeh6VW",
        "outputId": "eb368e02-4f84-447b-a0af-555c86263da1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "424 -> Jack\n",
            "256 ->  \n",
            "654 -> em\n",
            "531 -> br\n",
            "302 -> ac\n",
            "311 -> ed\n",
            "256 ->  \n",
            "296 -> be\n",
            "97 -> a\n",
            "465 -> ut\n",
            "121 -> y\n",
            "595 ->  through\n",
            "841 ->  ar\n",
            "116 -> t\n",
            "287 ->  a\n",
            "466 -> nd\n",
            "256 ->  \n",
            "326 -> li\n",
            "972 -> fe\n",
            "46 -> .\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer.decode(\n",
        "    tokenizer.encode(\"This is some text.\")\n",
        ")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "DWS3Pkm9h9LA",
        "outputId": "3710c8a0-17c1-40f2-add1-e65e1d10798d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'This is some text.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 205
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer.decode(\n",
        "    tokenizer.encode(\"This is some text with \\n newline characters.\")\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "fvSxvkiIh_yu",
        "outputId": "a9d714d1-61f4-4a43-9ac5-e66f1255a934"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'This is some text with \\n newline characters.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 206
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "3.2 Saving and loading the tokenizer\n"
      ],
      "metadata": {
        "id": "5Nvlv3A_iGkw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Save trained tokenizer\n",
        "tokenizer.save_vocab_and_merges(vocab_path=\"vocab.json\", bpe_merges_path=\"bpe_merges.txt\")"
      ],
      "metadata": {
        "id": "s03WnxsXiCAF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load tokenizer\n",
        "tokenizer2 = BPETokenizerSimple()\n",
        "tokenizer2.load_vocab_and_merges(vocab_path=\"vocab.json\", bpe_merges_path=\"bpe_merges.txt\")\n"
      ],
      "metadata": {
        "id": "aljvwpYXiJua"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(tokenizer2.decode(token_ids))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8gvHoD9OiMCM",
        "outputId": "df368620-bab3-4ef9-bdaf-56f75c8d3104"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Jack embraced beauty through art and life.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer2.decode(\n",
        "    tokenizer2.encode(\"This is some text with \\n newline characters.\")\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "eYdCYQiKiOFw",
        "outputId": "a20c66af-04f0-4e2e-b6e4-736c169d6702"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'This is some text with \\n newline characters.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 210
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "3.3 Loading the original GPT-2 BPE tokenizer from OpenAI"
      ],
      "metadata": {
        "id": "dzIixHGXiTYI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Download files if not already present in this directory\n",
        "\n",
        "# Define the directories to search and the files to download\n",
        "search_directories = [\".\", \"../02_bonus_bytepair-encoder/gpt2_model/\"]\n",
        "\n",
        "files_to_download = {\n",
        "    \"https://openaipublic.blob.core.windows.net/gpt-2/models/124M/vocab.bpe\": \"vocab.bpe\",\n",
        "    \"https://openaipublic.blob.core.windows.net/gpt-2/models/124M/encoder.json\": \"encoder.json\"\n",
        "}\n",
        "\n",
        "# Ensure directories exist and download files if needed\n",
        "paths = {}\n",
        "for url, filename in files_to_download.items():\n",
        "    paths[filename] = download_file_if_absent(url, filename, search_directories)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PgTrbQKXiVeI",
        "outputId": "7a1a8ed6-eee3-48ab-9b85-a3d506dfc3df"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "vocab.bpe already exists in ./vocab.bpe\n",
            "encoder.json already exists in ./encoder.json\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer_gpt2 = BPETokenizerSimple()\n",
        "tokenizer_gpt2.load_vocab_and_merges_from_openai(\n",
        "    vocab_path=paths[\"encoder.json\"], bpe_merges_path=paths[\"vocab.bpe\"]\n",
        ")"
      ],
      "metadata": {
        "id": "CodTcAHJiZXB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(tokenizer_gpt2.vocab)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MvhYl44Mibut",
        "outputId": "d45df70e-1b28-4170-ee99-db5462a99fa6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "50257"
            ]
          },
          "metadata": {},
          "execution_count": 213
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "input_text = \"This is some text\"\n",
        "token_ids = tokenizer_gpt2.encode(input_text)\n",
        "print(token_ids)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l4WYWYL0iftM",
        "outputId": "a875d3b2-c15a-417e-db1a-024b97c033d8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[1212, 318, 617, 2420]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(tokenizer_gpt2.decode(token_ids))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rWPHLPVvig4g",
        "outputId": "4f03b055-4391-41fc-e074-2913b527e4ac"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "This is some text\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tiktoken\n",
        "\n",
        "gpt2_tokenizer = tiktoken.get_encoding(\"gpt2\")\n",
        "gpt2_tokenizer.encode(\"This is some text\")\n",
        "# prints [1212, 318, 617, 2420]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ze-D8Ek9ijfU",
        "outputId": "42900f35-9e5b-44c9-b7a4-65b35ead905b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[1212, 318, 617, 2420]"
            ]
          },
          "metadata": {},
          "execution_count": 216
        }
      ]
    }
  ]
}