{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPOy6HU4OUJqa+aMwGq4nSv",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ZeynepSudeIlerieee/LLMs/blob/main/llmmChapter_4.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Chapter 4: Implementing a GPT Model from Scratch To Generate Text"
      ],
      "metadata": {
        "id": "4d8ZyhiZ0D3p"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install tiktoken\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dnUYF29W0GMB",
        "outputId": "39960d02-9143-455d-fdc7-5c3b8a0f1e1c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: tiktoken in /usr/local/lib/python3.11/dist-packages (0.9.0)\n",
            "Requirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.11/dist-packages (from tiktoken) (2024.11.6)\n",
            "Requirement already satisfied: requests>=2.26.0 in /usr/local/lib/python3.11/dist-packages (from tiktoken) (2.32.3)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.26.0->tiktoken) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests>=2.26.0->tiktoken) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.26.0->tiktoken) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests>=2.26.0->tiktoken) (2025.1.31)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install tiktoken\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8N6OZIGP0pCo",
        "outputId": "da8f9f63-80d8-4f7a-ff27-e42502e53e8d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: tiktoken in /usr/local/lib/python3.11/dist-packages (0.9.0)\n",
            "Requirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.11/dist-packages (from tiktoken) (2024.11.6)\n",
            "Requirement already satisfied: requests>=2.26.0 in /usr/local/lib/python3.11/dist-packages (from tiktoken) (2.32.3)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.26.0->tiktoken) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests>=2.26.0->tiktoken) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.26.0->tiktoken) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests>=2.26.0->tiktoken) (2025.1.31)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tiktoken\n",
        "print(tiktoken.__version__)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IQJ0x1O90msG",
        "outputId": "50fafdac-8e9d-4d92-a1dc-e9dab2c05556"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.9.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install --upgrade pip setuptools"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H8UwVf0Z0TIs",
        "outputId": "b7703047-deae-4250-8622-94a8527f5ece"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pip in /usr/local/lib/python3.11/dist-packages (25.0.1)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.11/dist-packages (77.0.1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from importlib.metadata import version\n",
        "\n",
        "print(\"matplotlib version:\", version(\"matplotlib\"))\n",
        "print(\"torch version:\", version(\"torch\"))\n",
        "print(\"tiktoken version:\", version(\"tiktoken\"))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MVBdWR4M1H98",
        "outputId": "4f372fed-ca8a-44ce-ee81-5e1ee68b0088"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "matplotlib version: 3.10.0\n",
            "torch version: 2.6.0+cu124\n",
            "tiktoken version: 0.9.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "GPT_CONFIG_124M = {\n",
        "    \"vocab_size\": 50257,    # Vocabulary size\n",
        "    \"context_length\": 1024, # Context length\n",
        "    \"emb_dim\": 768,         # Embedding dimension\n",
        "    \"n_heads\": 12,          # Number of attention heads\n",
        "    \"n_layers\": 12,         # Number of layers\n",
        "    \"drop_rate\": 0.1,       # Dropout rate\n",
        "    \"qkv_bias\": False       # Query-Key-Value bias\n",
        "}"
      ],
      "metadata": {
        "id": "iDDXuTfM1Lro"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "\n",
        "class DummyGPTModel(nn.Module):\n",
        "    def __init__(self, cfg):\n",
        "        super().__init__()\n",
        "        self.tok_emb = nn.Embedding(cfg[\"vocab_size\"], cfg[\"emb_dim\"])\n",
        "        self.pos_emb = nn.Embedding(cfg[\"context_length\"], cfg[\"emb_dim\"])\n",
        "        self.drop_emb = nn.Dropout(cfg[\"drop_rate\"])\n",
        "\n",
        "        # Use a placeholder for TransformerBlock\n",
        "        self.trf_blocks = nn.Sequential(\n",
        "            *[DummyTransformerBlock(cfg) for _ in range(cfg[\"n_layers\"])])\n",
        "\n",
        "        # Use a placeholder for LayerNorm\n",
        "        self.final_norm = DummyLayerNorm(cfg[\"emb_dim\"])\n",
        "        self.out_head = nn.Linear(\n",
        "            cfg[\"emb_dim\"], cfg[\"vocab_size\"], bias=False\n",
        "        )\n",
        "\n",
        "    def forward(self, in_idx):\n",
        "        batch_size, seq_len = in_idx.shape\n",
        "        tok_embeds = self.tok_emb(in_idx)\n",
        "        pos_embeds = self.pos_emb(torch.arange(seq_len, device=in_idx.device))\n",
        "        x = tok_embeds + pos_embeds\n",
        "        x = self.drop_emb(x)\n",
        "        x = self.trf_blocks(x)\n",
        "        x = self.final_norm(x)\n",
        "        logits = self.out_head(x)\n",
        "        return logits\n",
        "\n",
        "\n",
        "class DummyTransformerBlock(nn.Module):\n",
        "    def __init__(self, cfg):\n",
        "        super().__init__()\n",
        "        # A simple placeholder\n",
        "\n",
        "    def forward(self, x):\n",
        "        # This block does nothing and just returns its input.\n",
        "        return x\n",
        "\n",
        "\n",
        "class DummyLayerNorm(nn.Module):\n",
        "    def __init__(self, normalized_shape, eps=1e-5):\n",
        "        super().__init__()\n",
        "        # The parameters here are just to mimic the LayerNorm interface.\n",
        "\n",
        "    def forward(self, x):\n",
        "        # This layer does nothing and just returns its input.\n",
        "        return x"
      ],
      "metadata": {
        "id": "PXZUoWqW1SBG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import tiktoken\n",
        "\n",
        "tokenizer = tiktoken.get_encoding(\"gpt2\")\n",
        "\n",
        "batch = []\n",
        "\n",
        "txt1 = \"Every effort moves you\"\n",
        "txt2 = \"Every day holds a\"\n",
        "\n",
        "batch.append(torch.tensor(tokenizer.encode(txt1)))\n",
        "batch.append(torch.tensor(tokenizer.encode(txt2)))\n",
        "batch = torch.stack(batch, dim=0)\n",
        "print(batch)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ir9NGI5T1gDI",
        "outputId": "265121cf-b738-4f3a-b1bc-c602fc3eebb3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[6109, 3626, 6100,  345],\n",
            "        [6109, 1110, 6622,  257]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "torch.manual_seed(123)\n",
        "model = DummyGPTModel(GPT_CONFIG_124M)\n",
        "\n",
        "logits = model(batch)\n",
        "print(\"Output shape:\", logits.shape)\n",
        "print(logits)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KOCoEtPg24mr",
        "outputId": "f916cc1d-85c3-4928-8b90-f0956d7fe2e4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Output shape: torch.Size([2, 4, 50257])\n",
            "tensor([[[-0.9289,  0.2748, -0.7557,  ..., -1.6070,  0.2702, -0.5888],\n",
            "         [-0.4476,  0.1726,  0.5354,  ..., -0.3932,  1.5285,  0.8557],\n",
            "         [ 0.5680,  1.6053, -0.2155,  ...,  1.1624,  0.1380,  0.7425],\n",
            "         [ 0.0447,  2.4787, -0.8843,  ...,  1.3219, -0.0864, -0.5856]],\n",
            "\n",
            "        [[-1.5474, -0.0542, -1.0571,  ..., -1.8061, -0.4494, -0.6747],\n",
            "         [-0.8422,  0.8243, -0.1098,  ..., -0.1434,  0.2079,  1.2046],\n",
            "         [ 0.1355,  1.1858, -0.1453,  ...,  0.0869, -0.1590,  0.1552],\n",
            "         [ 0.1666, -0.8138,  0.2307,  ...,  2.5035, -0.3055, -0.3083]]],\n",
            "       grad_fn=<UnsafeViewBackward0>)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "torch.manual_seed(123)\n",
        "\n",
        "# create 2 training examples with 5 dimensions (features) each\n",
        "batch_example = torch.randn(2, 5)\n",
        "\n",
        "layer = nn.Sequential(nn.Linear(5, 6), nn.ReLU())\n",
        "out = layer(batch_example)\n",
        "print(out)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NY7U5_EB3O_T",
        "outputId": "277cd599-d6b5-4e16-9961-bfbd73e495b8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[0.2260, 0.3470, 0.0000, 0.2216, 0.0000, 0.0000],\n",
            "        [0.2133, 0.2394, 0.0000, 0.5198, 0.3297, 0.0000]],\n",
            "       grad_fn=<ReluBackward0>)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "mean = out.mean(dim=-1, keepdim=True)\n",
        "var = out.var(dim=-1, keepdim=True)\n",
        "\n",
        "print(\"Mean:\\n\", mean)\n",
        "print(\"Variance:\\n\", var)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zZPN1HbO3Zzi",
        "outputId": "1e84c937-d586-4709-a435-e02df354cf7e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mean:\n",
            " tensor([[0.1324],\n",
            "        [0.2170]], grad_fn=<MeanBackward1>)\n",
            "Variance:\n",
            " tensor([[0.0231],\n",
            "        [0.0398]], grad_fn=<VarBackward0>)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "out_norm = (out - mean) / torch.sqrt(var)\n",
        "print(\"Normalized layer outputs:\\n\", out_norm)\n",
        "\n",
        "mean = out_norm.mean(dim=-1, keepdim=True)\n",
        "var = out_norm.var(dim=-1, keepdim=True)\n",
        "print(\"Mean:\\n\", mean)\n",
        "print(\"Variance:\\n\", var)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C0VPTB0S3kyE",
        "outputId": "7a6312f2-cc4d-416e-80fc-5f4c5d0fb87a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Normalized layer outputs:\n",
            " tensor([[ 0.6159,  1.4126, -0.8719,  0.5872, -0.8719, -0.8719],\n",
            "        [-0.0189,  0.1121, -1.0876,  1.5173,  0.5647, -1.0876]],\n",
            "       grad_fn=<DivBackward0>)\n",
            "Mean:\n",
            " tensor([[9.9341e-09],\n",
            "        [1.9868e-08]], grad_fn=<MeanBackward1>)\n",
            "Variance:\n",
            " tensor([[1.0000],\n",
            "        [1.0000]], grad_fn=<VarBackward0>)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "torch.set_printoptions(sci_mode=False)\n",
        "print(\"Mean:\\n\", mean)\n",
        "print(\"Variance:\\n\", var)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1zIdlAyG3vMN",
        "outputId": "c0ee4403-fdb3-479b-faea-d51b4f6b5f2b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mean:\n",
            " tensor([[    0.0000],\n",
            "        [    0.0000]], grad_fn=<MeanBackward1>)\n",
            "Variance:\n",
            " tensor([[1.0000],\n",
            "        [1.0000]], grad_fn=<VarBackward0>)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class LayerNorm(nn.Module):\n",
        "    def __init__(self, emb_dim):\n",
        "        super().__init__()\n",
        "        self.eps = 1e-5\n",
        "        self.scale = nn.Parameter(torch.ones(emb_dim))\n",
        "        self.shift = nn.Parameter(torch.zeros(emb_dim))\n",
        "\n",
        "    def forward(self, x):\n",
        "        mean = x.mean(dim=-1, keepdim=True)\n",
        "        var = x.var(dim=-1, keepdim=True, unbiased=False)\n",
        "        norm_x = (x - mean) / torch.sqrt(var + self.eps)\n",
        "        return self.scale * norm_x + self.shift"
      ],
      "metadata": {
        "id": "Xhr6kbwr31MX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ln = LayerNorm(emb_dim=5)\n",
        "out_ln = ln(batch_example)"
      ],
      "metadata": {
        "id": "fUkmnknW34tD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "mean = out_ln.mean(dim=-1, keepdim=True)\n",
        "var = out_ln.var(dim=-1, unbiased=False, keepdim=True)\n",
        "\n",
        "print(\"Mean:\\n\", mean)\n",
        "print(\"Variance:\\n\", var)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y0UWH9Bq38jj",
        "outputId": "a8c4e673-84d3-4099-8455-a2494e39118f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mean:\n",
            " tensor([[    -0.0000],\n",
            "        [     0.0000]], grad_fn=<MeanBackward1>)\n",
            "Variance:\n",
            " tensor([[1.0000],\n",
            "        [1.0000]], grad_fn=<VarBackward0>)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "4.3 Implementing a feed forward network with GELU activations\n"
      ],
      "metadata": {
        "id": "LJA1pUji4Igr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class GELU(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "\n",
        "    def forward(self, x):\n",
        "        return 0.5 * x * (1 + torch.tanh(\n",
        "            torch.sqrt(torch.tensor(2.0 / torch.pi)) *\n",
        "            (x + 0.044715 * torch.pow(x, 3))\n",
        "        ))"
      ],
      "metadata": {
        "id": "YzaZPLOT4YMk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "gelu, relu = GELU(), nn.ReLU()\n",
        "\n",
        "# Some sample data\n",
        "x = torch.linspace(-3, 3, 100)\n",
        "y_gelu, y_relu = gelu(x), relu(x)\n",
        "\n",
        "plt.figure(figsize=(8, 3))\n",
        "for i, (y, label) in enumerate(zip([y_gelu, y_relu], [\"GELU\", \"ReLU\"]), 1):\n",
        "    plt.subplot(1, 2, i)\n",
        "    plt.plot(x, y)\n",
        "    plt.title(f\"{label} activation function\")\n",
        "    plt.xlabel(\"x\")\n",
        "    plt.ylabel(f\"{label}(x)\")\n",
        "    plt.grid(True)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 282
        },
        "id": "PIOiLFCa4awE",
        "outputId": "43bb7a6b-5862-4bcf-bd91-c2eb8110c37e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 800x300 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class FeedForward(nn.Module):\n",
        "    def __init__(self, cfg):\n",
        "        super().__init__()\n",
        "        self.layers = nn.Sequential(\n",
        "            nn.Linear(cfg[\"emb_dim\"], 4 * cfg[\"emb_dim\"]),\n",
        "            GELU(),\n",
        "            nn.Linear(4 * cfg[\"emb_dim\"], cfg[\"emb_dim\"]),\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.layers(x)"
      ],
      "metadata": {
        "id": "K921NKx54rEY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(GPT_CONFIG_124M[\"emb_dim\"])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XvfUXAOG4w5q",
        "outputId": "8810bc37-4ac0-427b-f2e3-ca968db092e3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "768\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "ffn = FeedForward(GPT_CONFIG_124M)\n",
        "\n",
        "# input shape: [batch_size, num_token, emb_size]\n",
        "x = torch.rand(2, 3, 768)\n",
        "out = ffn(x)\n",
        "print(out.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c1KHYIGg4zmZ",
        "outputId": "36e2c5d2-0ce2-4cd3-daa6-584a0d0cdfcc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([2, 3, 768])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "4.4 Adding shortcut connections"
      ],
      "metadata": {
        "id": "viAN_oJ5-KzO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class ExampleDeepNeuralNetwork(nn.Module):\n",
        "    def __init__(self, layer_sizes, use_shortcut):\n",
        "        super().__init__()\n",
        "        self.use_shortcut = use_shortcut\n",
        "        self.layers = nn.ModuleList([\n",
        "            nn.Sequential(nn.Linear(layer_sizes[0], layer_sizes[1]), GELU()),\n",
        "            nn.Sequential(nn.Linear(layer_sizes[1], layer_sizes[2]), GELU()),\n",
        "            nn.Sequential(nn.Linear(layer_sizes[2], layer_sizes[3]), GELU()),\n",
        "            nn.Sequential(nn.Linear(layer_sizes[3], layer_sizes[4]), GELU()),\n",
        "            nn.Sequential(nn.Linear(layer_sizes[4], layer_sizes[5]), GELU())\n",
        "        ])\n",
        "\n",
        "    def forward(self, x):\n",
        "        for layer in self.layers:\n",
        "            # Compute the output of the current layer\n",
        "            layer_output = layer(x)\n",
        "            # Check if shortcut can be applied\n",
        "            if self.use_shortcut and x.shape == layer_output.shape:\n",
        "                x = x + layer_output\n",
        "            else:\n",
        "                x = layer_output\n",
        "        return x\n",
        "\n",
        "\n",
        "def print_gradients(model, x):\n",
        "    # Forward pass\n",
        "    output = model(x)\n",
        "    target = torch.tensor([[0.]])\n",
        "\n",
        "    # Calculate loss based on how close the target\n",
        "    # and output are\n",
        "    loss = nn.MSELoss()\n",
        "    loss = loss(output, target)\n",
        "\n",
        "    # Backward pass to calculate the gradients\n",
        "    loss.backward()\n",
        "\n",
        "    for name, param in model.named_parameters():\n",
        "        if 'weight' in name:\n",
        "            # Print the mean absolute gradient of the weights\n",
        "            print(f\"{name} has gradient mean of {param.grad.abs().mean().item()}\")"
      ],
      "metadata": {
        "id": "Bc7OuBMb-Le8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "layer_sizes = [3, 3, 3, 3, 3, 1]\n",
        "\n",
        "sample_input = torch.tensor([[1., 0., -1.]])\n",
        "\n",
        "torch.manual_seed(123)\n",
        "model_without_shortcut = ExampleDeepNeuralNetwork(\n",
        "    layer_sizes, use_shortcut=False\n",
        ")\n",
        "print_gradients(model_without_shortcut, sample_input)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AOrLYWoBAW3_",
        "outputId": "12f2a7e4-2725-46f1-a7eb-b9011a05060f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "layers.0.0.weight has gradient mean of 0.00020173584925942123\n",
            "layers.1.0.weight has gradient mean of 0.00012011159560643137\n",
            "layers.2.0.weight has gradient mean of 0.0007152040489017963\n",
            "layers.3.0.weight has gradient mean of 0.0013988736318424344\n",
            "layers.4.0.weight has gradient mean of 0.005049645435065031\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "torch.manual_seed(123)\n",
        "model_with_shortcut = ExampleDeepNeuralNetwork(\n",
        "    layer_sizes, use_shortcut=True\n",
        ")\n",
        "print_gradients(model_with_shortcut, sample_input)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ybm3hDpxAa2B",
        "outputId": "3b26eb47-4cd4-4f89-9335-ac23294c79f9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "layers.0.0.weight has gradient mean of 0.22169791162014008\n",
            "layers.1.0.weight has gradient mean of 0.20694105327129364\n",
            "layers.2.0.weight has gradient mean of 0.32896995544433594\n",
            "layers.3.0.weight has gradient mean of 0.2665732204914093\n",
            "layers.4.0.weight has gradient mean of 1.3258540630340576\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "4.5 Connecting attention and linear layers in a transformer block"
      ],
      "metadata": {
        "id": "StEVeflzAfzi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from previous_chapters import MultiHeadAttention\n",
        "\n",
        "\n",
        "class TransformerBlock(nn.Module):\n",
        "    def __init__(self, cfg):\n",
        "        super().__init__()\n",
        "        self.att = MultiHeadAttention(\n",
        "            d_in=cfg[\"emb_dim\"],\n",
        "            d_out=cfg[\"emb_dim\"],\n",
        "            context_length=cfg[\"context_length\"],\n",
        "            num_heads=cfg[\"n_heads\"],\n",
        "            dropout=cfg[\"drop_rate\"],\n",
        "            qkv_bias=cfg[\"qkv_bias\"])\n",
        "        self.ff = FeedForward(cfg)\n",
        "        self.norm1 = LayerNorm(cfg[\"emb_dim\"])\n",
        "        self.norm2 = LayerNorm(cfg[\"emb_dim\"])\n",
        "        self.drop_shortcut = nn.Dropout(cfg[\"drop_rate\"])\n",
        "\n",
        "    def forward(self, x):\n",
        "        # Shortcut connection for attention block\n",
        "        shortcut = x\n",
        "        x = self.norm1(x)\n",
        "        x = self.att(x)  # Shape [batch_size, num_tokens, emb_size]\n",
        "        x = self.drop_shortcut(x)\n",
        "        x = x + shortcut  # Add the original input back\n",
        "\n",
        "        # Shortcut connection for feed forward block\n",
        "        shortcut = x\n",
        "        x = self.norm2(x)\n",
        "        x = self.ff(x)\n",
        "        x = self.drop_shortcut(x)\n",
        "        x = x + shortcut  # Add the original input back\n",
        "\n",
        "        return x"
      ],
      "metadata": {
        "id": "v727XelOAkPI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "torch.manual_seed(123)\n",
        "\n",
        "x = torch.rand(2, 4, 768)  # Shape: [batch_size, num_tokens, emb_dim]\n",
        "block = TransformerBlock(GPT_CONFIG_124M)\n",
        "output = block(x)\n",
        "\n",
        "print(\"Input shape:\", x.shape)\n",
        "print(\"Output shape:\", output.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YEbS7d1ECK0b",
        "outputId": "8d9419a6-c4e1-4ebb-d7c3-743091eadca2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input shape: torch.Size([2, 4, 768])\n",
            "Output shape: torch.Size([2, 4, 768])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "4.6 Coding the GPT model"
      ],
      "metadata": {
        "id": "TxrbasNSCWsU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class GPTModel(nn.Module):\n",
        "    def __init__(self, cfg):\n",
        "        super().__init__()\n",
        "        self.tok_emb = nn.Embedding(cfg[\"vocab_size\"], cfg[\"emb_dim\"])\n",
        "        self.pos_emb = nn.Embedding(cfg[\"context_length\"], cfg[\"emb_dim\"])\n",
        "        self.drop_emb = nn.Dropout(cfg[\"drop_rate\"])\n",
        "\n",
        "        self.trf_blocks = nn.Sequential(\n",
        "            *[TransformerBlock(cfg) for _ in range(cfg[\"n_layers\"])])\n",
        "\n",
        "        self.final_norm = LayerNorm(cfg[\"emb_dim\"])\n",
        "        self.out_head = nn.Linear(\n",
        "            cfg[\"emb_dim\"], cfg[\"vocab_size\"], bias=False\n",
        "        )\n",
        "\n",
        "    def forward(self, in_idx):\n",
        "        batch_size, seq_len = in_idx.shape\n",
        "        tok_embeds = self.tok_emb(in_idx)\n",
        "        pos_embeds = self.pos_emb(torch.arange(seq_len, device=in_idx.device))\n",
        "        x = tok_embeds + pos_embeds  # Shape [batch_size, num_tokens, emb_size]\n",
        "        x = self.drop_emb(x)\n",
        "        x = self.trf_blocks(x)\n",
        "        x = self.final_norm(x)\n",
        "        logits = self.out_head(x)\n",
        "        return logits"
      ],
      "metadata": {
        "id": "NM1AlZjkCXPh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "torch.manual_seed(123)\n",
        "model = GPTModel(GPT_CONFIG_124M)\n",
        "\n",
        "out = model(batch)\n",
        "print(\"Input batch:\\n\", batch)\n",
        "print(\"\\nOutput shape:\", out.shape)\n",
        "print(out)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fh7m9zNMC55l",
        "outputId": "bcb3d90d-f539-4dfa-a0a7-e99b62c144ba"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input batch:\n",
            " tensor([[6109, 3626, 6100,  345],\n",
            "        [6109, 1110, 6622,  257]])\n",
            "\n",
            "Output shape: torch.Size([2, 4, 50257])\n",
            "tensor([[[ 0.1381,  0.0077, -0.1963,  ..., -0.0222, -0.1060,  0.1717],\n",
            "         [ 0.3865, -0.8408, -0.6564,  ..., -0.5163,  0.2369, -0.3357],\n",
            "         [ 0.6989, -0.1829, -0.1631,  ...,  0.1472, -0.6504, -0.0056],\n",
            "         [-0.4290,  0.1669, -0.1258,  ...,  1.1579,  0.5303, -0.5549]],\n",
            "\n",
            "        [[ 0.1094, -0.2894, -0.1467,  ..., -0.0557,  0.2911, -0.2824],\n",
            "         [ 0.0882, -0.3552, -0.3527,  ...,  1.2930,  0.0053,  0.1898],\n",
            "         [ 0.6091,  0.4702, -0.4094,  ...,  0.7688,  0.3787, -0.1974],\n",
            "         [-0.0612, -0.0737,  0.4751,  ...,  1.2463, -0.3834,  0.0609]]],\n",
            "       grad_fn=<UnsafeViewBackward0>)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "total_params = sum(p.numel() for p in model.parameters())\n",
        "print(f\"Total number of parameters: {total_params:,}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dXPD1UyvC8T0",
        "outputId": "938c2684-05f9-4f06-9e3e-1672e1f2e0b9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total number of parameters: 163,009,536\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Token embedding layer shape:\", model.tok_emb.weight.shape)\n",
        "print(\"Output layer shape:\", model.out_head.weight.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tUJdSD4YC-9E",
        "outputId": "c3b130d3-7d78-4f5b-9a26-6c615a363ed0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Token embedding layer shape: torch.Size([50257, 768])\n",
            "Output layer shape: torch.Size([50257, 768])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "total_params_gpt2 =  total_params - sum(p.numel() for p in model.out_head.parameters())\n",
        "print(f\"Number of trainable parameters considering weight tying: {total_params_gpt2:,}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mgqp5R1uDBYv",
        "outputId": "4c2f4f7d-3786-46fa-fa97-43724d03f5d8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of trainable parameters considering weight tying: 124,412,160\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Calculate the total size in bytes (assuming float32, 4 bytes per parameter)\n",
        "total_size_bytes = total_params * 4\n",
        "\n",
        "# Convert to megabytes\n",
        "total_size_mb = total_size_bytes / (1024 * 1024)\n",
        "\n",
        "print(f\"Total size of the model: {total_size_mb:.2f} MB\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RANzCSwXDJ4c",
        "outputId": "0c845010-fb0f-437c-aa2f-5c7f1a8a6aa3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total size of the model: 621.83 MB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_text_simple(model, idx, max_new_tokens, context_size):\n",
        "    # idx is (batch, n_tokens) array of indices in the current context\n",
        "    for _ in range(max_new_tokens):\n",
        "\n",
        "        # Crop current context if it exceeds the supported context size\n",
        "        # E.g., if LLM supports only 5 tokens, and the context size is 10\n",
        "        # then only the last 5 tokens are used as context\n",
        "        idx_cond = idx[:, -context_size:]\n",
        "\n",
        "        # Get the predictions\n",
        "        with torch.no_grad():\n",
        "            logits = model(idx_cond)\n",
        "\n",
        "        # Focus only on the last time step\n",
        "        # (batch, n_tokens, vocab_size) becomes (batch, vocab_size)\n",
        "        logits = logits[:, -1, :]\n",
        "\n",
        "        # Apply softmax to get probabilities\n",
        "        probas = torch.softmax(logits, dim=-1)  # (batch, vocab_size)\n",
        "\n",
        "        # Get the idx of the vocab entry with the highest probability value\n",
        "        idx_next = torch.argmax(probas, dim=-1, keepdim=True)  # (batch, 1)\n",
        "\n",
        "        # Append sampled index to the running sequence\n",
        "        idx = torch.cat((idx, idx_next), dim=1)  # (batch, n_tokens+1)\n",
        "\n",
        "    return idx"
      ],
      "metadata": {
        "id": "UCmj-_1KDMN9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "start_context = \"Hello, I am\"\n",
        "\n",
        "encoded = tokenizer.encode(start_context)\n",
        "print(\"encoded:\", encoded)\n",
        "\n",
        "encoded_tensor = torch.tensor(encoded).unsqueeze(0)\n",
        "print(\"encoded_tensor.shape:\", encoded_tensor.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PnHaOBodDRJC",
        "outputId": "1cf32b3d-81c9-45e2-9ddd-15e59e069866"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "encoded: [15496, 11, 314, 716]\n",
            "encoded_tensor.shape: torch.Size([1, 4])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.eval() # disable dropout\n",
        "\n",
        "out = generate_text_simple(\n",
        "    model=model,\n",
        "    idx=encoded_tensor,\n",
        "    max_new_tokens=6,\n",
        "    context_size=GPT_CONFIG_124M[\"context_length\"]\n",
        ")\n",
        "\n",
        "print(\"Output:\", out)\n",
        "print(\"Output length:\", len(out[0]))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "v_5R_Fw6Dt7e",
        "outputId": "6e45cf39-e240-4bec-9af7-8b0a53f954db"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Output: tensor([[15496,    11,   314,   716, 27018, 24086, 47843, 30961, 42348,  7267]])\n",
            "Output length: 10\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "decoded_text = tokenizer.decode(out.squeeze(0).tolist())\n",
        "print(decoded_text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zQZ9WlmbEakc",
        "outputId": "d9210fce-34e8-4c2d-9ee6-4dbc84ba6caf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Hello, I am Featureiman Byeswickattribute argue\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Chapter 4 Exercise solutions"
      ],
      "metadata": {
        "id": "6xzbGHv-FYyH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from importlib.metadata import version\n",
        "\n",
        "print(\"torch version:\", version(\"torch\"))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eusuXucOFZlg",
        "outputId": "b5de4e11-486b-4981-9752-2a7c95906045"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch version: 2.6.0+cu124\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Exercise 4.1: Parameters in the feed forward versus attention module"
      ],
      "metadata": {
        "id": "-52wW7LGGh9o"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pip list | grep gpt\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b3H_UdMCGilA",
        "outputId": "a83c1b1e-c573-4edb-ecea-7b9790047437"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "gpt                                0.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install gpt\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AZ5MaCSsJc_9",
        "outputId": "e8efec89-f9b9-4041-bd86-5920d6733fe3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: gpt in /usr/local/lib/python3.11/dist-packages (0.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import gpt_1\n",
        "print(dir(gpt))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8hwHtpQ5KJYn",
        "outputId": "773a61da-a245-4b3d-fccd-5c504ffafca3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['GPTHeader', 'GPTPartitionEntry', 'MBR', 'MBR_Partition', 'OS_TYPES', 'PARTITION_TYPE_GUIDS', '__builtins__', '__cached__', '__doc__', '__file__', '__loader__', '__name__', '__package__', '__path__', '__spec__', 'binascii', 'calculate_partition_entry_array_crc32', 'decode_gpt_header', 'decode_gpt_partition_entry', 'decode_gpt_partition_entry_array', 'decode_gpt_partition_entry_attributes', 'decode_gpt_partition_type_guid', 'decode_guid', 'decode_mbr', 'encode_gpt_header', 'encode_gpt_partition_entry', 'encode_gpt_partition_entry_array', 'encode_mbr', 'nts_to_str', 'pack', 'unpack', 'uuid']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip show gpt\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EPe6T9U9Ke7c",
        "outputId": "ff9fc134-4ced-44ee-8b1e-4956ab6b4dea"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Name: gpt\n",
            "Version: 0.2\n",
            "Summary: GPT utils\n",
            "Home-page: https://github.com/metebalci/gpt\n",
            "Author: Mete Balci\n",
            "Author-email: metebalci@gmail.com\n",
            "License: GPLv3\n",
            "Location: /usr/local/lib/python3.11/dist-packages\n",
            "Requires: \n",
            "Required-by: \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install transformers"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "L6d-oIt6Kixh",
        "outputId": "5d346f9c-2881-4d25-aa7e-e6f2c78ee4db"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: transformers in /usr/local/lib/python3.11/dist-packages (4.48.3)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from transformers) (3.17.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.24.0 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.28.1)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from transformers) (2.0.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from transformers) (24.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from transformers) (6.0.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers) (2024.11.6)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from transformers) (2.32.3)\n",
            "Requirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.21.1)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.5.3)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.11/dist-packages (from transformers) (4.67.1)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.24.0->transformers) (2024.10.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.24.0->transformers) (4.12.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (2025.1.31)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip show gpt\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BZ3Zu7B-KwWl",
        "outputId": "2a4c2ba3-bac9-44e6-8058-b41b3623ec1f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Name: gpt\n",
            "Version: 0.2\n",
            "Summary: GPT utils\n",
            "Home-page: https://github.com/metebalci/gpt\n",
            "Author: Mete Balci\n",
            "Author-email: metebalci@gmail.com\n",
            "License: GPLv3\n",
            "Location: /usr/local/lib/python3.11/dist-packages\n",
            "Requires: \n",
            "Required-by: \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install gpt\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dgSyvTsXLFdB",
        "outputId": "b64c7a8d-42f3-4fd6-86f6-5e2a6272462f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: gpt in /usr/local/lib/python3.11/dist-packages (0.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install transformers\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gzWzAPvGLG4M",
        "outputId": "72c7f823-9ba6-4134-bc86-a86f55026ee9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: transformers in /usr/local/lib/python3.11/dist-packages (4.48.3)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from transformers) (3.17.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.24.0 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.28.1)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from transformers) (2.0.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from transformers) (24.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from transformers) (6.0.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers) (2024.11.6)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from transformers) (2.32.3)\n",
            "Requirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.21.1)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.5.3)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.11/dist-packages (from transformers) (4.67.1)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.24.0->transformers) (2024.10.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.24.0->transformers) (4.12.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (2025.1.31)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import GPT2Model\n"
      ],
      "metadata": {
        "id": "kXuHxluOLTSD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import gpt_1\n",
        "print(dir(gpt))  # gpt içindeki nesneleri listele\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "soyypRTWLukm",
        "outputId": "f16d7d71-7bf0-4e38-bad1-859ee152f5b9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['GPTHeader', 'GPTPartitionEntry', 'MBR', 'MBR_Partition', 'OS_TYPES', 'PARTITION_TYPE_GUIDS', '__builtins__', '__cached__', '__doc__', '__file__', '__loader__', '__name__', '__package__', '__path__', '__spec__', 'binascii', 'calculate_partition_entry_array_crc32', 'decode_gpt_header', 'decode_gpt_partition_entry', 'decode_gpt_partition_entry_array', 'decode_gpt_partition_entry_attributes', 'decode_gpt_partition_type_guid', 'decode_guid', 'decode_mbr', 'encode_gpt_header', 'encode_gpt_partition_entry', 'encode_gpt_partition_entry_array', 'encode_mbr', 'nts_to_str', 'pack', 'unpack', 'uuid']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import gpt_1\n",
        "print(dir(gpt))  # gpt modülündeki fonksiyonları/listeyi gösterir\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iG2tHi8jMiHg",
        "outputId": "045ea5fe-39f0-45e8-b4af-5e67be926655"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['GPTHeader', 'GPTPartitionEntry', 'MBR', 'MBR_Partition', 'OS_TYPES', 'PARTITION_TYPE_GUIDS', '__builtins__', '__cached__', '__doc__', '__file__', '__loader__', '__name__', '__package__', '__path__', '__spec__', 'binascii', 'calculate_partition_entry_array_crc32', 'decode_gpt_header', 'decode_gpt_partition_entry', 'decode_gpt_partition_entry_array', 'decode_gpt_partition_entry_attributes', 'decode_gpt_partition_type_guid', 'decode_guid', 'decode_mbr', 'encode_gpt_header', 'encode_gpt_partition_entry', 'encode_gpt_partition_entry_array', 'encode_mbr', 'nts_to_str', 'pack', 'unpack', 'uuid']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install gpt\n",
        "!pip install transformers\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YpvY5vLAORMB",
        "outputId": "323b9883-1561-4b46-b43e-532533ac857c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: gpt in /usr/local/lib/python3.11/dist-packages (0.2)\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.11/dist-packages (4.48.3)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from transformers) (3.17.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.24.0 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.28.1)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from transformers) (2.0.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from transformers) (24.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from transformers) (6.0.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers) (2024.11.6)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from transformers) (2.32.3)\n",
            "Requirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.21.1)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.5.3)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.11/dist-packages (from transformers) (4.67.1)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.24.0->transformers) (2024.10.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.24.0->transformers) (4.12.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (2025.1.31)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import GPT2Model, GPT2Config\n",
        "\n",
        "config = GPT2Config()\n",
        "model = GPT2Model(config)\n",
        "print(model)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1nkwk38xOZ6n",
        "outputId": "527da679-ae71-4a21-f5d5-48cf12fb5841"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GPT2Model(\n",
            "  (wte): Embedding(50257, 768)\n",
            "  (wpe): Embedding(1024, 768)\n",
            "  (drop): Dropout(p=0.1, inplace=False)\n",
            "  (h): ModuleList(\n",
            "    (0-11): 12 x GPT2Block(\n",
            "      (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "      (attn): GPT2Attention(\n",
            "        (c_attn): Conv1D(nf=2304, nx=768)\n",
            "        (c_proj): Conv1D(nf=768, nx=768)\n",
            "        (attn_dropout): Dropout(p=0.1, inplace=False)\n",
            "        (resid_dropout): Dropout(p=0.1, inplace=False)\n",
            "      )\n",
            "      (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "      (mlp): GPT2MLP(\n",
            "        (c_fc): Conv1D(nf=3072, nx=768)\n",
            "        (c_proj): Conv1D(nf=768, nx=3072)\n",
            "        (act): NewGELUActivation()\n",
            "        (dropout): Dropout(p=0.1, inplace=False)\n",
            "      )\n",
            "    )\n",
            "  )\n",
            "  (ln_f): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            ")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install transformers  # Önce kütüphaneyi yükleyin (Colab için)\n",
        "from transformers import GPT2Model  # Örnek bir GPT modeli\n",
        "\n",
        "# Config yerine direkt bir model kullanabilirsiniz\n",
        "model = GPT2Model.from_pretrained(\"gpt2\")  # Küçük bir GPT-2 modeli\n",
        "print(model)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vMbT-loOPDGY",
        "outputId": "5df21849-6b14-4b7b-f6b8-e61d5c5e1f11"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: transformers in /usr/local/lib/python3.11/dist-packages (4.48.3)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from transformers) (3.17.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.24.0 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.28.1)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from transformers) (2.0.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from transformers) (24.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from transformers) (6.0.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers) (2024.11.6)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from transformers) (2.32.3)\n",
            "Requirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.21.1)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.5.3)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.11/dist-packages (from transformers) (4.67.1)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.24.0->transformers) (2024.10.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.24.0->transformers) (4.12.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (2025.1.31)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GPT2Model(\n",
            "  (wte): Embedding(50257, 768)\n",
            "  (wpe): Embedding(1024, 768)\n",
            "  (drop): Dropout(p=0.1, inplace=False)\n",
            "  (h): ModuleList(\n",
            "    (0-11): 12 x GPT2Block(\n",
            "      (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "      (attn): GPT2Attention(\n",
            "        (c_attn): Conv1D(nf=2304, nx=768)\n",
            "        (c_proj): Conv1D(nf=768, nx=768)\n",
            "        (attn_dropout): Dropout(p=0.1, inplace=False)\n",
            "        (resid_dropout): Dropout(p=0.1, inplace=False)\n",
            "      )\n",
            "      (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "      (mlp): GPT2MLP(\n",
            "        (c_fc): Conv1D(nf=3072, nx=768)\n",
            "        (c_proj): Conv1D(nf=768, nx=3072)\n",
            "        (act): NewGELUActivation()\n",
            "        (dropout): Dropout(p=0.1, inplace=False)\n",
            "      )\n",
            "    )\n",
            "  )\n",
            "  (ln_f): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            ")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "YiKtOeqYVYJf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from gpt_1 import TransformerBlock\n",
        "\n",
        "GPT_CONFIG_124M = {\n",
        "    \"vocab_size\": 50257,\n",
        "    \"context_length\": 1024,\n",
        "    \"emb_dim\": 768,\n",
        "    \"n_heads\": 12,\n",
        "    \"n_layers\": 12,\n",
        "    \"drop_rate\": 0.1,\n",
        "    \"qkv_bias\": False\n",
        "}\n",
        "\n",
        "block = TransformerBlock(GPT_CONFIG_124M)\n",
        "print(block)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9HZy_YcvVDb9",
        "outputId": "2d5a142b-c22e-41df-9fe0-df63f8a794e8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "TransformerBlock(\n",
            "  (att): MultiHeadAttention(\n",
            "    (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
            "    (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
            "    (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
            "    (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
            "    (dropout): Dropout(p=0.1, inplace=False)\n",
            "  )\n",
            "  (ff): FeedForward(\n",
            "    (layers): Sequential(\n",
            "      (0): Linear(in_features=768, out_features=3072, bias=True)\n",
            "      (1): GELU()\n",
            "      (2): Linear(in_features=3072, out_features=768, bias=True)\n",
            "    )\n",
            "  )\n",
            "  (norm1): LayerNorm()\n",
            "  (norm2): LayerNorm()\n",
            "  (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
            ")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "total_params = sum(p.numel() for p in block.ff.parameters())\n",
        "print(f\"Total number of parameters in feed forward module: {total_params:,}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zgzNngiaVygf",
        "outputId": "5de2026d-7418-4043-e425-1b5333c7d5b9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total number of parameters in feed forward module: 4,722,432\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "total_params = sum(p.numel() for p in block.att.parameters())\n",
        "print(f\"Total number of parameters in attention module: {total_params:,}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nlA6xf34V_16",
        "outputId": "0ce43c86-68a0-4c19-c0bf-360ba32bf4de"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total number of parameters in attention module: 2,360,064\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "SZfLnLS-WwR9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Exercise 4.2: Initialize larger GPT models"
      ],
      "metadata": {
        "id": "nyJ9PG-LW1qx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "GPT_CONFIG_124M = {\n",
        "    \"vocab_size\": 50257,\n",
        "    \"context_length\": 1024,\n",
        "    \"emb_dim\": 768,\n",
        "    \"n_heads\": 12,\n",
        "    \"n_layers\": 12,\n",
        "    \"drop_rate\": 0.1,\n",
        "    \"qkv_bias\": False\n",
        "}\n",
        "\n",
        "\n",
        "def get_config(base_config, model_name=\"gpt2-small\"):\n",
        "    GPT_CONFIG = base_config.copy()\n",
        "\n",
        "    if model_name == \"gpt2-small\":\n",
        "        GPT_CONFIG[\"emb_dim\"] = 768\n",
        "        GPT_CONFIG[\"n_layers\"] = 12\n",
        "        GPT_CONFIG[\"n_heads\"] = 12\n",
        "\n",
        "    elif model_name == \"gpt2-medium\":\n",
        "        GPT_CONFIG[\"emb_dim\"] = 1024\n",
        "        GPT_CONFIG[\"n_layers\"] = 24\n",
        "        GPT_CONFIG[\"n_heads\"] = 16\n",
        "\n",
        "    elif model_name == \"gpt2-large\":\n",
        "        GPT_CONFIG[\"emb_dim\"] = 1280\n",
        "        GPT_CONFIG[\"n_layers\"] = 36\n",
        "        GPT_CONFIG[\"n_heads\"] = 20\n",
        "\n",
        "    elif model_name == \"gpt2-xl\":\n",
        "        GPT_CONFIG[\"emb_dim\"] = 1600\n",
        "        GPT_CONFIG[\"n_layers\"] = 48\n",
        "        GPT_CONFIG[\"n_heads\"] = 25\n",
        "\n",
        "    else:\n",
        "        raise ValueError(f\"Incorrect model name {model_name}\")\n",
        "\n",
        "    return GPT_CONFIG\n",
        "\n",
        "\n",
        "def calculate_size(model): # based on chapter code\n",
        "\n",
        "    total_params = sum(p.numel() for p in model.parameters())\n",
        "    print(f\"Total number of parameters: {total_params:,}\")\n",
        "\n",
        "    total_params_gpt2 =  total_params - sum(p.numel() for p in model.out_head.parameters())\n",
        "    print(f\"Number of trainable parameters considering weight tying: {total_params_gpt2:,}\")\n",
        "\n",
        "    # Calculate the total size in bytes (assuming float32, 4 bytes per parameter)\n",
        "    total_size_bytes = total_params * 4\n",
        "\n",
        "    # Convert to megabytes\n",
        "    total_size_mb = total_size_bytes / (1024 * 1024)\n",
        "\n",
        "    print(f\"Total size of the model: {total_size_mb:.2f} MB\")"
      ],
      "metadata": {
        "id": "8MitWP74W2pJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Transformers kütüphanesini yükleyin\n",
        "!pip install transformers\n",
        "\n",
        "from transformers import GPT2Model, GPT2Config\n",
        "\n",
        "# Farklı GPT-2 modellerini test etme\n",
        "for model_abbrev in (\"small\", \"medium\", \"large\", \"xl\"):\n",
        "    model_name = f\"gpt2-{model_abbrev}\" if model_abbrev != \"small\" else \"gpt2\"\n",
        "    print(f\"\\nLoading {model_name}...\")\n",
        "    model = GPT2Model.from_pretrained(model_name)\n",
        "    total_params = sum(p.numel() for p in model.parameters())\n",
        "    print(f\"Total number of parameters in {model_name}: {total_params:,}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7AAeGhvcXnzW",
        "outputId": "8f411b11-f7a9-4f26-95cb-360fc509f910"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: transformers in /usr/local/lib/python3.11/dist-packages (4.48.3)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from transformers) (3.17.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.24.0 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.28.1)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from transformers) (2.0.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from transformers) (24.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from transformers) (6.0.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers) (2024.11.6)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from transformers) (2.32.3)\n",
            "Requirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.21.1)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.5.3)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.11/dist-packages (from transformers) (4.67.1)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.24.0->transformers) (2024.10.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.24.0->transformers) (4.12.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (2025.1.31)\n",
            "\n",
            "Loading gpt2...\n",
            "Total number of parameters in gpt2: 124,439,808\n",
            "\n",
            "Loading gpt2-medium...\n",
            "Total number of parameters in gpt2-medium: 354,823,168\n",
            "\n",
            "Loading gpt2-large...\n",
            "Total number of parameters in gpt2-large: 774,030,080\n",
            "\n",
            "Loading gpt2-xl...\n",
            "Total number of parameters in gpt2-xl: 1,557,611,200\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install transformers\n",
        "from transformers import GPT2Model\n",
        "\n",
        "for model_abbrev in (\"small\", \"medium\", \"large\", \"xl\"):\n",
        "    model_name = f\"gpt2-{model_abbrev}\" if model_abbrev != \"small\" else \"gpt2\"\n",
        "    print(f\"\\nLoading {model_name}...\")\n",
        "    model = GPT2Model.from_pretrained(model_name)\n",
        "    total_params = sum(p.numel() for p in model.parameters())\n",
        "    print(f\"Total number of parameters in {model_name}: {total_params:,}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MZOrhHcEY4WR",
        "outputId": "dc4aed6e-467b-4b94-820d-e91946097c41"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: transformers in /usr/local/lib/python3.11/dist-packages (4.48.3)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from transformers) (3.17.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.24.0 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.28.1)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from transformers) (2.0.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from transformers) (24.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from transformers) (6.0.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers) (2024.11.6)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from transformers) (2.32.3)\n",
            "Requirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.21.1)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.5.3)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.11/dist-packages (from transformers) (4.67.1)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.24.0->transformers) (2024.10.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.24.0->transformers) (4.12.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (2025.1.31)\n",
            "\n",
            "Loading gpt2...\n",
            "Total number of parameters in gpt2: 124,439,808\n",
            "\n",
            "Loading gpt2-medium...\n",
            "Total number of parameters in gpt2-medium: 354,823,168\n",
            "\n",
            "Loading gpt2-large...\n",
            "Total number of parameters in gpt2-large: 774,030,080\n",
            "\n",
            "Loading gpt2-xl...\n",
            "Total number of parameters in gpt2-xl: 1,557,611,200\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Exercise 4.3: Using separate dropout parameters"
      ],
      "metadata": {
        "id": "Lok-daps1PFj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "GPT_CONFIG_124M = {\n",
        "    \"vocab_size\": 50257,\n",
        "    \"context_length\": 1024,\n",
        "    \"emb_dim\": 768,\n",
        "    \"n_heads\": 12,\n",
        "    \"n_layers\": 12,\n",
        "    \"drop_rate_emb\": 0.1,        # NEW: dropout for embedding layers\n",
        "    \"drop_rate_attn\": 0.1,       # NEW: dropout for multi-head attention\n",
        "    \"drop_rate_shortcut\": 0.1,   # NEW: dropout for shortcut connections\n",
        "    \"qkv_bias\": False\n",
        "}\n"
      ],
      "metadata": {
        "id": "boK3BqMC1P1a"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.nn as nn\n",
        "from gpt_1 import MultiHeadAttention, LayerNorm, FeedForward\n",
        "\n",
        "\n",
        "class TransformerBlock(nn.Module):\n",
        "    def __init__(self, cfg):\n",
        "        super().__init__()\n",
        "        self.att = MultiHeadAttention(\n",
        "            d_in=cfg[\"emb_dim\"],\n",
        "            d_out=cfg[\"emb_dim\"],\n",
        "            context_length=cfg[\"context_length\"],\n",
        "            num_heads=cfg[\"n_heads\"],\n",
        "            dropout=cfg[\"drop_rate_attn\"], # NEW: dropout for multi-head attention\n",
        "            qkv_bias=cfg[\"qkv_bias\"])\n",
        "        self.ff = FeedForward(cfg)\n",
        "        self.norm1 = LayerNorm(cfg[\"emb_dim\"])\n",
        "        self.norm2 = LayerNorm(cfg[\"emb_dim\"])\n",
        "        self.drop_shortcut = nn.Dropout(cfg[\"drop_rate_shortcut\"])\n",
        "\n",
        "    def forward(self, x):\n",
        "        # Shortcut connection for attention block\n",
        "        shortcut = x\n",
        "        x = self.norm1(x)\n",
        "        x = self.att(x)  # Shape [batch_size, num_tokens, emb_size]\n",
        "        x = self.drop_shortcut(x)\n",
        "        x = x + shortcut  # Add the original input back\n",
        "\n",
        "        # Shortcut connection for feed-forward block\n",
        "        shortcut = x\n",
        "        x = self.norm2(x)\n",
        "        x = self.ff(x)\n",
        "        x = self.drop_shortcut(x)\n",
        "        x = x + shortcut  # Add the original input back\n",
        "\n",
        "        return x\n",
        "\n",
        "\n",
        "class GPTModel(nn.Module):\n",
        "    def __init__(self, cfg):\n",
        "        super().__init__()\n",
        "        self.tok_emb = nn.Embedding(cfg[\"vocab_size\"], cfg[\"emb_dim\"])\n",
        "        self.pos_emb = nn.Embedding(cfg[\"context_length\"], cfg[\"emb_dim\"])\n",
        "        self.drop_emb = nn.Dropout(cfg[\"drop_rate_emb\"]) # NEW: dropout for embedding layers\n",
        "\n",
        "        self.trf_blocks = nn.Sequential(\n",
        "            *[TransformerBlock(cfg) for _ in range(cfg[\"n_layers\"])])\n",
        "\n",
        "        self.final_norm = LayerNorm(cfg[\"emb_dim\"])\n",
        "        self.out_head = nn.Linear(cfg[\"emb_dim\"], cfg[\"vocab_size\"], bias=False)\n",
        "\n",
        "    def forward(self, in_idx):\n",
        "        batch_size, seq_len = in_idx.shape\n",
        "        tok_embeds = self.tok_emb(in_idx)\n",
        "        pos_embeds = self.pos_emb(torch.arange(seq_len, device=in_idx.device))\n",
        "        x = tok_embeds + pos_embeds  # Shape [batch_size, num_tokens, emb_size]\n",
        "        x = self.drop_emb(x)\n",
        "        x = self.trf_blocks(x)\n",
        "        x = self.final_norm(x)\n",
        "        logits = self.out_head(x)\n",
        "        return logits"
      ],
      "metadata": {
        "id": "YHwo9-941S5J"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "\n",
        "torch.manual_seed(123)\n",
        "model = GPTModel(GPT_CONFIG_124M)"
      ],
      "metadata": {
        "id": "O-rWxolY1ZjD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "FLOPS Analysis"
      ],
      "metadata": {
        "id": "NBlfcGL31nOC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install thop\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B2-k7DH914rg",
        "outputId": "10c90c4f-2b5b-40a8-8fbf-1f5ffb89619c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: thop in /usr/local/lib/python3.11/dist-packages (0.1.1.post2209072238)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.11/dist-packages (from thop) (2.6.0+cu124)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch->thop) (3.17.0)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.11/dist-packages (from torch->thop) (4.12.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch->thop) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch->thop) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch->thop) (2024.10.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch->thop) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch->thop) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch->thop) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.11/dist-packages (from torch->thop) (9.1.0.70)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /usr/local/lib/python3.11/dist-packages (from torch->thop) (12.4.5.8)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /usr/local/lib/python3.11/dist-packages (from torch->thop) (11.2.1.3)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /usr/local/lib/python3.11/dist-packages (from torch->thop) (10.3.5.147)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /usr/local/lib/python3.11/dist-packages (from torch->thop) (11.6.1.9)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /usr/local/lib/python3.11/dist-packages (from torch->thop) (12.3.1.170)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch->thop) (0.6.2)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch->thop) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch->thop) (12.4.127)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch->thop) (12.4.127)\n",
            "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch->thop) (3.2.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch->thop) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch->thop) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch->thop) (3.0.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from importlib.metadata import version\n",
        "\n",
        "pkgs = [\n",
        "    \"thop\",\n",
        "    \"torch\",\n",
        "]\n",
        "for p in pkgs:\n",
        "    print(f\"{p} version: {version(p)}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wy-g7Fst1sY3",
        "outputId": "896a5661-ba09-4e9d-d93e-c45f24d4c239"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "thop version: 0.1.1-2209072238\n",
            "torch version: 2.6.0+cu124\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Simple benchmark with fixed batch size\n",
        "forward pass only"
      ],
      "metadata": {
        "id": "tT34Xdmw26gU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!cat /content/previous_chapters.py"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XncszV5w63kw",
        "outputId": "e478bf49-e178-4152-8601-490e69d6d548"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "# Copyright (c) Sebastian Raschka under Apache License 2.0 (see LICENSE.txt).\n",
            "# Source for \"Build a Large Language Model From Scratch\"\n",
            "#   - https://www.manning.com/books/build-a-large-language-model-from-scratch\n",
            "# Code: https://github.com/rasbt/LLMs-from-scratch\n",
            "\n",
            "import tiktoken\n",
            "import torch\n",
            "import torch.nn as nn\n",
            "from torch.utils.data import Dataset, DataLoader\n",
            "\n",
            "\n",
            "class GPTDatasetV1(Dataset):\n",
            "    def __init__(self, txt, tokenizer, max_length, stride):\n",
            "        self.input_ids = []\n",
            "        self.target_ids = []\n",
            "\n",
            "        # Tokenize the entire text\n",
            "        token_ids = tokenizer.encode(txt, allowed_special={\"<|endoftext|>\"})\n",
            "\n",
            "        # Use a sliding window to chunk the book into overlapping sequences of max_length\n",
            "        for i in range(0, len(token_ids) - max_length, stride):\n",
            "            input_chunk = token_ids[i:i + max_length]\n",
            "            target_chunk = token_ids[i + 1: i + max_length + 1]\n",
            "            self.input_ids.append(torch.tensor(input_chunk))\n",
            "            self.target_ids.append(torch.tensor(target_chunk))\n",
            "\n",
            "    def __len__(self):\n",
            "        return len(self.input_ids)\n",
            "\n",
            "    def __getitem__(self, idx):\n",
            "        return self.input_ids[idx], self.target_ids[idx]\n",
            "\n",
            "\n",
            "def create_dataloader_v1(txt, batch_size=4, max_length=256,\n",
            "                         stride=128, shuffle=True, drop_last=True, num_workers=0):\n",
            "    # Initialize the tokenizer\n",
            "    tokenizer = tiktoken.get_encoding(\"gpt2\")\n",
            "\n",
            "    # Create dataset\n",
            "    dataset = GPTDatasetV1(txt, tokenizer, max_length, stride)\n",
            "\n",
            "    # Create dataloader\n",
            "    dataloader = DataLoader(\n",
            "        dataset, batch_size=batch_size, shuffle=shuffle, drop_last=drop_last, num_workers=num_workers)\n",
            "\n",
            "    return dataloader\n",
            "\n",
            "\n",
            "class MultiHeadAttention(nn.Module):\n",
            "    def __init__(self, d_in, d_out, context_length, dropout, num_heads, qkv_bias=False):\n",
            "        super().__init__()\n",
            "        assert d_out % num_heads == 0, \"d_out must be divisible by num_heads\"\n",
            "\n",
            "        self.d_out = d_out\n",
            "        self.num_heads = num_heads\n",
            "        self.head_dim = d_out // num_heads  # Reduce the projection dim to match desired output dim\n",
            "\n",
            "        self.W_query = nn.Linear(d_in, d_out, bias=qkv_bias)\n",
            "        self.W_key = nn.Linear(d_in, d_out, bias=qkv_bias)\n",
            "        self.W_value = nn.Linear(d_in, d_out, bias=qkv_bias)\n",
            "        self.out_proj = nn.Linear(d_out, d_out)  # Linear layer to combine head outputs\n",
            "        self.dropout = nn.Dropout(dropout)\n",
            "        self.register_buffer('mask', torch.triu(torch.ones(context_length, context_length), diagonal=1))\n",
            "\n",
            "    def forward(self, x):\n",
            "        b, num_tokens, d_in = x.shape\n",
            "\n",
            "        keys = self.W_key(x)  # Shape: (b, num_tokens, d_out)\n",
            "        queries = self.W_query(x)\n",
            "        values = self.W_value(x)\n",
            "\n",
            "        # We implicitly split the matrix by adding a `num_heads` dimension\n",
            "        # Unroll last dim: (b, num_tokens, d_out) -> (b, num_tokens, num_heads, head_dim)\n",
            "        keys = keys.view(b, num_tokens, self.num_heads, self.head_dim)\n",
            "        values = values.view(b, num_tokens, self.num_heads, self.head_dim)\n",
            "        queries = queries.view(b, num_tokens, self.num_heads, self.head_dim)\n",
            "\n",
            "        # Transpose: (b, num_tokens, num_heads, head_dim) -> (b, num_heads, num_tokens, head_dim)\n",
            "        keys = keys.transpose(1, 2)\n",
            "        queries = queries.transpose(1, 2)\n",
            "        values = values.transpose(1, 2)\n",
            "\n",
            "        # Compute scaled dot-product attention (aka self-attention) with a causal mask\n",
            "        attn_scores = queries @ keys.transpose(2, 3)  # Dot product for each head\n",
            "\n",
            "        # Original mask truncated to the number of tokens and converted to boolean\n",
            "        mask_bool = self.mask.bool()[:num_tokens, :num_tokens]\n",
            "\n",
            "        # Use the mask to fill attention scores\n",
            "        attn_scores.masked_fill_(mask_bool, -torch.inf)\n",
            "\n",
            "        attn_weights = torch.softmax(attn_scores / keys.shape[-1]**0.5, dim=-1)\n",
            "        attn_weights = self.dropout(attn_weights)\n",
            "\n",
            "        # Shape: (b, num_tokens, num_heads, head_dim)\n",
            "        context_vec = (attn_weights @ values).transpose(1, 2)\n",
            "\n",
            "        # Combine heads, where self.d_out = self.num_heads * self.head_dim\n",
            "        context_vec = context_vec.contiguous().view(b, num_tokens, self.d_out)\n",
            "        context_vec = self.out_proj(context_vec)  # optional projection\n",
            "\n",
            "        return context_vec\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile previous_chapters.py\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "class TransformerBlock(nn.Module):\n",
        "    def __init__(self, cfg):\n",
        "        super().__init__()\n",
        "        self.emb_dim = cfg[\"emb_dim\"]\n",
        "        self.n_heads = cfg[\"n_heads\"]\n",
        "        self.drop_rate = cfg[\"drop_rate\"]\n",
        "        self.attention = nn.MultiheadAttention(self.emb_dim, self.n_heads, dropout=self.drop_rate)\n",
        "        self.ff = nn.Sequential(\n",
        "            nn.Linear(self.emb_dim, self.emb_dim),\n",
        "            nn.ReLU()\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        attn_output, _ = self.attention(x, x, x)\n",
        "        out = self.ff(attn_output)\n",
        "        return out\n",
        "\n",
        "class GPTModel(nn.Module):\n",
        "    def __init__(self, cfg):\n",
        "        super().__init__()\n",
        "        self.vocab_size = cfg[\"vocab_size\"]\n",
        "        self.emb_dim = cfg[\"emb_dim\"]\n",
        "        self.context_length = cfg[\"context_length\"]\n",
        "        self.n_layers = cfg[\"n_layers\"]\n",
        "        self.token_emb = nn.Embedding(self.vocab_size, self.emb_dim)\n",
        "        self.pos_emb = nn.Embedding(self.context_length, self.emb_dim)\n",
        "        self.blocks = nn.ModuleList([TransformerBlock(cfg) for _ in range(self.n_layers)])\n",
        "        self.out = nn.Linear(self.emb_dim, self.vocab_size)\n",
        "\n",
        "    def forward(self, x):\n",
        "        batch_size, seq_len = x.shape\n",
        "        positions = torch.arange(seq_len, device=x.device).unsqueeze(0).expand(batch_size, seq_len)\n",
        "        x = self.token_emb(x) + self.pos_emb(positions)\n",
        "        for block in self.blocks:\n",
        "            x = block(x)\n",
        "        return self.out(x)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cLGS3mBS65gt",
        "outputId": "5383fc80-48e4-4235-e79c-a985e3cab35c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting previous_chapters.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!cat /content/previous_chapters.py"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zLO-HRw07CM7",
        "outputId": "eefc4573-2efe-4a81-f373-6e8d5ec35f7f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "import torch\n",
            "import torch.nn as nn\n",
            "\n",
            "class TransformerBlock(nn.Module):\n",
            "    def __init__(self, cfg):\n",
            "        super().__init__()\n",
            "        self.emb_dim = cfg[\"emb_dim\"]\n",
            "        self.n_heads = cfg[\"n_heads\"]\n",
            "        self.drop_rate = cfg[\"drop_rate\"]\n",
            "        self.attention = nn.MultiheadAttention(self.emb_dim, self.n_heads, dropout=self.drop_rate)\n",
            "        self.ff = nn.Sequential(\n",
            "            nn.Linear(self.emb_dim, self.emb_dim),\n",
            "            nn.ReLU()\n",
            "        )\n",
            "\n",
            "    def forward(self, x):\n",
            "        attn_output, _ = self.attention(x, x, x)\n",
            "        out = self.ff(attn_output)\n",
            "        return out\n",
            "\n",
            "class GPTModel(nn.Module):\n",
            "    def __init__(self, cfg):\n",
            "        super().__init__()\n",
            "        self.vocab_size = cfg[\"vocab_size\"]\n",
            "        self.emb_dim = cfg[\"emb_dim\"]\n",
            "        self.context_length = cfg[\"context_length\"]\n",
            "        self.n_layers = cfg[\"n_layers\"]\n",
            "        self.token_emb = nn.Embedding(self.vocab_size, self.emb_dim)\n",
            "        self.pos_emb = nn.Embedding(self.context_length, self.emb_dim)\n",
            "        self.blocks = nn.ModuleList([TransformerBlock(cfg) for _ in range(self.n_layers)])\n",
            "        self.out = nn.Linear(self.emb_dim, self.vocab_size)\n",
            "\n",
            "    def forward(self, x):\n",
            "        batch_size, seq_len = x.shape\n",
            "        positions = torch.arange(seq_len, device=x.device).unsqueeze(0).expand(batch_size, seq_len)\n",
            "        x = self.token_emb(x) + self.pos_emb(positions)\n",
            "        for block in self.blocks:\n",
            "            x = block(x)\n",
            "        return self.out(x)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# thop’u yükle\n",
        "!pip install thop\n",
        "\n",
        "# Config\n",
        "GPT_CONFIG_124M = {\n",
        "    \"vocab_size\": 50257,\n",
        "    \"context_length\": 1024,\n",
        "    \"emb_dim\": 768,\n",
        "    \"n_heads\": 12,\n",
        "    \"n_layers\": 12,\n",
        "    \"drop_rate\": 0.1,\n",
        "    \"qkv_bias\": False\n",
        "}\n",
        "\n",
        "# Import ve test\n",
        "import sys\n",
        "sys.path.insert(0, '/content')  # Colab’ın dosyayı bulması için\n",
        "from thop import profile\n",
        "from previous_chapters import GPTModel\n",
        "import torch\n",
        "\n",
        "# Modeli oluştur\n",
        "model = GPTModel(GPT_CONFIG_124M)\n",
        "\n",
        "# Örnek giriş tensoru (thop için gerekli)\n",
        "input_tensor = torch.zeros(1, GPT_CONFIG_124M[\"context_length\"], dtype=torch.long)\n",
        "\n",
        "# FLOPs ve parametre sayısını hesapla\n",
        "flops, params = profile(model, inputs=(input_tensor,))\n",
        "print(f\"Total FLOPs: {flops:,}\")\n",
        "print(f\"Total parameters: {params:,}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 859
        },
        "id": "uiC3m8TB7F8U",
        "outputId": "797a4f7a-98cf-4e43-f6ad-1f78b7b09d98"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: thop in /usr/local/lib/python3.11/dist-packages (0.1.1.post2209072238)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.11/dist-packages (from thop) (2.6.0+cu124)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch->thop) (3.17.0)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.11/dist-packages (from torch->thop) (4.12.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch->thop) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch->thop) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch->thop) (2024.10.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch->thop) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch->thop) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch->thop) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.11/dist-packages (from torch->thop) (9.1.0.70)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /usr/local/lib/python3.11/dist-packages (from torch->thop) (12.4.5.8)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /usr/local/lib/python3.11/dist-packages (from torch->thop) (11.2.1.3)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /usr/local/lib/python3.11/dist-packages (from torch->thop) (10.3.5.147)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /usr/local/lib/python3.11/dist-packages (from torch->thop) (11.6.1.9)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /usr/local/lib/python3.11/dist-packages (from torch->thop) (12.3.1.170)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch->thop) (0.6.2)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch->thop) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch->thop) (12.4.127)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch->thop) (12.4.127)\n",
            "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch->thop) (3.2.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch->thop) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch->thop) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch->thop) (3.0.2)\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "ImportError",
          "evalue": "cannot import name 'GPTModel' from 'previous_chapters' (/content/previous_chapters.py)",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-73-911df5bc6767>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minsert\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'/content'\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# Colab’ın dosyayı bulması için\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mthop\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mprofile\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mprevious_chapters\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mGPTModel\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     20\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mImportError\u001b[0m: cannot import name 'GPTModel' from 'previous_chapters' (/content/previous_chapters.py)",
            "",
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"
          ],
          "errorDetails": {
            "actions": [
              {
                "action": "open_url",
                "actionText": "Open Examples",
                "url": "/notebooks/snippets/importing_libraries.ipynb"
              }
            ]
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!ls /content/previous_chapters.py"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wMxf3Ed_7QgQ",
        "outputId": "ecd843c1-3c50-4120-e23c-2ead769f6f82"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/previous_chapters.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from thop import profile\n",
        "\n",
        "from previous_chapters import GPTModel\n",
        "\n",
        "\n",
        "BASE_CONFIG = {\n",
        "    \"vocab_size\": 50257,     # Vocabulary size\n",
        "    \"context_length\": 1024,  # Context length\n",
        "    \"drop_rate\": 0.0,        # Dropout rate\n",
        "    \"qkv_bias\": True         # Query-key-value bias\n",
        "}\n",
        "\n",
        "model_configs = {\n",
        "    \"gpt-small (124M)\": {\"emb_dim\": 768, \"n_layers\": 12, \"n_heads\": 12},\n",
        "    \"gpt-medium (355M)\": {\"emb_dim\": 1024, \"n_layers\": 24, \"n_heads\": 16},\n",
        "    \"gpt-large (774M)\": {\"emb_dim\": 1280, \"n_layers\": 36, \"n_heads\": 20},\n",
        "    \"gpt-xl (1558M)\": {\"emb_dim\": 1600, \"n_layers\": 48, \"n_heads\": 25},\n",
        "}\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "batch_size = 2\n",
        "input_tensor = torch.randint(0, 50257, (batch_size, 1024)).to(device)\n",
        "\n",
        "for size in model_configs:\n",
        "    BASE_CONFIG.update(model_configs[size])\n",
        "\n",
        "    model = GPTModel(BASE_CONFIG).bfloat16()\n",
        "    model.to(device)\n",
        "\n",
        "    # MACS = multiply-accumulate operations\n",
        "    # MACS are typically counted as two FLOPS (one multiply and one accumulate)\n",
        "    macs, params = profile(model, inputs=(input_tensor,), verbose=False)\n",
        "    flops = 2*macs\n",
        "    print(f\"{size:18}: {flops:.1e} FLOPS\")\n",
        "\n",
        "    del model\n",
        "    torch.cuda.empty_cache()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 411
        },
        "id": "RtelSked29FC",
        "outputId": "e23c9ddf-f453-4120-84d2-6f6d9c7d67f8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ImportError",
          "evalue": "cannot import name 'GPTModel' from 'previous_chapters' (/content/previous_chapters.py)",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-71-be59d5c31435>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mthop\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mprofile\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mprevious_chapters\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mGPTModel\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mImportError\u001b[0m: cannot import name 'GPTModel' from 'previous_chapters' (/content/previous_chapters.py)",
            "",
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"
          ],
          "errorDetails": {
            "actions": [
              {
                "action": "open_url",
                "actionText": "Open Examples",
                "url": "/notebooks/snippets/importing_libraries.ipynb"
              }
            ]
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile previous_chapters.py\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "class TransformerBlock(nn.Module):\n",
        "    def __init__(self, cfg):\n",
        "        super().__init__()\n",
        "        self.emb_dim = cfg[\"emb_dim\"]\n",
        "        self.n_heads = cfg[\"n_heads\"]\n",
        "        self.drop_rate = cfg[\"drop_rate\"]\n",
        "        self.attention = nn.MultiheadAttention(self.emb_dim, self.n_heads, dropout=self.drop_rate)\n",
        "        self.ff = nn.Sequential(\n",
        "            nn.Linear(self.emb_dim, self.emb_dim),\n",
        "            nn.ReLU()\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        attn_output, _ = self.attention(x, x, x)\n",
        "        out = self.ff(attn_output)\n",
        "        return out\n",
        "\n",
        "class GPTModel(nn.Module):\n",
        "    def __init__(self, cfg):\n",
        "        super().__init__()\n",
        "        self.vocab_size = cfg[\"vocab_size\"]\n",
        "        self.emb_dim = cfg[\"emb_dim\"]\n",
        "        self.context_length = cfg[\"context_length\"]\n",
        "        self.n_layers = cfg[\"n_layers\"]\n",
        "        self.token_emb = nn.Embedding(self.vocab_size, self.emb_dim)\n",
        "        self.pos_emb = nn.Embedding(self.context_length, self.emb_dim)\n",
        "        self.blocks = nn.ModuleList([TransformerBlock(cfg) for _ in range(self.n_layers)])\n",
        "        self.out = nn.Linear(self.emb_dim, self.vocab_size)\n",
        "\n",
        "    def forward(self, x):\n",
        "        batch_size, seq_len = x.shape\n",
        "        positions = torch.arange(seq_len, device=x.device).unsqueeze(0).expand(batch_size, seq_len)\n",
        "        x = self.token_emb(x) + self.pos_emb(positions)\n",
        "        for block in self.blocks:\n",
        "            x = block(x)\n",
        "        return self.out(x)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZlR54Y-C7a7j",
        "outputId": "3b9a6ebd-fe02-4e0f-cab9-44f34ea71cda"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting previous_chapters.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!cat /content/previous_chapters.py"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ULPyM20n7cWE",
        "outputId": "6af38d94-479d-4809-d97b-a793487acf56"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "import torch\n",
            "import torch.nn as nn\n",
            "\n",
            "class TransformerBlock(nn.Module):\n",
            "    def __init__(self, cfg):\n",
            "        super().__init__()\n",
            "        self.emb_dim = cfg[\"emb_dim\"]\n",
            "        self.n_heads = cfg[\"n_heads\"]\n",
            "        self.drop_rate = cfg[\"drop_rate\"]\n",
            "        self.attention = nn.MultiheadAttention(self.emb_dim, self.n_heads, dropout=self.drop_rate)\n",
            "        self.ff = nn.Sequential(\n",
            "            nn.Linear(self.emb_dim, self.emb_dim),\n",
            "            nn.ReLU()\n",
            "        )\n",
            "\n",
            "    def forward(self, x):\n",
            "        attn_output, _ = self.attention(x, x, x)\n",
            "        out = self.ff(attn_output)\n",
            "        return out\n",
            "\n",
            "class GPTModel(nn.Module):\n",
            "    def __init__(self, cfg):\n",
            "        super().__init__()\n",
            "        self.vocab_size = cfg[\"vocab_size\"]\n",
            "        self.emb_dim = cfg[\"emb_dim\"]\n",
            "        self.context_length = cfg[\"context_length\"]\n",
            "        self.n_layers = cfg[\"n_layers\"]\n",
            "        self.token_emb = nn.Embedding(self.vocab_size, self.emb_dim)\n",
            "        self.pos_emb = nn.Embedding(self.context_length, self.emb_dim)\n",
            "        self.blocks = nn.ModuleList([TransformerBlock(cfg) for _ in range(self.n_layers)])\n",
            "        self.out = nn.Linear(self.emb_dim, self.vocab_size)\n",
            "\n",
            "    def forward(self, x):\n",
            "        batch_size, seq_len = x.shape\n",
            "        positions = torch.arange(seq_len, device=x.device).unsqueeze(0).expand(batch_size, seq_len)\n",
            "        x = self.token_emb(x) + self.pos_emb(positions)\n",
            "        for block in self.blocks:\n",
            "            x = block(x)\n",
            "        return self.out(x)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!ls /content/previous_chapters.py"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h-jF458M7vtp",
        "outputId": "c0956444-76f6-42c0-c65b-a499ce119383"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/previous_chapters.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!cat /content/previous_chapters.py"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6SmmKyfs7wu-",
        "outputId": "74c4ff41-356a-4e78-9765-88196afe5f91"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "import torch\n",
            "import torch.nn as nn\n",
            "\n",
            "class TransformerBlock(nn.Module):\n",
            "    def __init__(self, cfg):\n",
            "        super().__init__()\n",
            "        self.emb_dim = cfg[\"emb_dim\"]\n",
            "        self.n_heads = cfg[\"n_heads\"]\n",
            "        self.drop_rate = cfg[\"drop_rate\"]\n",
            "        self.attention = nn.MultiheadAttention(self.emb_dim, self.n_heads, dropout=self.drop_rate)\n",
            "        self.ff = nn.Sequential(\n",
            "            nn.Linear(self.emb_dim, self.emb_dim),\n",
            "            nn.ReLU()\n",
            "        )\n",
            "\n",
            "    def forward(self, x):\n",
            "        attn_output, _ = self.attention(x, x, x)\n",
            "        out = self.ff(attn_output)\n",
            "        return out\n",
            "\n",
            "class GPTModel(nn.Module):\n",
            "    def __init__(self, cfg):\n",
            "        super().__init__()\n",
            "        self.vocab_size = cfg[\"vocab_size\"]\n",
            "        self.emb_dim = cfg[\"emb_dim\"]\n",
            "        self.context_length = cfg[\"context_length\"]\n",
            "        self.n_layers = cfg[\"n_layers\"]\n",
            "        self.token_emb = nn.Embedding(self.vocab_size, self.emb_dim)\n",
            "        self.pos_emb = nn.Embedding(self.context_length, self.emb_dim)\n",
            "        self.blocks = nn.ModuleList([TransformerBlock(cfg) for _ in range(self.n_layers)])\n",
            "        self.out = nn.Linear(self.emb_dim, self.vocab_size)\n",
            "\n",
            "    def forward(self, x):\n",
            "        batch_size, seq_len = x.shape\n",
            "        positions = torch.arange(seq_len, device=x.device).unsqueeze(0).expand(batch_size, seq_len)\n",
            "        x = self.token_emb(x) + self.pos_emb(positions)\n",
            "        for block in self.blocks:\n",
            "            x = block(x)\n",
            "        return self.out(x)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile previous_chapters.py\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from gpt_1 import MultiHeadAttention, FeedForward, LayerNorm\n",
        "\n",
        "class TransformerBlock(nn.Module):\n",
        "    def __init__(self, cfg):\n",
        "        super().__init__()\n",
        "        self.att = MultiHeadAttention(\n",
        "            d_in=cfg[\"emb_dim\"],\n",
        "            d_out=cfg[\"emb_dim\"],\n",
        "            context_length=cfg[\"context_length\"],\n",
        "            num_heads=cfg[\"n_heads\"],\n",
        "            dropout=cfg[\"drop_rate_attn\"],\n",
        "            qkv_bias=cfg[\"qkv_bias\"])\n",
        "        self.ff = FeedForward(cfg)\n",
        "        self.norm1 = LayerNorm(cfg[\"emb_dim\"])\n",
        "        self.norm2 = LayerNorm(cfg[\"emb_dim\"])\n",
        "        self.drop_shortcut = nn.Dropout(cfg[\"drop_rate_shortcut\"])\n",
        "\n",
        "    def forward(self, x):\n",
        "        shortcut = x\n",
        "        x = self.norm1(x)\n",
        "        x = self.att(x)\n",
        "        x = self.drop_shortcut(x)\n",
        "        x = x + shortcut\n",
        "        shortcut = x\n",
        "        x = self.norm2(x)\n",
        "        x = self.ff(x)\n",
        "        x = self.drop_shortcut(x)\n",
        "        x = x + shortcut\n",
        "        return x\n",
        "\n",
        "class GPTModel(nn.Module):\n",
        "    def __init__(self, cfg):\n",
        "        super().__init__()\n",
        "        self.tok_emb = nn.Embedding(cfg[\"vocab_size\"], cfg[\"emb_dim\"])\n",
        "        self.pos_emb = nn.Embedding(cfg[\"context_length\"], cfg[\"emb_dim\"])\n",
        "        self.drop_emb = nn.Dropout(cfg[\"drop_rate_emb\"])\n",
        "        self.trf_blocks = nn.Sequential(\n",
        "            *[TransformerBlock(cfg) for _ in range(cfg[\"n_layers\"])])\n",
        "        self.final_norm = LayerNorm(cfg[\"emb_dim\"])\n",
        "        self.out_head = nn.Linear(cfg[\"emb_dim\"], cfg[\"vocab_size\"], bias=False)\n",
        "\n",
        "    def forward(self, in_idx):\n",
        "        batch_size, seq_len = in_idx.shape\n",
        "        tok_embeds = self.tok_emb(in_idx)\n",
        "        pos_embeds = self.pos_emb(torch.arange(seq_len, device=in_idx.device))\n",
        "        x = tok_embeds + pos_embeds\n",
        "        x = self.drop_emb(x)\n",
        "        x = self.trf_blocks(x)\n",
        "        x = self.final_norm(x)\n",
        "        logits = self.out_head(x)\n",
        "        return logits"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SJfukhy970Jx",
        "outputId": "5059ded0-b629-40e5-fa22-051efe83f923"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting previous_chapters.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# thop’u yükle\n",
        "!pip install thop\n",
        "\n",
        "# Config\n",
        "GPT_CONFIG_124M = {\n",
        "    \"vocab_size\": 50257,\n",
        "    \"context_length\": 1024,\n",
        "    \"emb_dim\": 768,\n",
        "    \"n_heads\": 12,\n",
        "    \"n_layers\": 12,\n",
        "    \"drop_rate\": 0.1,\n",
        "    \"qkv_bias\": False\n",
        "}\n",
        "\n",
        "# Import ve test\n",
        "import sys\n",
        "sys.path.insert(0, '/content')  # Colab’ın dosyayı bulması için\n",
        "from thop import profile\n",
        "from previous_chapters import GPTModel\n",
        "import torch\n",
        "\n",
        "# Modeli oluştur\n",
        "torch.manual_seed(123)\n",
        "model = GPTModel(GPT_CONFIG_124M)\n",
        "\n",
        "# Örnek giriş tensoru (thop için gerekli)\n",
        "input_tensor = torch.zeros(1, GPT_CONFIG_124M[\"context_length\"], dtype=torch.long)\n",
        "\n",
        "# FLOPs ve parametre sayısını hesapla\n",
        "flops, params = profile(model, inputs=(input_tensor,))\n",
        "print(f\"Total FLOPs: {flops:,}\")\n",
        "print(f\"Total parameters: {params:,}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 859
        },
        "id": "QQqLXJXF8CNf",
        "outputId": "c6f54b65-1a50-4144-b63f-56b38a9a54b5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: thop in /usr/local/lib/python3.11/dist-packages (0.1.1.post2209072238)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.11/dist-packages (from thop) (2.6.0+cu124)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch->thop) (3.17.0)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.11/dist-packages (from torch->thop) (4.12.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch->thop) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch->thop) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch->thop) (2024.10.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch->thop) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch->thop) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch->thop) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.11/dist-packages (from torch->thop) (9.1.0.70)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /usr/local/lib/python3.11/dist-packages (from torch->thop) (12.4.5.8)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /usr/local/lib/python3.11/dist-packages (from torch->thop) (11.2.1.3)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /usr/local/lib/python3.11/dist-packages (from torch->thop) (10.3.5.147)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /usr/local/lib/python3.11/dist-packages (from torch->thop) (11.6.1.9)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /usr/local/lib/python3.11/dist-packages (from torch->thop) (12.3.1.170)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch->thop) (0.6.2)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch->thop) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch->thop) (12.4.127)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch->thop) (12.4.127)\n",
            "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch->thop) (3.2.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch->thop) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch->thop) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch->thop) (3.0.2)\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "ImportError",
          "evalue": "cannot import name 'GPTModel' from 'previous_chapters' (/content/previous_chapters.py)",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-82-d1325c31e5d7>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minsert\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'/content'\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# Colab’ın dosyayı bulması için\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mthop\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mprofile\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mprevious_chapters\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mGPTModel\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     20\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mImportError\u001b[0m: cannot import name 'GPTModel' from 'previous_chapters' (/content/previous_chapters.py)",
            "",
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"
          ],
          "errorDetails": {
            "actions": [
              {
                "action": "open_url",
                "actionText": "Open Examples",
                "url": "/notebooks/snippets/importing_libraries.ipynb"
              }
            ]
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!cat previous_chapters.py\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ea143RqP3N2F",
        "outputId": "592ce752-a3d3-4224-9fd4-3e40c069b0c1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "# Copyright (c) Sebastian Raschka under Apache License 2.0 (see LICENSE.txt).\n",
            "# Source for \"Build a Large Language Model From Scratch\"\n",
            "#   - https://www.manning.com/books/build-a-large-language-model-from-scratch\n",
            "# Code: https://github.com/rasbt/LLMs-from-scratch\n",
            "\n",
            "import tiktoken\n",
            "import torch\n",
            "import torch.nn as nn\n",
            "from torch.utils.data import Dataset, DataLoader\n",
            "\n",
            "\n",
            "class GPTDatasetV1(Dataset):\n",
            "    def __init__(self, txt, tokenizer, max_length, stride):\n",
            "        self.input_ids = []\n",
            "        self.target_ids = []\n",
            "\n",
            "        # Tokenize the entire text\n",
            "        token_ids = tokenizer.encode(txt, allowed_special={\"<|endoftext|>\"})\n",
            "\n",
            "        # Use a sliding window to chunk the book into overlapping sequences of max_length\n",
            "        for i in range(0, len(token_ids) - max_length, stride):\n",
            "            input_chunk = token_ids[i:i + max_length]\n",
            "            target_chunk = token_ids[i + 1: i + max_length + 1]\n",
            "            self.input_ids.append(torch.tensor(input_chunk))\n",
            "            self.target_ids.append(torch.tensor(target_chunk))\n",
            "\n",
            "    def __len__(self):\n",
            "        return len(self.input_ids)\n",
            "\n",
            "    def __getitem__(self, idx):\n",
            "        return self.input_ids[idx], self.target_ids[idx]\n",
            "\n",
            "\n",
            "def create_dataloader_v1(txt, batch_size=4, max_length=256,\n",
            "                         stride=128, shuffle=True, drop_last=True, num_workers=0):\n",
            "    # Initialize the tokenizer\n",
            "    tokenizer = tiktoken.get_encoding(\"gpt2\")\n",
            "\n",
            "    # Create dataset\n",
            "    dataset = GPTDatasetV1(txt, tokenizer, max_length, stride)\n",
            "\n",
            "    # Create dataloader\n",
            "    dataloader = DataLoader(\n",
            "        dataset, batch_size=batch_size, shuffle=shuffle, drop_last=drop_last, num_workers=num_workers)\n",
            "\n",
            "    return dataloader\n",
            "\n",
            "\n",
            "class MultiHeadAttention(nn.Module):\n",
            "    def __init__(self, d_in, d_out, context_length, dropout, num_heads, qkv_bias=False):\n",
            "        super().__init__()\n",
            "        assert d_out % num_heads == 0, \"d_out must be divisible by num_heads\"\n",
            "\n",
            "        self.d_out = d_out\n",
            "        self.num_heads = num_heads\n",
            "        self.head_dim = d_out // num_heads  # Reduce the projection dim to match desired output dim\n",
            "\n",
            "        self.W_query = nn.Linear(d_in, d_out, bias=qkv_bias)\n",
            "        self.W_key = nn.Linear(d_in, d_out, bias=qkv_bias)\n",
            "        self.W_value = nn.Linear(d_in, d_out, bias=qkv_bias)\n",
            "        self.out_proj = nn.Linear(d_out, d_out)  # Linear layer to combine head outputs\n",
            "        self.dropout = nn.Dropout(dropout)\n",
            "        self.register_buffer('mask', torch.triu(torch.ones(context_length, context_length), diagonal=1))\n",
            "\n",
            "    def forward(self, x):\n",
            "        b, num_tokens, d_in = x.shape\n",
            "\n",
            "        keys = self.W_key(x)  # Shape: (b, num_tokens, d_out)\n",
            "        queries = self.W_query(x)\n",
            "        values = self.W_value(x)\n",
            "\n",
            "        # We implicitly split the matrix by adding a `num_heads` dimension\n",
            "        # Unroll last dim: (b, num_tokens, d_out) -> (b, num_tokens, num_heads, head_dim)\n",
            "        keys = keys.view(b, num_tokens, self.num_heads, self.head_dim)\n",
            "        values = values.view(b, num_tokens, self.num_heads, self.head_dim)\n",
            "        queries = queries.view(b, num_tokens, self.num_heads, self.head_dim)\n",
            "\n",
            "        # Transpose: (b, num_tokens, num_heads, head_dim) -> (b, num_heads, num_tokens, head_dim)\n",
            "        keys = keys.transpose(1, 2)\n",
            "        queries = queries.transpose(1, 2)\n",
            "        values = values.transpose(1, 2)\n",
            "\n",
            "        # Compute scaled dot-product attention (aka self-attention) with a causal mask\n",
            "        attn_scores = queries @ keys.transpose(2, 3)  # Dot product for each head\n",
            "\n",
            "        # Original mask truncated to the number of tokens and converted to boolean\n",
            "        mask_bool = self.mask.bool()[:num_tokens, :num_tokens]\n",
            "\n",
            "        # Use the mask to fill attention scores\n",
            "        attn_scores.masked_fill_(mask_bool, -torch.inf)\n",
            "\n",
            "        attn_weights = torch.softmax(attn_scores / keys.shape[-1]**0.5, dim=-1)\n",
            "        attn_weights = self.dropout(attn_weights)\n",
            "\n",
            "        # Shape: (b, num_tokens, num_heads, head_dim)\n",
            "        context_vec = (attn_weights @ values).transpose(1, 2)\n",
            "\n",
            "        # Combine heads, where self.d_out = self.num_heads * self.head_dim\n",
            "        context_vec = context_vec.contiguous().view(b, num_tokens, self.d_out)\n",
            "        context_vec = self.out_proj(context_vec)  # optional projection\n",
            "\n",
            "        return context_vec\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile previous_chapters.py\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "class TransformerBlock(nn.Module):\n",
        "    def __init__(self, cfg):\n",
        "        super().__init__()\n",
        "        self.emb_dim = cfg[\"emb_dim\"]\n",
        "        self.n_heads = cfg[\"n_heads\"]\n",
        "        self.drop_rate = cfg[\"drop_rate\"]\n",
        "        self.attention = nn.MultiheadAttention(self.emb_dim, self.n_heads, dropout=self.drop_rate)\n",
        "        self.ff = nn.Sequential(\n",
        "            nn.Linear(self.emb_dim, self.emb_dim),\n",
        "            nn.ReLU()\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        attn_output, _ = self.attention(x, x, x)\n",
        "        out = self.ff(attn_output)\n",
        "        return out\n",
        "\n",
        "class GPTModel(nn.Module):\n",
        "    def __init__(self, cfg):\n",
        "        super().__init__()\n",
        "        self.vocab_size = cfg[\"vocab_size\"]\n",
        "        self.emb_dim = cfg[\"emb_dim\"]\n",
        "        self.context_length = cfg[\"context_length\"]\n",
        "        self.n_layers = cfg[\"n_layers\"]\n",
        "        self.token_emb = nn.Embedding(self.vocab_size, self.emb_dim)\n",
        "        self.pos_emb = nn.Embedding(self.context_length, self.emb_dim)\n",
        "        self.blocks = nn.ModuleList([TransformerBlock(cfg) for _ in range(self.n_layers)])\n",
        "        self.out = nn.Linear(self.emb_dim, self.vocab_size)\n",
        "\n",
        "    def forward(self, x):\n",
        "        batch_size, seq_len = x.shape\n",
        "        positions = torch.arange(seq_len, device=x.device).unsqueeze(0).expand(batch_size, seq_len)\n",
        "        x = self.token_emb(x) + self.pos_emb(positions)\n",
        "        for block in self.blocks:\n",
        "            x = block(x)\n",
        "        return self.out(x)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B6FfDOnJ8TMU",
        "outputId": "fc121005-2f67-4714-8bb2-b2a7ee98f235"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting previous_chapters.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Config\n",
        "GPT_CONFIG_124M = {\n",
        "    \"vocab_size\": 50257,\n",
        "    \"context_length\": 1024,\n",
        "    \"emb_dim\": 768,\n",
        "    \"n_heads\": 12,\n",
        "    \"n_layers\": 12,\n",
        "    \"drop_rate\": 0.1,\n",
        "    \"qkv_bias\": False\n",
        "}\n",
        "\n",
        "# Import ve test\n",
        "import sys\n",
        "sys.path.insert(0, '/content')  # Colab’ın dosyayı bulması için\n",
        "from previous_chapters_1 import GPTModel\n",
        "import torch\n",
        "\n",
        "# Modeli oluştur\n",
        "torch.manual_seed(123)\n",
        "model = GPTModel(GPT_CONFIG_124M)\n",
        "print(model)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G8VeM0zL8lyL",
        "outputId": "b50bb5c7-ba9b-45b0-cfe6-e4c9d8b61a7e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GPTModel(\n",
            "  (tok_emb): Embedding(50257, 768)\n",
            "  (pos_emb): Embedding(1024, 768)\n",
            "  (drop_emb): Dropout(p=0.1, inplace=False)\n",
            "  (trf_blocks): Sequential(\n",
            "    (0): TransformerBlock(\n",
            "      (att): MultiHeadAttention(\n",
            "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
            "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
            "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
            "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
            "        (dropout): Dropout(p=0.1, inplace=False)\n",
            "      )\n",
            "      (ff): FeedForward(\n",
            "        (layers): Sequential(\n",
            "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
            "          (1): GELU()\n",
            "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
            "        )\n",
            "      )\n",
            "      (norm1): LayerNorm()\n",
            "      (norm2): LayerNorm()\n",
            "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
            "    )\n",
            "    (1): TransformerBlock(\n",
            "      (att): MultiHeadAttention(\n",
            "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
            "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
            "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
            "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
            "        (dropout): Dropout(p=0.1, inplace=False)\n",
            "      )\n",
            "      (ff): FeedForward(\n",
            "        (layers): Sequential(\n",
            "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
            "          (1): GELU()\n",
            "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
            "        )\n",
            "      )\n",
            "      (norm1): LayerNorm()\n",
            "      (norm2): LayerNorm()\n",
            "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
            "    )\n",
            "    (2): TransformerBlock(\n",
            "      (att): MultiHeadAttention(\n",
            "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
            "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
            "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
            "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
            "        (dropout): Dropout(p=0.1, inplace=False)\n",
            "      )\n",
            "      (ff): FeedForward(\n",
            "        (layers): Sequential(\n",
            "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
            "          (1): GELU()\n",
            "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
            "        )\n",
            "      )\n",
            "      (norm1): LayerNorm()\n",
            "      (norm2): LayerNorm()\n",
            "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
            "    )\n",
            "    (3): TransformerBlock(\n",
            "      (att): MultiHeadAttention(\n",
            "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
            "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
            "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
            "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
            "        (dropout): Dropout(p=0.1, inplace=False)\n",
            "      )\n",
            "      (ff): FeedForward(\n",
            "        (layers): Sequential(\n",
            "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
            "          (1): GELU()\n",
            "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
            "        )\n",
            "      )\n",
            "      (norm1): LayerNorm()\n",
            "      (norm2): LayerNorm()\n",
            "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
            "    )\n",
            "    (4): TransformerBlock(\n",
            "      (att): MultiHeadAttention(\n",
            "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
            "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
            "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
            "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
            "        (dropout): Dropout(p=0.1, inplace=False)\n",
            "      )\n",
            "      (ff): FeedForward(\n",
            "        (layers): Sequential(\n",
            "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
            "          (1): GELU()\n",
            "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
            "        )\n",
            "      )\n",
            "      (norm1): LayerNorm()\n",
            "      (norm2): LayerNorm()\n",
            "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
            "    )\n",
            "    (5): TransformerBlock(\n",
            "      (att): MultiHeadAttention(\n",
            "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
            "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
            "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
            "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
            "        (dropout): Dropout(p=0.1, inplace=False)\n",
            "      )\n",
            "      (ff): FeedForward(\n",
            "        (layers): Sequential(\n",
            "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
            "          (1): GELU()\n",
            "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
            "        )\n",
            "      )\n",
            "      (norm1): LayerNorm()\n",
            "      (norm2): LayerNorm()\n",
            "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
            "    )\n",
            "    (6): TransformerBlock(\n",
            "      (att): MultiHeadAttention(\n",
            "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
            "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
            "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
            "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
            "        (dropout): Dropout(p=0.1, inplace=False)\n",
            "      )\n",
            "      (ff): FeedForward(\n",
            "        (layers): Sequential(\n",
            "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
            "          (1): GELU()\n",
            "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
            "        )\n",
            "      )\n",
            "      (norm1): LayerNorm()\n",
            "      (norm2): LayerNorm()\n",
            "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
            "    )\n",
            "    (7): TransformerBlock(\n",
            "      (att): MultiHeadAttention(\n",
            "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
            "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
            "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
            "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
            "        (dropout): Dropout(p=0.1, inplace=False)\n",
            "      )\n",
            "      (ff): FeedForward(\n",
            "        (layers): Sequential(\n",
            "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
            "          (1): GELU()\n",
            "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
            "        )\n",
            "      )\n",
            "      (norm1): LayerNorm()\n",
            "      (norm2): LayerNorm()\n",
            "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
            "    )\n",
            "    (8): TransformerBlock(\n",
            "      (att): MultiHeadAttention(\n",
            "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
            "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
            "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
            "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
            "        (dropout): Dropout(p=0.1, inplace=False)\n",
            "      )\n",
            "      (ff): FeedForward(\n",
            "        (layers): Sequential(\n",
            "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
            "          (1): GELU()\n",
            "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
            "        )\n",
            "      )\n",
            "      (norm1): LayerNorm()\n",
            "      (norm2): LayerNorm()\n",
            "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
            "    )\n",
            "    (9): TransformerBlock(\n",
            "      (att): MultiHeadAttention(\n",
            "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
            "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
            "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
            "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
            "        (dropout): Dropout(p=0.1, inplace=False)\n",
            "      )\n",
            "      (ff): FeedForward(\n",
            "        (layers): Sequential(\n",
            "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
            "          (1): GELU()\n",
            "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
            "        )\n",
            "      )\n",
            "      (norm1): LayerNorm()\n",
            "      (norm2): LayerNorm()\n",
            "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
            "    )\n",
            "    (10): TransformerBlock(\n",
            "      (att): MultiHeadAttention(\n",
            "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
            "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
            "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
            "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
            "        (dropout): Dropout(p=0.1, inplace=False)\n",
            "      )\n",
            "      (ff): FeedForward(\n",
            "        (layers): Sequential(\n",
            "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
            "          (1): GELU()\n",
            "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
            "        )\n",
            "      )\n",
            "      (norm1): LayerNorm()\n",
            "      (norm2): LayerNorm()\n",
            "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
            "    )\n",
            "    (11): TransformerBlock(\n",
            "      (att): MultiHeadAttention(\n",
            "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
            "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
            "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
            "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
            "        (dropout): Dropout(p=0.1, inplace=False)\n",
            "      )\n",
            "      (ff): FeedForward(\n",
            "        (layers): Sequential(\n",
            "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
            "          (1): GELU()\n",
            "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
            "        )\n",
            "      )\n",
            "      (norm1): LayerNorm()\n",
            "      (norm2): LayerNorm()\n",
            "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
            "    )\n",
            "  )\n",
            "  (final_norm): LayerNorm()\n",
            "  (out_head): Linear(in_features=768, out_features=50257, bias=False)\n",
            ")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from thop import profile\n",
        "\n",
        "from previous_chapters_1 import GPTModel\n",
        "\n",
        "\n",
        "BASE_CONFIG = {\n",
        "    \"vocab_size\": 50257,     # Vocabulary size\n",
        "    \"context_length\": 1024,  # Context length\n",
        "    \"drop_rate\": 0.0,        # Dropout rate\n",
        "    \"qkv_bias\": True         # Query-key-value bias\n",
        "}\n",
        "\n",
        "model_configs = {\n",
        "    \"gpt-small (124M)\": {\"emb_dim\": 768, \"n_layers\": 12, \"n_heads\": 12},\n",
        "    \"gpt-medium (355M)\": {\"emb_dim\": 1024, \"n_layers\": 24, \"n_heads\": 16},\n",
        "    \"gpt-large (774M)\": {\"emb_dim\": 1280, \"n_layers\": 36, \"n_heads\": 20},\n",
        "    \"gpt-xl (1558M)\": {\"emb_dim\": 1600, \"n_layers\": 48, \"n_heads\": 25},\n",
        "}\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "batch_size = 2\n",
        "input_tensor = torch.randint(0, 50257, (batch_size, 1024)).to(device)\n",
        "\n",
        "for size in model_configs:\n",
        "    BASE_CONFIG.update(model_configs[size])\n",
        "\n",
        "    model = GPTModel(BASE_CONFIG).bfloat16()\n",
        "    model.to(device)\n",
        "\n",
        "    # MACS = multiply-accumulate operations\n",
        "    # MACS are typically counted as two FLOPS (one multiply and one accumulate)\n",
        "    macs, params = profile(model, inputs=(input_tensor,), verbose=False)\n",
        "    flops = 2*macs\n",
        "    print(f\"{size:18}: {flops:.1e} FLOPS\")\n",
        "\n",
        "    del model\n",
        "    torch.cuda.empty_cache()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-6Md8ye28VNd",
        "outputId": "729a6ec3-ef15-45f1-e958-274aab884df8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "gpt-small (124M)  : 5.1e+11 FLOPS\n",
            "gpt-medium (355M) : 1.4e+12 FLOPS\n",
            "gpt-large (774M)  : 3.2e+12 FLOPS\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Simple benchmark with automatic batch size finding"
      ],
      "metadata": {
        "id": "lEI1Qx5n9Pxv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for size in model_configs:\n",
        "    print(f\"\\nProcessing {size}\")\n",
        "    config = BASE_CONFIG.copy()\n",
        "    config.update(model_configs[size])\n",
        "\n",
        "    min_batch_size = 1\n",
        "    max_batch_size = None\n",
        "    max_possible_batch_size = 4096\n",
        "\n",
        "    while min_batch_size <= max_possible_batch_size:\n",
        "        batch_size = (min_batch_size + max_possible_batch_size) // 2\n",
        "        try:\n",
        "            input_tensor = torch.randint(\n",
        "                0, config[\"vocab_size\"],\n",
        "                (batch_size, config[\"context_length\"]),\n",
        "                device=device\n",
        "            )\n",
        "\n",
        "            model = GPTModel(config).bfloat16().to(device)\n",
        "\n",
        "            # MACS = multiply-accumulate operations\n",
        "            # MACS are typically counted as two FLOPS (one multiply and one accumulate)\n",
        "            macs, params = profile(model, inputs=(input_tensor,), verbose=False)\n",
        "            flops = 2 * macs\n",
        "            print(f\"  Batch size {batch_size}: {flops:.1e} FLOPS\")\n",
        "\n",
        "            # If successful, try a larger batch size\n",
        "            min_batch_size = batch_size + 1\n",
        "            max_batch_size = batch_size\n",
        "\n",
        "            # Clean up\n",
        "            del model, input_tensor\n",
        "            torch.cuda.empty_cache()\n",
        "\n",
        "        except RuntimeError as e:\n",
        "            if \"out of memory\" in str(e):\n",
        "                # Try smaller batch size\n",
        "                max_possible_batch_size = batch_size - 1\n",
        "\n",
        "                # Clean up\n",
        "                try:\n",
        "                    del model, input_tensor\n",
        "                    torch.cuda.empty_cache()\n",
        "                except NameError:\n",
        "                    pass\n",
        "            else:\n",
        "                raise e"
      ],
      "metadata": {
        "id": "dN-LrXF59VIv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Benchmark with automatic batch size finding and Model FLOP Utilization (MFU)\n",
        "Model FLOPs Utilization (MFU) explanation from the PaLM paper\n",
        "We propose a new metric for efficiency that is implementation-independent and permits a cleaner comparison of system efficiency, called model FLOPs utilization (MFU). This is the ratio of the observed throughput (tokens-per-second) relative to the theoretical maximum throughput of a system operating at peak FLOPs. Crucially, the “theoretical maximum” throughput only accounts for the required operations to compute the forward+backward passes, and not rematerialization.\n",
        "\n",
        "\n",
        "\n",
        "![image.png](data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAABIAAAAJeCAYAAADMTH4/AAAMS2lDQ1BJQ0MgUHJvZmlsZQAASImVVwdYU1cbPndkQggQCENG2EsQkRFARggr7I0gKiEJEEaMCUHFjRYrWCcigqOiVRDFDYi4UKtWiuK2juJApVKLtbiV/4QAWvqP5//ynHvfvOc77/m+7547DgD0Lr5UmodqApAvKZDFhQSwJqWkskg9AIE/OtADbnyBXMqJiYkA0IbPf7fXN6AvtKuOSq1/9v9X0xKK5AIAkBiIM4RyQT7EhwDAWwVSWQEARCnkLWYWSJW4HGIdGQwQ4lolzlLhViXOUOHLgz4JcVyIHwNAVufzZVkAaPRBnlUoyII6dJgtcJYIxRKI/SH2zc+fLoR4IcS20AfOSVfqszO+0sn6m2bGiCafnzWCVbkMGjlQLJfm8Wf/n+X435afpxiewwY29WxZaJwyZ1i3x7nTw5VYHeK3koyoaIi1AUBxsXDQX4mZ2YrQRJU/aiuQc2HNABPiifK8eN4QHyfkB4ZDbARxpiQvKmLIpzhTHKz0gfVDK8UFvASI9SGuFcmD4od8Tsqmxw3PeyNTxuUM8c/4ssEYlPqfFbmJHJU+pp0t4g3pY05F2QnJEFMhDiwUJ0VBrAFxlDw3PnzIJ60omxs17CNTxClzsYRYJpKEBKj0sYpMWXDckP+ufPlw7tjJbDEvaghfKchOCFXVCnss4A/GD3PB+kQSTuKwjkg+KWI4F6EoMEiVO04WSRLjVTyuLy0IiFONxe2leTFD/niAKC9EyZtDnCAvjB8eW1gAF6dKHy+RFsQkqOLEq3L4YTGqePB9IAJwQSBgAQVsGWA6yAHijt6mXvhP1RMM+EAGsoAIOA4xwyOSB3sk8BgPisDvEImAfGRcwGCvCBRC/tMoVsmJRzjV0RFkDvUpVXLBE4jzQTjIg/8Vg0qSkQiSwGPIiP8RER82AcwhDzZl/7/nh9kvDAcyEUOMYnhGFn3YkxhEDCSGEoOJdrgh7ot74xHw6A+bC87GPYfz+OJPeELoJDwkXCd0EW5PExfLRkUZCbqgfvBQfTK+rg9uDTXd8ADcB6pDZZyJGwJH3BXOw8H94MxukOUOxa2sCmuU9t8y+OoKDflRnCkoRY/iT7EdPVLDXsNtREVZ66/ro4o1Y6Te3JGe0fNzv6q+EJ7DR3ti32IHsXPYKewC1oo1ARZ2AmvG2rFjSjyy4h4Prrjh2eIG48mFOqPXzJcrq6yk3Lneucf5o6qvQDSrQHkzcqdLZ8vEWdkFLA58Y4hYPInAaSzLxdnFDQDl+0f1eHsVO/heQZjtX7jFvwLgc2JgYODoFy7sBAD7PeAj4cgXzpYNXy1qAJw/IlDIClUcrjwQ4JODDu8+A2ACLIAtzMcFuANv4A+CQBiIBgkgBUyF0WfDdS4DM8FcsAiUgDKwCqwDVWAL2AZqwR5wADSBVnAK/AgugsvgOrgDV083eA76wGvwAUEQEkJDGIgBYopYIQ6IC8JGfJEgJAKJQ1KQdCQLkSAKZC6yGClD1iBVyFakDtmPHEFOIReQTuQ28gDpQf5E3qMYqo7qoMaoNToOZaMcNBxNQKegWegMtAhdgq5AK9EadDfaiJ5CL6LX0S70OdqPAUwNY2JmmCPGxrhYNJaKZWIybD5WilVgNVgD1gKv81WsC+vF3uFEnIGzcEe4gkPxRFyAz8Dn48vxKrwWb8TP4FfxB3gf/plAIxgRHAheBB5hEiGLMJNQQqgg7CAcJpyF91I34TWRSGQSbYge8F5MIeYQ5xCXEzcR9xJPEjuJj4j9JBLJgORA8iFFk/ikAlIJaQNpN+kE6Qqpm/SWrEY2JbuQg8mpZAm5mFxB3kU+Tr5Cfkr+QNGkWFG8KNEUIWU2ZSVlO6WFconSTflA1aLaUH2oCdQc6iJqJbWBepZ6l/pKTU3NXM1TLVZNrLZQrVJtn9p5tQdq79S11e3Vuepp6gr1Feo71U+q31Z/RaPRrGn+tFRaAW0FrY52mnaf9laDoeGkwdMQaizQqNZo1Lii8YJOoVvROfSp9CJ6Bf0g/RK9V5Oiaa3J1eRrztes1jyieVOzX4uhNV4rWitfa7nWLq0LWs+0SdrW2kHaQu0l2tu0T2s/YmAMCwaXIWAsZmxnnGV06xB1bHR4Ojk6ZTp7dDp0+nS1dV11k3Rn6VbrHtPtYmJMayaPmcdcyTzAvMF8r2esx9ET6S3Ta9C7ovdGf4y+v75Iv1R/r/51/fcGLIMgg1yD1QZNBvcMcUN7w1jDmYabDc8a9o7RGeM9RjCmdMyBMb8YoUb2RnFGc4y2GbUb9RubGIcYS403GJ827jVhmvib5JiUmxw36TFlmPqaik3LTU+Y/sbSZXFYeaxK1hlWn5mRWaiZwmyrWYfZB3Mb80TzYvO95vcsqBZsi0yLcos2iz5LU8tIy7mW9Za/WFGs2FbZVuutzlm9sbaxTrZeat1k/cxG34ZnU2RTb3PXlmbrZzvDtsb2mh3Rjm2Xa7fJ7rI9au9mn21fbX/JAXVwdxA7bHLoHEsY6zlWMrZm7E1HdUeOY6FjveMDJ6ZThFOxU5PTi3GW41LHrR53btxnZzfnPOftznfGa48PG188vmX8ny72LgKXapdrE2gTgicsmNA84aWrg6vIdbPrLTeGW6TbUrc2t0/uHu4y9wb3Hg9Lj3SPjR432TrsGPZy9nlPgmeA5wLPVs93Xu5eBV4HvP7wdvTO9d7l/WyizUTRxO0TH/mY+/B9tvp0+bJ8032/9+3yM/Pj+9X4PfS38Bf67/B/yrHj5HB2c14EOAfIAg4HvOF6cedxTwZigSGBpYEdQdpBiUFVQfeDzYOzguuD+0LcQuaEnAwlhIaHrg69yTPmCXh1vL4wj7B5YWfC1cPjw6vCH0bYR8giWiLRyLDItZF3o6yiJFFN0SCaF702+l6MTcyMmKOxxNiY2OrYJ3Hj4+bGnYtnxE+L3xX/OiEgYWXCnUTbREViWxI9KS2pLulNcmDymuSuSeMmzZt0McUwRZzSnEpKTUrdkdo/OWjyusndaW5pJWk3pthMmTXlwlTDqXlTj02jT+NPO5hOSE9O35X+kR/Nr+H3Z/AyNmb0CbiC9YLnQn9hubBH5CNaI3qa6ZO5JvNZlk/W2qyebL/siuxeMVdcJX6ZE5qzJedNbnTuztyBvOS8vfnk/PT8IxJtSa7kzHST6bOmd0odpCXSrhleM9bN6JOFy3bIEfkUeXOBDvzQb1fYKr5RPCj0LawufDszaebBWVqzJLPaZ9vPXjb7aVFw0Q9z8DmCOW1zzeYumvtgHmfe1vnI/Iz5bQssFixZ0L0wZGHtIuqi3EU/FzsXryn+a3Hy4pYlxksWLnn0Tcg39SUaJbKSm0u9l275Fv9W/G3HsgnLNiz7XCos/anMuayi7ONywfKfvhv/XeV3AysyV3SsdF+5eRVxlWTVjdV+q2vXaK0pWvNobeTaxnJWeWn5X+umrbtQ4VqxZT11vWJ9V2VEZfMGyw2rNnysyq66Xh1QvXej0cZlG99sEm66stl/c8MW4y1lW95/L/7+1taQrY011jUV24jbCrc92Z60/dwP7B/qdhjuKNvxaadkZ1dtXO2ZOo+6ul1Gu1bWo/WK+p7dabsv7wnc09zg2LB1L3Nv2T6wT7Hvt/3p+28cCD/QdpB9sOGQ1aGNhxmHSxuRxtmNfU3ZTV3NKc2dR8KOtLV4txw+6nR0Z6tZa/Ux3WMrj1OPLzk+cKLoRP9J6cneU1mnHrVNa7tzetLpa2diz3ScDT97/sfgH0+f45w7cd7nfOsFrwtHfmL/1HTR/WJju1v74Z/dfj7c4d7ReMnjUvNlz8stnRM7j1/xu3LqauDVH6/xrl28HnW980bijVs302523RLeenY77/bLXwp/+XBn4V3C3dJ7mvcq7hvdr/nV7te9Xe5dxx4EPmh/GP/wziPBo+eP5Y8/di95QntS8dT0ad0zl2etPcE9l3+b/Fv3c+nzD70lv2v9vvGF7YtDf/j/0d43qa/7pezlwJ/LXxm82vmX619t/TH991/nv/7wpvStwdvad+x3594nv3/6YeZH0sfKT3afWj6Hf747kD8wIOXL+IOfAhhQbm0yAfhzJwC0FAAYcN9InazaHw4aotrTDiLwn7BqDzlo7gA0wG/62F74dXMTgH3bAbCG+vQ0AGJoACR4AnTChJE2vJcb3HcqjQj3Bt+nfMrIzwD/xlR70q/iHn0GSlVXMPr8L2ZNgxoakAt6AAAAOGVYSWZNTQAqAAAACAABh2kABAAAAAEAAAAaAAAAAAACoAIABAAAAAEAAASAoAMABAAAAAEAAAJeAAAAABvjkXgAAEAASURBVHgB7J0FmF3V1YZ3cIdAKBBcC0GKuwTXBpcQKJRCcdfS4C4p7hCSAEWLuxT34lDghxR3D67zn3eXdbrunnPvXJm5dyb51vNMjm0775Hc/Z211+7VllmQiYAIiIAIiIAIiIAIiIAIiIAIiIAIiIAIjLYExhptz0wnJgIiIAIiIAIiIAIiIAIiIAIiIAIiIAIiEAlIANKNIAIiIAIiIAIiIAIiIAIiIAIiIAIiIAKjOQEJQKP5BdbpiYAIiIAIiIAIiIAIiIAIiIAIiIAIiIAEIN0DIiACIiACIiACIiACIiACIiACIiACIjCaE5AANJpfYJ2eCIiACIiACIiACIiACIiACIiACIiACEgA0j0gAiIgAiIgAiIgAiIgAiIgAiIgAiIgAqM5AQlAo/kF1umJgAiIgAiIgAiIgAiIgAiIgAiIgAiIgAQg3QMiIAIiIAIiIAIiIAIiIAIiIAIiIAIiMJoTkAA0ml9gnZ4IiIAIiIAIiIAIiIAIiIAIiIAIiIAIjCMEIiACIiACIiACItDZBL777rtwzz33hLvvvju8/PLL4fPPPw/TTz996NevX/jtb38bFltssTDzzDN3WO37778fPvroo/Dll1+GL774Inz22Wfh559/DltuuWWHeZWgawgUXZOJJ544rLvuul1TYYtK5X57++23w1dffRXvPbv/Nt100zD55JO3qFWqtlUEHn300XDNNdeEkSNHhu+//z5MN910YcYZZwzrr79+mHfeeWOzLrroonDjjTeGyy+/vFXN7LH1/uc//4nPGc8b/1/wN/fcc8f/K3rsSanhItANCfRqy6wbtktNEgEREAEREAER6IEEfvrpp3D++eeHM844I3z99df5GSAQ+G0ObL311mHXXXcNvXv3ztOlK5tvvnl45JFHSnZPNdVU4fHHHy/Zp43mERg0aFB4+OGHSyqs95qstdZa4a233iopq5GN3/zmN+Guu+5qpIg872mnnRZOOumkfNtWEDWrES8tvZY9mwCCxODBg8P1119f9kTWWGONKErzbNT7LJQtfAw4gKg/55xztjtTxLUhQ4a0268dIiAC9ROQB1D97JRTBERABERABETAEXj99dfDTjvtFF566aW4l47Q/vvvH7/gzjTTTKFXr17h+eefj+LQbbfdFoYNGxauvPLK8Ne//jVsttlmrqT/rfIF+JNPPgmvvPLK/3ZqraUE5plnnvDxxx93yjWxe6WzTui1114LfNvkXmvU8PBYYIEFwrPPPttoUcrfQwkgaPNOe+CBB+IZIFpvtdVW0fsHj5WnnnoqHH300eHWW2+Nfz30NFvebJ5XvEIRg/EwlImACHQdAcUA6jq2KlkEREAEREAExhgCDPP6/e9/n4s//fv3D3feeWfYaKONoreEdcjnm2++cNZZZ4XjjjsussEr6MADDwynn356IauDDz44IBYdccQRhce1s/kE8IbgmtDxbcS++eabkux/+ctf4rBBxL5XX301Ckz77bdfSZodd9wx7rfjdMxpj7dRo0b5zbrXuXevvfbacMstt9RdhjL2bALDhw/PxZ+99tor8D7C+2u88caLw5MGDhwYrrjiioCHo6x+AmONNVYcNvfQQw+FAQMG1F+QcoqACHRIQAJQh4iUQAREQAREQAREoBIBhkhsscUW+RAvvHYQdCrFSdl4443DAQcckBf7t7/9Ldx88835drqy6KKLpru03WICfLFvxIipY3bmmWeG7bbbLuApNvbYYwc6hCz79OljSeKSIV7+eN++fcM222wTLr300jwdsUM604hZJRvzCPz444/h7LPPjieOwLP99tsXQsAj7oYbbig8pp21E1hqqaVqz6QcIiACVROQAFQ1KiUUAREQAREQAREoInDuuefGYVp2DDFnookmss2ySzr8DLExO+SQQ0LqFWLHEARk3YuAeXXV26pPP/00ZsUrbPXVVy8sJr3u6bZlWmKJJfJ7qbMFIOqQh4eRHnOWb7zxRv5em2uuucK4445b9uRnmWWWsPbaa5c9rgPVEyj3jFdfglKKgAhUIqBfU5Xo6JgIiIAIiIAIiEBFAsyS5IdvrbrqqnFoRMVMvx5EQNhtt93ypMT6Oeecc/JtrXRvAo121EyoWXbZZcvG7KlFZFpyySUjMGaKk4lAowR8cPL/+7//i7MPVipzzTXXrHRYx6okUMszX2WRSiYCIuAISAByMLQqAiIgAiIgAiJQGwG8fbxtsMEGfrPD9RVWWKHEu4KZl/zQICtAnQIjMfosTahh2FdnmM3MZeV2RpkqY8wl4AVOYpV1NPPg8ssvP+bC0pmLgAj0GAISgHrMpVJDRUAEREAERKB7Efj2229jkFzfqgUXXNBvdrhOPBfz3LDETzzxhK1Wtfzll1/iUI3vvvuuqvQkIi2zOz344INxJh+8j7AXXnghMJtZJfvyyy/Dv/71r/Doo4+GDz/8sFLS/BjTHKfCFrGT2N8MI54JM7Bxvm+++WZd9dL+zmyvCTXTTjttWQS1CH8mJNnQsqJCuVdGjhwZOTz33HPhhx9+KErW5fvqvR4MkUzvIxqLNxUzVlVrpOceJugu9wXlMnvaww8/HOy6VFuWpSM/93QahBvmtLlW1uRjpq37778/EGS+2vycC+8mM1iXG1pqaYqW008/fcluhqwy61c5m2SSScLW2SxhCy+8cLkk+f56r78VwHvnkUceie354IMPAqyqMRhyvWHKc1BtPsr+/vvv4+x/aT2wrYcv5RS9F9PytS0CItC5BDQNfOfyVGkiIAIiIAIiMMYQePrpp0vOlWnfp5lmmpJ91WzQYbrrrrvypHRCV1pppXyblVQIoKM5dOjQcO+995Z0yhCTmJmHGcmKjI4TM5Bdc8017Q7blN9M80w8otSYnviMM84Il1xySckh4sPssMMO8Q9BC2N6c6a3R1jiDw8C7Prrr4+zCrG0KdB33XXXsMceewQECcqnIznOOP/9iUYHjU4bHSxmwLLOJQG0KZP66HjTkaLTu++++5YMwSPfxRdfHPCssjbEhmT/rLfeenFWoymmmMJ2tVsyvfV1110XxQITyRZZZJGw8sorh/79+7dLX8uOFVdcMbafGECdYf369QtHHnlkmH/++dsVB8OrrroqnHTSSXlcF0tEMGt4LrTQQrar6uXJJ58cxYnxxx8/xojhPkWIgfW6664b1lprrZKyar0eXE+ESkQt4w/78847LwYevu+++6KYZVNncw9zL5W7NtxjxxxzTBQPShqWbRC8nXuSgNxrrLFGerjdNvfc5ptvHsUn3z5mT2PGrPPPPz889thjUXCwzMR62nbbbQP3UDnjnue+GzJkSHjttddKkpHvqKOOCsTkMeOaI2R99NFHOSPazzM5bNiwXKTmPjvhhBNCtUG9Z5999jDrrLPmbeCabrjhhvHdstxyywUC0xP7xxuzhFWyWq+/LwvR6KKLLor3cPosk26zzTYL++yzT5hyyil9trjO9eF6WFBrS8C7i3ctM/ClQix1XXnllVH0sfuLfIhyCGG8wxDB7T2GAEtA9kGDBsXn2upIlzwfXBfuXWbxw2gH13aTTTaJ77M0j7ZFQAQ6j0Cv7EdDW+cVp5JEQAREQAREQATGFAKXXXZZnMLdzpeO9OWXX26bVS+ZapsOo9mcc84Zpxm3bZZ8rSa+kBkdBjpBdDrojNEZpT1mdDTpQPpg1Hg9UAYdaTrKBG2lg4dwMmLEiGCeR0UC0JNPPhmntLfy+dKP4MCU9tZJRUCg00SdfJ2nc5yadbJtacdPOeWUMNlkk4U//vGPtqvdko6ulQlrEwR8QuIxmejw8ccfh0033TRvH6IYM+wgmjGNO4Zoh6DlO9Tsx4vjsMMOy4UyeCM8EAj3nnvuaVc35XQ0RIZya7X03qBNW265ZU3FwIFOKdPLYwgUCGncP3SIjeNOO+0U9txzz8LOK6KSdbr/+c9/5h3/P/3pT+Huu+8ubM+hhx4a/vCHP+TH6rkeMLf7ywpCOEPEoO3cv3Sc8eqwjjjpEEdTEYj7m9n3MAQSnhsE2/feey8gZBmHagUgBImOxBTuG2I8PfPMM8GLCLvvvnvgLzWeYwSsm266KR7i3IitQ9t41sx4Xkzk5ZngefOGmIGnHteMe9POjfcF92+1xnOC8FrOKJvrsdpqq8WlCcBF6eu5/lYOXlkIPHYP8/5CuEG8xavvjjvuiEkZhnbhhReWCOaINdyHsOB6UA5iGGIg9wnG/qOPPjpnyj7uX96LqXHfIa5x7ssss0wUJ03IIS3H9ttvvzRb3EY84l2PqIlxPZZeeul4fewc4oFf/1l//fXje9zv07oIiECDBBCAZCIgAiIgAiIgAiJQK4HMW6Ut64Dmf5lwUmsRMX02/XtehpWXFvTqq6+2S5N1xEuSZUOb2jKvizxdFmC6LfMmyNNkX//jsezLfVv2JT7fz0rW8Wyj/dSfdXxKjr344ottWYcpLzcTg/LjmajUlnVA82MwwSg/G7bSln0lz4/ZuVFP1qkv2Z91aNuyDlpbFmy2LetMtdFGS5919Nqok7rMss58W9bpzNMceOCBMV/W6Y1JMg+pkuNZR86ytmVf4NsyL5A8L+33BovMiyo//uc//7kt8yDIk8A08wzIj9NO2tsVlnlqldTjz6Oa+mi355R5mpVk4zoNHjw4ryMTGUqO24a//pkYabvb/v3vf+d54UBdWSDztswjpS0bMpOnq/d6ZDNRtXGtM8+IknqoK/Nki9fSKsm81vI0mThiu/OlPRtZBz3fZytwsnvulltusd0Vl9wHmSARzzWL5ZXXbfdDJsrk7cvEothejtlfJpa2Kz/zeMqPZwJRnp+EmSiUH+N62PPwzjvvxOcj8yzKj1sdmSjZ5stkf/rst2tEsiPzVmlXrpXvl1n8s7ZsqFuS+7+b9V5/cvO8ZqJn3oZMQCnhkglU+THakwl6eRsyL838WCb+xvdOfjBbyYaPtdFuO49sWGB+OPOoastEojZ/X1k63mHGnwzpO9wfswIzEa7kPco7j/vCLPPSK3kWqYtzlYmACHQuAcUAalBAU3YREAEREAERGFMJMAzLm4+74fd3tM6X+loNzxC+vHubccYZ4xAP23fDDTfEoSS2bV+dGSIx3njj2e64JODr9ttvX7LPNo499tjc+wMPET9UaPLJJw9HHHGEJQ0nnnhi9J6ZcMIJo1cNXgppO/Fi4cs3XkBmeO3gOYT3E1/V8YIwy8SimJa6zPBgWWeddeImX/cZFkM+ho9hDPsybwGGxXmvGbwU9t9///gFn7QMuePP7Oqrr849KvAMYMhc79697XD0LsCLhmEj3d0Y+mYc8DhJhxZynRhmxXlixx9/fJ6+3LllP8XzQ37oIh4TWUc4ZIJZ9LTy91i914P7hGudeqFwT9Fu73HivY3wCPKxeBh2Y/d/nz598vbbCtd3iy22sM2qlgx3m2OOOeK5+rx4hjDcbokllsjbx5BGhifh0WTGcCm8j8zwVCGfGc+VPz+eEYYtYnizDB8+PK737ds3PpO77LJL3LZ/GE6UiVoldeL9wjWvxTKxIw4R7CgP7ceDLxOY2iWt9/pTEF595mHDfZoJliVc/PT0HLf3BN5U3hMHj8h0yNpvfvObknPbe++98/hJ3Cd4CrHPG9cXDyyrh2N4QLHfDBap8Y7iumF4MDIDpA11ZR/nwbsxfV9yTCYCItB5BCQAdR5LlSQCIiACIiACYxSBNC5P9tW3rvMniKk335Hw+/16UZwXjiOgDBgwIE9KrAkzhmBgCAIMQ0iD3SLIZF+dA50iMzrNxKows+FVts2SPCYgsJ15K7HIzXc4GbrBbFUITggt/DEUg460N4anebvzzjv9ZlxHBMOIqeINIY5OoxmxaFLj2iEYmTFEB2NYD50ws5133jkOM7Ftv/RCmN/fXdbffvvt4K+/Fx98Gxl65xkSI6eSIQARp4YOLbPgce0ZfogA4wULK6OR62FlEGPIG9clff6mnnpqn6REALKONwkY8nfBBRfEQOg+A2IJghM8ajXfvnnmmSfe42kZ3POpkHXFFVfkyfw9yzM86aST5sdsBVHJjGGZ3nwb2G/PEMNBGfZFXCGGOdVjiHoMcUR84T7yz7svD+GDYNHcH2aNXH9EHMQjM0QTL8ayHyGQc6Rdp556ai5wZZ5cuZhJexFdioz9DLXDCBDv62NfypVhj178IQ33/XTTTcdqtPT/AgRJH3cNAbrIuEesLUXHtU8ERKBxAuM0XoRKEAEREAEREAERGBMJeKGE8yfQaD2WzqSVdmRrLRORhQClGJ02hB46TXSSLE4K3kH8kZYYFCyZkt57dJCfILbe3n333cKZv/A+srLfeuutPFgzeX1H3YsmE0wwQSg3axqxPegE23kgMFjME8okADeeQcT8mGGGGdiVWzaMLP/Szk46/97DxxJ6DxU6fhgxOrxYgCjQU80Ld5zDvPPOW/ZUEC3MEAvoeBeJOaRhNiQ63dahJVCu9+aycmzZyPWwMugYe+N+TS1trxch6LDTsbY4V4hX/PXv3z/eq1xn4kNx7vVY2r5yZeDNhMhk9xseU3hmwdvHUuLeLLpn/Ux/cPWWnr+/JtTZqCFME+SYP9qbDQ2NQZD/8Y9/5M8+ddBugiPDE2vk+iNAW/wiyvLnxDbG8+/jI/13b8jjfLFNHCbvbWNpbPm73/0uvzeIp4SIZZZe28UXX9wOlSx9Ou8lRyITmC0D9clEQARaQ0ACUGu4q1YREAEREAER6PEEUvGCjgrDH3zg5WpOElHFG8MOGrFUQMpihEQBiEDAzITjBQ46WDY0hq/k5557bt5xow2ILN4YDtKRpV+/fceImYWqNQL2mgBEp5JOs3Vk8RzCGNKSmnWubT/Bozsy62SmnepKM4R1VGarj3tPLDrvXohL2+a9tDiGEIY3WZERANx4cRzvhqKOueVt5HpYGf4e4j4t6sxXOj/KYVihHwrIPgQf/jBEJYbMIWZ2pRE42pjgjYdYkHoBMhTMDwcrao8PKp0eh1H6HkjTNLKN2MR7ij/uB4ZJ8m4xw/vGBCA7VztWy/NYFNzayulomcWnypMUeVPlB7MV/85G9Oaa2P1kS0sP2yLzAlwqAPm2kN+nLSpL+0RABLqOgASgrmOrkkVABERABERgtCZA54cf815QoTNc7gtxORivv/56ySG8WhoxPGu8MT00RkwLZpph+ExRjArOA5HIzzDkY5RwrsyQ1JGlwoHvQPl4HR2VQ+weZjOyji4eJ3hLMKSEddpTFC/Dt5k6iGvDbE+VzDrLCB/e0qEe/phf954Zfn8r141bNW3wAgvpESbS62jlePGHfcRZobM//fTTW5KSZSPXwwry95DtS5cdpWHIH0OuGIaVngNlIYQyxJF7Kx2SmNaVbndUt09vcapsH7GKUgGIYUYdvQfSZ6mWNljdlZb3339/HCrK81P0nFlexIwDDjggxs3i/Yf5d1oj19+/Wym32ueRtN6zMhVkOO7Ns6NO8pZ7Z6TPipVTbj/HvbCceo5a/qJlR+0uyqN9IiAClQlIAKrMR0dFQAREQAREQATKEKDjQ5wNH8eDISa1CEAIMd7LBlGD6akbMQLeevNDnRBUaC9DwximQf3pUKHDDz88Dhcjn49rQceo0bZV6iT5NrMOX6a4Js4MRmwOAt0SD4i2ELcmjc9BOt9mtvG4KBczieOVrDsKO5Xa64/5697ReTCsy5v3iPD7WSfWCl4cTFFtIhMiUDarVYztlKbvzOuRlu23q7m3GOrF/X7vvfeGbMan+GcecJTFfYUXECJoLeYFhI7ypeIT1ykVG2DWyLOWisAdtanoOCxoK++ISgIQeWGPd5XFtvGCViPXPxW5EMtqEVDsvBCNK1l6//MeLmflrnU19x9ldtSWcvVqvwiIQOcQKB1Q3DllqhQREAEREAEREIExhICPFcEpDx06NGTT+VZ99gy58sbMQLV85fZ5bT2bitlW4xIBBKNshsEgrOBdgzcNQYLx9vAdXjp9Niwm9YRIy44Fd/CP/4pdrvNUrghEBjPaxWxAxJzBsumb7VDJkqDU3swDyu8rt556vaSd9XL5uuN+gm2b0Zknbks5S89zttlmK5c0CnIIFibMkZAheghARdbI9bDy/D1k+2pZIoAhJhL8meFua6yxRgxoTCBxBA4838yIjZXysGPllrXc1y+88EJeDGxoD8KsN++94vdXWm+UUVq2lWdePenxdNvfb170aeT6EzPJmxeW/P6i9bnmmivfnc7YmB/4dcW/IxgumXpp+fS1XGvL5+NvIZoaWztebunjWJVLo/0iIAK1EZAAVBsvpRYBERABERABEXAEiGmzww475HvoONrsVPnOMisjR44sCVRKkNoNN9ywTOrqd3uPBma4sWmv8Xggpk7aoUMQIsCyF4Hsi7jF8bDa05gctp8lsYYIEJsGkm6kE8OwIj8UhlmMEIGI11Iu7gwdPz+Tmk0h7dtq64giiGI2A5OvizRpfCbL1xOW6ZTvBO0tZ37oG9fcYi0Vped+wRARud5mzJ7m4w7Z/kauh5XRyD1EGXhdcO+efPLJMYi1lcsSwZUp170IZPe/T9cZ6wwF8uKSzdSF94ifYY+hmpWMoMd4wzXKpVIddgwxOI3jY8f80mYZZJ+fbr2R60+Aei+OMZNZOeNZZcp2e/+sueaaeVI8MysJoIjgZkxl7y0Va+phvuqqq/oiS4anlRzQhgiIQJcTkADU5YhVgQiIgAiIgAiM3gR22mmnkngpxMNIRZaUAB1MZiHyhrhR7TACP2zMl4GHDjNmmW2xxRa2mneALIByfuDXFe/tYx4giCx++McZZ5wRA12nedkeMmRI9BwygcDS+A5UPZ2nTTfd1IrKp3UeOHBgvi9dYUiNF+XwGEJsKzJmMEIUI3g3xpd/3xE/++yzy3ayiZHSnY2ZhhBpzMp1nn/88ceSqa+Zzj01PIjM/PWkw+09PPbaa69Aed4auR5WTjX3TZrGt9PK4TwQNIrMe4x40aEobbrPe4UglnhePi0imbeNNtoo32SqdTOebzyRigyx4oQTTghvv/12yfvCCxwdDfkrKrfSPqZfT4eWpul9e7340sj1513i78dLLrkkH3aY1o83JfGb7P7De9CGcnE9HnrooTRL3Gb2Qv++TkX4au4rCvLp/DrHGBbsRekLL7yQ3e0M79EHH3ww3++vab5TKyIgAg0RkADUED5lFgEREAEREAERQDSgY+KHDyFQeE8cT4nhCHhO+I4ogVZ9fp++aJ38ftgCaRB/fCcSrx4/dbqVw7AvP+W07bcv52z7tiBUWUeKjtKuu+7abpgbefF8okPL1NpmdBr9sA28hNLOkaUtt8STxeq3NL6Dafv8ktnKTPyg80d8EotXY+noqOP5gYDBOZkxVM46a5yvDTmz4ywRhogVY1ZJWLA0tS7p/PnhQuSns1rLEEM8RcxTigDezM7kjTqI+WSCxYABA8Iqq6zik4TPPvusZNvfdwxfIqiyGby233776DnlBZhGrgdl+2tHW9M2keatt95ikZv3SPFtQYR544038nSswMG8bpgyvFoh1grx5XNfcT+lgsnf//73kqndaYf3tMKrzd+HDNFMp4JHqBw8eHCs9sQTT7Tq4zJl5D2NShLWscG7jJhb3lPGF4P4c9ttt8VdnEcaB62R648A7N9HzPyXeubBacSIEdFbiBhVGM8wYri9OxDqvacbabiPEOzNeBbSeEyeK+nSutnHPemfC7/OcWIZ+fcFYtXLL7/Modx4rgnQ7685/0ek9ecZtCICIlAXgV7ZC7utrpzKJAIiIAIiUBMBftwUxTXgyylf+fixlgZ8rKYCppzGvZ9OZfpKJ0Ass/vgbVFrp7Nc3QTXpM10GPhhRrBU2k2HwX8Fpi18ieRLLF9Ae/funRcJC36cW17LRx7K5Xxoe6OxYPIKtdIUAnQ48YDwQ47o+OD+j0cN9wPeN34qdjonp556aomXTVFj8WCxYQQMUyKQLXnpbNPBZ5phyrahGnRi8dbx0x+vvvrqJR04vIOIsfHpp5/Gr84mChEnxXv90B469ohLvjNCeQsuuGDsTNPRwmuCTiB1Pvnkk4FzN2EhPSfaTkfur3/9a3qocBsRinZhiEwIZh0ZnTs6VH7YGqIQQ5x4xohZQ/vwAGJGN2/EhfGeAJtssklgFinOnyDUBNEuZ3TQ/dCocunS/Vw76uSdUY6bzwND3keIPAQ3Lme8d2m/3RsMC2RoDe9F7lWuLUbdxx57bD5FNfcpwwKL2kLdG2+8cdh6661LBL+0DTfffHMuQNVzPbi/8dwo1waG79HZRoAtlwZBErHFM6L9XCOEBZ4tBEw48P8QXmFemEnPqWib+//AAw8sOUQZDPHi+eR5pVyMug855JDI2979lpH3P/f6sEykNaONiKD8f3HjjTfGZ/jQQw/NPWOoFwGm3Plzj3C8Vq8mxEKen9TwrMG7jPPj/z48y+CPcW5sF80IV8/1t7q//PLL2Bb/bsVTj/cXM44RIJ5rh8jmxSLy86x6L0LeowsttFAUcjhHE8rwwOSdZNbR/c87dr311gv77LNPIXvKgcdzzz1nRYbhw4fHe9F2cP/ieYnQC7dynp2Ug8BFu2UiIAKNEdAsYI3xU24REAERqJoAX7vWXXfdsunxmEiHxJRN/OsBfvgvscQSZZPRUeaHND8Uy/2wKpu5zAF+gPbt2zf+aKx2lhY6wvzgN+MrapFnhh1nyRAWZtaR9RwCxNrhRzqeBNzLdLj5wc9fkXFfMLTCi4NF6fw+Ou8MH6BTzDAQH4iXdHSC6JDQ4U87lxynI4FnAcGq6TTxZ4YIsueee7YTfzjOsZtuuimKDZdeemns8CD22Fd/BKODDjooF5wQROmQUh8dUDpZtA0zgaOowxoTFPyDOGECEOdWjcEVkYdzPOecc6J4gxhkghCeP3zxT8UfyqajRacdDyGuJzOn+dne8IZATGKZmg0nS/d3tI0HF5xgZtzK5bEhPqS3IS/l0jJr0lVXXRU76XRq6RB7AQuPDaYd5z3ph+8hSHON7Lr58qkXTzYEeKyovaTxXjD1XA+LKZS2we4hhDzq8O2kXkvPuveYQozhPHluvEcG54AwiAhQq/hDXv/xgXK4X4855pj4vHDcjP+T2O+DJNsxlvDHA80EXIRI/r8wzxs4c88S0NoMAQTz58y6v0cQluo1njfeUzwLPO8Ms+IvNWKYEWOpSPwhbT3X3+pAVOb557rxLGOIi/xh8EIULhK5eGci9PDe5BnmeTZvL/JyPyAGpgGnGWLn7yvSmsGW57Wa95zlYck7n4DQXGO8+eBlxrXl/w1+1/j9HKcdHT3nVo6WIiAClQnIA6gyHx0VAREQgU4jwFdWOoj8iOEHKz/MU+NLGT+CqrXzzjsv/phO09OhY2gCnVKEFL5SE3yTr4j8kErNfjj7/UXt4zgdKX4o0vHBpZzz4QebfV33ZdCxwpMHcYsvhWa4oeMpUm6IEB1TYmvww1TWMwngcUbQXQRD7n06CwwVo+PH/UlHsNJU29WeNR1khr7gZcaX70pTJDO0APGS2XroEDKUgfuWZ46ZwnhmqjE63TxPeJZwTng3pcMmqimn1jTExqCzD7sicatSeZwvrGz4Bm2eYYYZSgSPcvkRdBCwec55NslLRx3PKYSUKaaYInrrTTbZZFEAg2etQ4jK1d3Z++m4cl/y/oLhjDPOGAhk3mxr5HrU01bqw3MLcYbrhPcT9z5DEhEs7JrWUzZ58DyxoVmIEQjB1MlQM/6/QwS156SWe5c28nzz/xbCFPcf/6c0w55++ukouhx33HH5u+q9996L3oJw449ng3cKQzLxBqz23Bq5/v55xMO3X79+VTPhvuf+Ny/bjt6ZXcmZ9wdt4TcE7YAj/BD7uO68V7hX7a/a93NXtllli8DoQEAC0OhwFXUOIiACPY4AP/4Yp8+PHG8EkfXTPvtj6TpfXBF40jKIi1BuemjKYEiDn+2o0nANOrh0Gvhia8IReVPvHdqCJ4ANoaEe4obwRbSSweHyyy/POw6cD8OBahHBKpWvYyIgAiIgAl1PgCFQfODATADq+lpVgwiIgAiIQK0EFAS6VmJKLwIiIAKdQICv53y5w7y7vZ+9qKNqcI1H/LFAr5a+I/EkdRGvlB5vClztGfpi6cyDwOpjyVc7H2uFfZae9XIGB8o3oYh4KNXkK1ee9ouACIiACDSfgB8C1vzaVaMIiIAIiEC1BCQAVUtK6URABESgiwj4WAYMp0hnZylXrQXUJBBpI1aNyzoiFcO9MNzeq7FqyrVybLgIgpBMBERABESgZxHwApCPe9SzzkKtFQEREIHRn4AEoNH/GusMRUAEujmBdDjVdddd12GLiQFAIFpmdykXcLLDQmpMwCwsGIEhqzETdapJa2lqEY0sj5YiIAIiIALNJ8AQXoKMM6U3kw2YEWScocIEf6/2g4bl1VIEREAERKBrCWgWsK7lq9JFQAREoEMCDAVjOmmbTYgf1Ew9W8kb5vbbb4/lMh10Vxg/7G36YptSlqlaMf2g7wriKlMEREAEehYBvH787I6+9RZnjuDoBF2XiYAIiIAIdA8CEoC6x3VQK0RABMZwAkyZawIQs289+uijYemlly5LhQDLxMrBK6fcTFplM1dxAA8jpsrGO8l+yCNIMTU0sYf44d+Rt05Hx4uaUU+eonK0TwREQAREoGsJ8L4+7LDD4v9F4447bv7RghkAbWr6JZZYomsbodJFQAREQARqIiABqCZcSiwCIiACXUNghRVWiD+ibaYt4vuUE4AI/Mx01ltttVWcWrcrRBObWYwf8t6Y5eXjjz/2u8qu19OuevKUbYAOiIAIiIAIdBkBPgpsueWWXVa+ChYBERABEeh8AooB1PlMVaIIiIAI1EyAr6cDBw7M811zzTVh1KhR+bZfsRhB1U4X7/NWu46HUZEtuOCCYZVVVunQ+4e89Yg59cQNKmqn9omACIiACIiACIiACIiACJQSkAdQKQ9tiYAIiEDLCGywwQbh/PPPz+u/9dZbwyabbJJvs0JsHoI/E5dngQUWKDlW78Z9990Xvvzyy/Dtt9+Gr776Kjz00EPh+eefr7m4zhBv6hGNrKFXXXVVXe22/OWWeGetuOKK5Q5rvwiIgAiIgAiIgAiIgAj0CAISgHrEZVIjRUAExgQCc889d+DvpZdeiqd7+eWXtxOAHnvssfD++++HbbfdttOQEOyZvyKrRdRpRLyxoWaNlEHcJIbOdbZ9/vnnEoA6G6rKEwEREAEREAEREAERaDoBCUBNR64KRUAERKCUAAGVzTbffPNw8MEHx02CLb/66qvBZt9i59VXXx2PpVPHx511/rPeeuuFRRddNHz33XfREwghhWl8a7VaxKJay64m/ZFHHhn233//apLmaRCc7M92ptsE25aJgAiIgAiIgAiIgAiIQE8nIAGop19BtV8ERKDHE/AC0Nprr50LQJwYgs9+++0Xz5GYQHi4rLrqqoGp4zvLllxyyXaeRscee2w499xzg3nmVFNX6r3jz6ua/KRJy6g2H+nGH3/8+FdLHqUVAREQAREQAREQAREQgTGFgASgMeVK6zxFQAS6LQEvlPTu3TsgAt10002xvQRj3nvvveP0ujZN/EYbbdTl57LuuutGAaiWilLxphbxyNKmZdRSf3dNO9tss3XXpqldIiACIiACIiACLSbwn//8p8UtUPVjEgEJQGPS1da5ioAIdEsCXgCigQg8JgB98skngSDNBCG+7LLL4lTx/fv37/LzmHHGGWuuIxVvCFhdrf34448xaauHkVXb3lrS6YddLbSUVgREQAREQAREQAREoKsISADqKrIqVwREQASqJJAKQMsuu2yYaqqpAuIPxrAvBBliAhH8mSnjO9PS+il7ookmCuedd15NQ80mmWSSkmZ98803JdvlNvD+ee211+Jh6q3XmMnss88+qzd72Xx9+vSJPMom0AEREAEREAEREAEREAER6AEEJAD1gIukJoqACIxZBMYee+xAMOjTTjstnjgzdJkwwlTxnW1FAhCeOCuvvHJNVS222GJh6NCheZ4XX3wxLLzwwvl2uZUXXnghfP3113FqezvPcmkr7d9nn33CHXfcUSlJXccIkv23v/2trrzKJAIiIAIiIAIiIAIiIALdhYAEoO5yJdQOERCBMZZAkQCz/vrr5wIQYK666qow33zzxWniOxuUxd9ptNyll166pIgHH3wwDBo0qGRf0cZ1110Xd2+66aZFh6veR/7ZZ5+96vTVJlx88cWrTap0IiACIiACIiACIiACItBtCUgA6raXRg0TAREY3QlY3Jvvv/8+9/Cxc55lllkCHjWPP/647QqNCiR5QclKkQCVJKlqc9JJJw0HHHBAYAYx7NZbbw0vvfRSRdHqySefzL2GGp3afqWVVgr8yURABERABERABERABERABNoTGKv9Lu0RAREQARHoSgIffPBBOP7448Ozzz4bq9lll13C66+/HtKgyangw+xgRfbGG2+U7H7nnXdKtv0GYk+avqhun6eW9a233jrOYmZ5dt9991AuCPI999wTttpqq5iUIVadObW91a+lCIiACIiACIiACIiACIjAfwn0yjoDbYIhAiIgAiLQ9QTeeuutsNZaa8V4N+VqO+6448LGG28cDxMXZ/7554/rAwYMCCeffHKeDQHpoosuqljWxBNPHJgxjFhC22+/fXjooYc6TD/BBBOE1VZbLRx11FF5XbWuMKSMtp5++ul51j//+c9hoYUWCr/5zW/CyJEjw4033hhnNyMBga0PPPDAPK1WREAEREAEREAEREAEREAEOp+AhoB1PlOVKAIiIAKFBD7//PMowCDMILR4++677+Ixlmak22abbeIQqYEDB9ruuHzzzTfLlkUCK++nn36K6V999dV26ZlljNnGLD1L9lmeeKCOfwggvddee4XZZpstHHTQQbHec889t11J1H300UeHVVddtd0x7aiPADOvcW8wIxp/n376afjiiy8CwcN79+5dX6HK1WMJ4A3IM829wH3ALHk8d2ussUbV5/TDDz+EDz/8sF36Xr16BQLWU149MxPyPvz2228DgnH6LXL88ceXR2A74o3t4Pq//fbb4auvvor3gt0PeJpOPvnkjRWu3D2OwKOPPhquueaa+EGGYejTTTddnG2U+IPzzjtvPB8+MvGx5vLLL+9x59fqBuP5zDPG88a7jr+55547Du1vddtUvwjIA0j3gAiIgAiIQJcRIM7RvffeG5577rnY+eCHJj+C+IFJjKN06vgua0g3KphZ3fbff/9ObdGRRx4Z1l133Rh3aaeddmpX9gUXXBBWXHHFdvu1o3ECCG4EMkdk2WSTTcIcc8zReKGdVAKeg88//3xJabPOOmu46667SvZV2uDZ5d4qZ4jTtXoMfvTRR2GJJZYoV2RYfvnlw7Bhw8oe744H3nvvveg92ZltYwbCI444olOKxBP0pJNOalfW3XffHWaeeeZ2+7Vj9CSAIDF48OBw/fXXlz1BBOItt9wyTuKAwOtjEZbNpAM5AYbzzznnnPm2rSCuDRkyxDa1FIGWEZAHUMvQq2IREAERGP0J4BmwyiqrxL/R/2yrO0NiQDG8rzONMrEpppgiDrX7v//7v06vozPbOzqVtdtuu+XxvC699NLw1FNPhXHG6R4/r/r16xfvg9dee61u5BNNNFFYcsklA2Iu8cLwKPLGOTOEE4/Fau3aa68tTMpMhxNOOGGsrzBBN94Jl85+rivFc6sVBR4eCyywQH6v1ppf6Xs+Abx7+UDwwAMPxJMhZh9x+Lg38Fjh3YVXLhM48CerjwDekXzgYtj/+++/X18hyiUCXUige/xC6cITVNEiIAIiIAIi0J0IMAzHbKmllgo777xzWHDBBfNhgXyhXWaZZUo6k0888UQ+TINhM3h1nHXWWXkcJSuTjvo//vGP6G6+3HLLlZRhdWrZMYG99947PP300x16yiC8WTB3SkUAQGwp+vrbca2dn8Jm5GMIpq3XWsvss88e/v73v8dsfNleeeWV4zBDX87tt98e+LpdjTHc65JLLmmX9MQTT4xDFdsd6CE77BmkuTPNNFPgHlp66aWjKEuHEHbEYiP4vRmeeXg7cdwENgS1ESNGxCQff/yxJW14udFGGwX+Xn755bDmmms2XJ4K6HkEhg8fnos/DNNmAgozPHP54/8iPBk7W8y0esaEJcPgbdjcHnvsUdHbakzgoXPsfgQ0C1j3uyZqkQiIgAiIwGhMwDqK/Nimo0cnES8LfjTyN9lkk+VikGEgfo8dx9OC4TN0HhGQsNQrA08gypfVR+C+++6LQk5Hufv06dPO82X66afvKFvTjy+yyCKdUicxf2y2PkQOs8suu8xWO1ziZcCwOcRKb7V4EPl83WWdGB9mCGa///3vY3wkmPHs4g3J/eKNoPh2nLhHv/3tb8Ohhx4a9txzz5iMYWWdbdQhG/MIIDCeffbZ8cR51hAji2yeeeYJN9xwQ9Eh7auDgP0fXUdWZRGBLiMgAajL0KpgERABERABEWhPwL7q77PPPrHz1z5FdXvoODK7GpYKQNWVoFRFBBDoquXJNcDjimEUgwYNil96EfO6m+Fh0tm2+eab50USI+SNN97ItyutwAuz2Q4rpe1Jx0zY5Zns27dvVU1HGCoy4q9g3IdpgOyi9LXu6+liW63nq/QhPp/2XptrrrkqBm6fZZZZwtprry1snUCg3DPeCUWrCBGom0Dx/zx1F6eMIiACIiACIiAClQiYALToootWSlbVMdz1MYLqpqYfnimR6rbxUKnF6EwdcsghMVgvMWy6o3WFAISHizcCYXdkzFLHEKf+/fuH7ugp1VH7Kx1nxj2sUnDraq+D9+BjSKhMBBolQDwaM2LEMSSxkmmYYCU61R+r9pmvvkSlFIHGCUgAapyhShABERABERCBqgkg1vAFnqFejRrTN1NW0VARvFNktRGgU3TcccfVlmkMTc1QsNVXXz0/e6aM7qhTSawgjFg0o5uZd8WMM85Y9alV6hxaHCnzLKq6UCUUgQIC/oMA8X06mtmL2FQyERCB0ZOABKDR87rqrERABERABLopAeKfMBV3ZxmxfmodKvLFF1+EejwLmOr8X//6V3j00UfDhx9+WNMp/PLLL2HkyJHhwQcfDEwt/sMPP1Sdn7S+vQyLoS2UWck4zuw2999/fwx+W6lOyjz99NPDK6+8UqnIsseYYWfUqFFlj/sDtOOll16KLF599dVAYO9qDO8xAoI/+eSTJTw6yltJaOgob6XjG264YX6Ye5D7opJdeeWVUbBcaaWVKiWreKxeBhUL7YSD5tk3zTTTdEJpIX9H+NhCacHcRwSE5/7m2eroeUjzd9Z2Pe8F2sp7CK8wbzyHeFPVci7Mlvbwww+HRx55JD7nCJGUC5eORElft18nH+zTZ5NYOrS71nLJx7Xi/cf/AdXkhwXvFJ+W9nz//fe+qVWtpx532223XZz1q1zmSSaZJGydzRK28MILl0uS76/n+ltmzg0ecHnhhRciWzvW0RI2vAvJW+tsWzC0Z9bXw32T3pP+eKV1zoV7QyYC3Z2AZgHr7ldI7RMBERABERitCJxxxhntgjynJ0jA2GqNmVzoANFZ8B19v05Z/ECmbqbgthle8B7adNNN40xkBJouZ5Y3nb2J/DvssEP8K+dxRCf1qquuCieddFK72DpMlXvAAQfEqet93bRx6NCh8Qe6/2FPB48ZrRhuhOAw1VRThcMPP7zdrEZ0HpnGeMiQIe2CORMQ+aijjgoM3TJDmKCN6VdxOkDeOFcLXvzPf/4znHrqqbGTSFuMKR0ShvAUGUMvmGaZINOpIQruv//+YbXVVis5RGwdvJLozFodloA8AwYMCDvuuGMYb7zxbHe7ZXovtEtQ544VVlghCjrWLuL7ENS8yOjk0UknXtIEE0xQcq8Wpff76mUAs2HDhkU244wzTh5zi2eFTh7c6ODut99+cZtAzNzH8LKO/mmnnRaDtPv2FK3ToYbHpJNOWnQ47qvlOqyxxhqBINFFghICyfnnn58H9bUKeR4R1/7yl7+Eaaed1nZXvTz55JOjgAIH3kG0F2GT67vuuuuGtdZaq6SsWt4LdIy33XbbKO7QceeZwQYPHhzjZ+FBxvP30EMP5ff5qquuGvbdd98wxxxzlNRrGwQrps3MvOeN9wLtp32Ikha43KdJ1xFk//rXv8bnGXHb7unjjz8+zup34YUXRuHa6oL1euutF999qbjiy+Y+u/jiiwP3kZVpx8l/8MEH5+8LBARiayFMeEaHHXZYfNddccUV+buDa8F7DC/QaozZ/HhfWPtpCwIuQzmZMZIhycT+8UbbKlkt1z8tB8+2v/3tb4UzAsKW2TF5por+X0Gk59170003lRTLdWcGs1133bXd/7HcX7znYev/T+EDAcN+r7/++nivcB9gBLnfZptt4r1Z1AarmOeDdwzv9AceeCDupv38P0NbeNfIRKC7EZAA1N2uiNojAiIgAiIwWhPo7NgKdDo7Mn7U0sml00Wnis7RzTffHDskCC3PPPNMjM1CJzk1BA0/ZAdRpF+/fnEaejoTiCyIIfzATgMg82Ob4MjmVUM5dLjpfDAjDR0+OiE77bRTnPnIfmgjFvC1PDUC7DLtOj/OORf+6CjQ0bdOGJ0opt61zgE/xGFO2rPOOit60NC5PuWUU2LnhzroTFsbfZ2pUANrE4AYduengLd8CAdFhnh20EEH5Ye22GKLQKfsu+++iwIPLBGY6KTYrF10HmFG2zGOE/eJL+U33nhj7MxxHrfddlvshCAYFFktwkNR/nL7uI8GDhwY+ZHmmmuuifGQioY3WoygaqeLtzobYfDBBx+Eu+++24pqt6SDhj322GPRC6Fdghp2cF9X4y1RbZF49hXN5Edn9Q9/+EN8huhobrbZZoHYU3jV8SwjivA8IjSmcZqK6vYdVMoox2uZZZYpyV7rewGPC7zXUsN7hI424iCCMM8qbeCev+OOO6IgxDIVtHh/IM5gvJMWWmihMOGEE8Zng2eiVsPbpyj+F+9NM9qA8GLvTp5pxGrE7VVWWcWS5UvefwjsJrpwPZgV6t57743PLHl5d1EOgjTCdSpCUxhxs3iHI3CY0QZE+yOOOMJ2VVzyDuBcED29cb/YrF+Uv+KKK0YRmqW9j316W6/1+ls+lk8//XQg0LkJYgwl5frx/w/Tp/MutmvLO88bYpoJUwyT5HrMNtts8X3IfcI7HvEfgWjeeefNs+IhV/R/CsNSqYNz5x5npj6EHP4POvTQQ6NY5O+BvMBsBfFor732yv8f4P8lBHC7d9P/P3xerYtASwlkL36ZCIiACIiACIhANyKQdRLasq+1+V89Tcu+JOf5KYsyMw+UvKh333235HjWacyP2cqLL77YlnUu83TZj3471JZ1mNp8HZl3UX6MlcxLoS3zZsnz3nXXXSXHs459W/b1Pz+e/XDPj5M3+7Heln0hzo8bjzPPPLMt8zQp2Z91HvO8mcdAfmz33Xdvy77Q5scyUSg/xnlxDlj2Y78t6yC0ZUJKfpz62Of/LD15WM86zO3amHkPcLjEsiEKJeWSzwzGdm4sYWKW5su8COxQPK/MKyPPm3VE8mPpSibw5ekyD5H0cE3bmSAVy8qErpgvbX/WgWtXHteA+4/7wSwTXfI2cd5Zp80OlSwbYZB5nbRlQ+zasg5nyb1mnDmOZR3gkrZwDe6888547Usa0+BG5uFVUg/sajHOw+4VeGbCQkn2TPBq22CDDfI02XDNkuO24Z9p7m+zf//733le6uF6nXPOOW2ZV05bJuBYsrZ63gvcA7x/sk5xyTvFzsdff9L6d8exxx6b180Kz57lGz58eMkxNjIRJT9e9Dy2y5Dt4H308ssvt2WeIHleq4N73rOmfv/uI51/pik/G7Jacg4jRozIq+X8jjnmmLweysIyAagtEz8i70xszo9TPteM92LmqZPvzwTMvMxqVzJvlTy/nV/RkvvIno+07Hquv5WRed+UnEMmftmh+E7z9yYMvGXiT972P/7xj22ZgOQPx/8zLD+cMi+j/HgWey9eoyxgf16GnXfmlZj/X0CGTFwrSePf+1ZgJvKU3MeZ6Nhm70TSZJ6v7d45ld7RVq6WItAMAooB1FL5TZWLgAiIgAiIQHMIMPzLAstS43TTTRe8N0bRl+es45V/pd1zzz1Lhmox9MB/fT7xxBNLYuAw5MG8ajIhJg5N8WfK13qGd+DFgPHF19LzZZuvt7vttpvPEocwMIwETwHLl/2Ij8MXSMgXfIZymdE+/xWbr8UMu8D4+px1HuM6gXv5imxeRHFn9g/7/J8fbsF61tlo10bLa0u+Bm+//fa2Gb2TyGfm28e+mWee2Q61CxTuPXzId8IJJ+Rp8b7JOvP5tl/pKg8g6kg9VfiCnxoeNgy7wBuiVku9iWphQF68rH73u98FhtGsvPLKefV4XpjHm91LLBkKwn1DWq59dzE827wnAp536ZAd2DCk0mzvvfduF8PGjtky62zYashE2nwd7we8TPC6y8SmkiGG9bwXuF95/zDcyKa5t8oOPPDAkoDipOU5NyPGizd/n0855ZT+UFxnOJN50bU7WGYH7yO8cPDSwfvFDI8/3hOeNc8+71PvkcM7zrPEU8XeZ5Thz5nzY7in5cf7iT+eU4a7wRsPQW/ck7wXGYpnhvddrcYQTH+PlMvPuzQTWQrj4dRz/a0ehizzTsTg4s8hfU/x7Jrx/vAelEVDM/k/wzyGqMP//4RnD+9dnglvXAM8xvy7PRMf82tD2iLPMIbfmQcT/x/xf5W9T8iDdyTvHH8vsV8mAt2BgASg7nAV1AYREAEREAER6EICzOiCi31qPr4IcUW8MbzJu7AjnqSG+GKdZ44R0Bh7++2345CkuJH94zveto8lHXTf0cu+ivvDUbzx5TM8hB/WCDa0DdEDF3774U0QZzNi4xTFY/HTdDOMoVGjM1fJGJZgHQXOhbgW3ugU09mm08dQmI033jg/TIeFzhodJTpO66yzTn6MFfL6oTFwb5b5zm7mwZBXS2fJ7gPbefXVV8fVaoYkWR5bdhYDZkFCZLRON0M8jjzyyChMmdDI/ePFOWtDd1jecsstuaDAfUSns8jYb+IH54gQUcm4jgw9okNLTBbKvuyyy+Iws6J7u5H3grWDGFDeGNKWmo/bw1Aqb5lHRr7JtUPMQyDzRseb91Ol2Fg+vV8nBpIZglU6tJVjxPn605/+ZMniMC9ilGEEavbvIi/aWAbEDj+sjmG43lJGDN3FEMsY3kqsJBOzfb5q1hH1EPyJv8S72b9jfX6eZd5X3B9mjVx/3gt+GCCCphd9eEYZ2se14/3thSoENzNYlGszApcZ/z8w3Mybv7bs5xp68Yd93Pd8IDHz9xv7GEpG2WaIeUXG+dizWHRc+0SgVQTGaVXFqlcEREAEREAERKA5BBAQisxPDew79KTFa8NbNmSscOYvxBgLnPnWW2/FOCheOKIMH4vBl8n6PPPMk++65557YkeuqONJIt8552s4f2Z0AH38Ejp+fFVPjZg7ZgRl7mojHoUZHgZ4GqRGB7ioE0w6Omv8eaODSQwiYtx4SzvBdiy9tra/kaUvc+21187jclAmgo95qxDMluDQdNp8p76WujuDAfVxv+A5YIIVQgfxTxDo8OAgxlN3NeI8mS277LK56Gn7/BKPJ+toI0qkoqNPS2wePPGsQ0sMqqLYQ5ankfeCleE7/ZxLkUjj3wFpXK20U02nH0EAMYNzR1ghrhh/9Zh/L1bKj7BjsWpIhwcVQi7vFRN92c960bvInzdinTffBi+0s9+/M32eWtYRQhGc+eO9kQ3rikGQeVbtfU55tJtA2pwX1sj19x5mlOUD8bORSTksAABAAElEQVSNce28MPbfvSHGWrL1ouN2jNnLEMbN+4rngLhpZp4r+xZffHE7VLL06fy7jkSpWMc9JxOBnkRAAlBPulpqqwiIgAiIgAjUQaDIE4ZifCcr/ZGbxbwoqcl/WS054DbsS6n3AKGj4Tt8LnlcTQURAmvyA77I/DCM9HgqhjAUzA8HS9Oz7WeDKTre6L4s1keJF1Xfvn3rKpIOGh0vvIkQLGwIRVqY/1KfHuvsbX+/IKwgAlngbUQEhlpwf5lwQTDrRqyzGCCGEiSc2aMwOucICnhYdWfL4vPkzSv3PFsC77HCfcO1KvcMbr311iX3E94NlQSgRt4L1j7fuU6H+BWlsX22xGMDwc4He+Y6MnyPP4z7Dc86z8Lyd7QsxyrN573vOIYAjqViDp5mHVn6TPs2dIbgU6l+nlPEdf64H5h1kMD4ZnifmQDUyPX3Q/kQ7Kq9NniAeUGto3yIQGapB5DnSppynkSV/m/0zyL5fVqrV0sR6M4EJAB156ujtomACIiACIhAJxDwHS5fXLn9pMHDxIwfuVnwZdssuzThphZhJW0DX26tnLQihn+Vs1QAwrWfoW+VrFJ5lfJVeywLBFqS1IYflezsYINhanho+I7XAgssEGMqES+IzmXaeUyL9GJNeqze7bRMOtwmANEevMAYyoGXDfdP//79660qdAYDXzkzx2VBnvNZgfCCQWDqzh05piY3S9nbflv6Ti4dZ/L64Z6WjmV67+C5RWc/jYdleRp5L1gZvn3lmPs0ls8vEYCI6+LjwvjjiL82VCcd9uPTNbJOG3mmjaGxsaWVjZdQOf6WJvWO8+dvQ1wtbT1LhskxYxVtqRSXhuvB0Cs8x+CHvf7663HJP/7cav1/AW9AMx/Ly/aVW6ZDAMulK9rvxZqi4+n/P5am3H6Oe8/RWs6jo+fW6tZSBLqagASgrias8kVABERABESgBQT8j03fmfBNKbefND4GAp1IYmFUa35ogx9yVZSfzre3Sl93K7U37WDR/lra7NtQtM5QiHfeeScGzi7XaU3zpZ0I85BK05XbRvjwnjMIPwRg9R4aTEFtHdBy5fh7oVyaWvenZTKUx3eGGUrC8EDiiBDnqV6xrbMY+PNjOKMX1OjoEsSc+Co9wRgCWMnSZ4qOejlj2BQiIgHhTbhFBLroootCev9SRiPvhaI2lHumy+33ZQwaNChOWc6099xnxLXx15WhTAxH9IGGff5y60XnXZQW0dA/e3aPe0bk++1vfxvmn3/+oiKq2lft+6ZSYbzDaSucKglAlMH5E7TaYtt4cd2fW63/Lxgf6vCCJtuVLBXA0vs7zeufj4685crdZ9XeA76utB3aFoHuSkBBoLvrlVG7REAEREAERKABAnROzMr9yLXjRUtmo/GWTQnsNyuu+5ms6CT4tqQZfQeKY5VmXqrUEUqHY9TSwbA2VfrRz+xWdIzTeCSWt2hJIFcffBsBqVpjOJcfloToc+mll5aIP0VlwfqFF14I/nqlYk1Rvkb3cW0stg5lMYPUueeeG4vNppSuq/jOZGANoPOIBxD3pY8lw5AXYlB1V/PxUrIpxis2M5vyOj+OKOeHxOQHfl0h8DPiKUszxE4EoCJr5L1g5TV6P2ZTrsd7jUDIeM4wuxzCKDFm8DxbffXVraqSYPT5zg5Wqn1fpkHXEWgxYvZ489fD76+07hlVei9VKsMfs/LMq8cfK1r373Av+jRy/W0YGfXx/FUrnqRDZ7/88suiJuf7PG//3OQJ3Eq119plKYlph2hqbH2aovVmDtEtql/7RMAISAAyElqKgAiIgAiIwGhKoJ4fnv7HOlhshpsiRAgbBBO1IJ8rrbRSSTICjJYzYv6YUedMM81km+2WlX5o00nyM5URL6eSnXXWWVFg8WzSzoCvz9YriVBF9eGlYEZAUj+EwvbbcsSIETF2Dm2Ci3lkcHzHHXcsDCBNR8qMNiJiMNuWj7dhxztzaTx8mXiReGMYDnFFvMeSP97RelcwYLYrOsEMSUPU89dn1113bRdYu6M2Nus4M+CZcR9VElUtAC7pmcq7ktn9TGwknmEzprD2sbxsfyPvBSvDP3NF95GlK7fEI4X30YUXXtguyQwzzBADfZsI05FY0K6AGnY88MADJantvYfo4Id7pul8Jq4jMan8rGEc91w8L5+3nnXeD2mMoqJy/LArH3utkeu/4YYbllRl/1+U7Px1g/cXXN54440YK8h7LVmA86J8CN/+o8Imm2xSksxz5UA9bG1GNiu4no8NlldLEWgFAQlAraCuOkVABERABESgiwn4H7Z+3Veb/hj2x+i0+x/dTMP7zTff+CT5+pAhQ6LwYJ1JZkXxM4/5mbDyTNkK3jR+mupyM2FZnnLnYcf9bFkMBSFgcpHRQT7hhBPidPX+63oakNp/obav/elwhKLy/b411ljDb4ahQ4eWbNsGwhBBawlaSpt8J4Y0RTFZmJ3Hp4NPkYeSv86VhANrS6WllV80DIOOYjo9Od4Z9Zo/N8pohAH5EaS43+icc/3hzLAvizmFmLbnnntWFFcopxWGuGZDuWgn3i9FxrAn7+WRdrrJk4qGVg6Bu004YR8xY+x6W5pG3gtWhr8fyz3TPo3ls6UdQ0Ao6nzzjJrnRyNDr6ivXAwZhnPidWTGPWTvPIbA7rDDDnYoEBR95MiR+bZfYagkgavTd6vnYufr8zWyvttuuwUC1Fcy/+704mMj1x+vIoaKmuF1l95fHOMddfDBB0cueFFiDCM147p/9tlntlmy9O3mmngvPxJ6rmyXY+vT+XXyMHOYF/iKhEjSEQPOC/GNvnspUyYCnUFAAlBnUFQZIiACIiACItBJBAi4mX619kEnq6mGuDuffvppnrRo6BE/fH28DL74pj+G8ZawTiedSjwk0sDG/Bi/9tprY6wavCrM8LAxzw8CSDOTjDd+DB9++OF5Z3TAgAFhlVVW8Unij3zfWbVZdkoSuQ2GYNBGMwLFptMv09EaPHhwTELcF290UPxU83wtx/hiTuwMOi+pl1DaEfFfzslLTCM/C9AFF1wQYOON60WHB9t+++3jkrgh3mx2I9tHnjRmDbFt7Fpbx4n03pMIUcULW1ZeR0u8Lggg++yzz8akDE/jXk07Nangw+xgRcaXfW/Wbr+vMxhwrgwZIpC2TU3PNNJTTjllrArR75BDDsmrxbOE+76jYVZ5hipX8EzwzxvZeKbSZ65ccXQ4LaA2aZji3HvPsY97kQC+ZjxfaWys9H71w2VggaeZGe3jfuS+8u1s5L1A2ZRnxr1ZJEb4+4N73b8HfFs431Q84d1nXjd+CKbVWcuSwOaI396454844oiSNiGC+xg3zJpoghBtJ6aOfw4pj/cK5SC6+fcWxzwjno30vUuaeo1nGEHFe4r5shBRbPY+3qnpVOmNXH9ERfs/hXbwHknF5HPOOSc+K+utt15+/+J5xPvHjPan1537lRnMzBDo0vd1eg08Z8vH9fLPhV8nDdf5tNNOs+RxqOvLL7+cb7PC9WKoqf//h/9P0vpLMmlDBJpEoFf2Em1rUl2qRgREQAREQAREICGAOMBQFMx3cpJkcdN+ONOxOO+889olIRgqoke5cuhEXnPNNYEvuuXSUMcll1wSLJ4FP6rxrPE/XImxseCCC0b3fDqlxN+hw5AG3OTrPC74NuQA75Cll146/uCng0bZGF4K/Fg3DyK+DDPFc6U24sGRetdQFp0zOijDhg1jMxpfghmegRhz4403xo4P3jZFHkeIWXRSMFjQkSMP54AIYwLRqaeeGq9BURvJxxAaH/sGPr5zTZsIwMs02MTLsc42QoV5JZ199tklnR68QFZbbbUo7sEIQYH2GMfY6OwfhtHRcaU+hKtybUR02njjjS1b4RLRjaF1RWVYBjpdVg7pzOsCUc+mWyctHThiy1QqC3YIidbBaoTBFltsEY4++mhrZskSEY77GMEu7eBaQtpCAOFUaLPjlZZcU4SlVLwoykM9GKIdHgM+iHqankDHXmRjOAoiBx1ZRFbzmuK8N9tsszx7pWeK+rl+TAHuRdw8868rnJOJurW+FxDU1llnnfxdkJbNu4mOP6KViYxpGtrJ88H7xnvY0CaeDfZzv+NxyPsKwZYyU8++tNx0m6FHqeCKJwn3yxRTTBHf1zYMiWeNQOxFQhNiGyKAHz7LuxsxA2HSngV7r/Du4vlOhUJrH+ePWJS2zY5XWnJv0JbU4IbHJueBsAE73v8Y9bFd5HlX6/X39TK0kHev/Z/Cteddzrnh1cjwXRjxjPJ+9Mb/e8ccc0zcRT68VIkbh5jF/20Y7fb/h7Gvo/ufewXBaZ999in7fqJcxGSz4cOHx/e8bXPfECOJGGxwq3QdGe5bdM9YWVqKQFcSGKcrC1fZIiACIiACIiAClQnwpZsOMT8u+UFbyawzWW42Kb52WlneA4QyyUvnkB/5Pg37MdJb+SbEsB+BATGBH+MEISYvYoZ9IeYHOFMxp+IPeZkil2E3/BjnBzidV/7MEJmYrh2BwdfJtynfRtoNG2srx9KvxlYm5SBs8IOeL/d0COkc2NduONPJ9AGLLS9LPFYYhsUPdOrBewnDe8TEH7bTNrIPszb+d+t//9J5ZLgHwhAdXN8mzo39eAl4o5NLpxYxhM4EHRzr5NBhozOEiITghWcRRkeV8+c8zdMnva/sOpdrq28D95q/Fv5YUTnUSywZhrqlsy8hopUri3KtPO8R0ggDBAvMn7/VYfebDemj3UXPDO2tx+jcct9SblHZvkxrE3V19F0WEZXOPMNOrrjiithZ9vGueJbgv/DCC/sq8vvVs7AEtBOBxt4rRe0ljb8utb4X8Nbg+heVzflb+dyzPg37abMx8nx4VhFkeL+YKMA5kR9hA3G9VvGH/L4O7j/uEWL0mOhDGox3F2JxuTp69+4dRR6GHSJEcU8gBpkghODBu8jeK9TLc17p/FMPw/+2pPp/EeQZAobnEe9w/07xpfAeQbwtEn9IV+v192UjkiC0I5DSBq6xF52Iy8X/KUVC6HbbbReHbPJ+4SMC/794495HXOL96I0hvDxfRfc/9xYeegjv/v1k9x7l2P3ny+TjwLzzzhvftwy99GI315D3Mt5Dfj/5qaNo6JsvW+si0JUE5AHUlXRVtgiIgAiIgAiMRgTonDEcDc8eZhbiy2s6xKTc6fIDmmDQdDIRqpgifPbZZy+XvNP20+nEi4Uf3XQK6HSNP/74HZbP13vif9BW4on06dOnwzzVJkD0o0MCk3nmmSeks9wUlTNq1Kj4ZZk8cCfYrYkYpKdzSVurvR5FdXT3fWJQeoV4lnimeC65p/EqQ3RttjXyXqinrXTMEWkRn+m0M2SW4YgM/YJBNc9TpXoZjoXojeFxhCcd58iQO55bGPMeQXyq1vDuwfPFhhwVPcPVllVPOnghEuOthyckRtwxPM4YYsYfIh3s8BDFw5P3STXWyPVH0IIr71uY8Offa5Xq51ogmCFM8v9Rv379onhWKU9XHePe41lE2LF7EH4I/fwfxL2CN5P9lRMNu6p9KlcEPAEJQJ6G1kVABERABERABERABERABMZYAkUC0BgLQycuAiIw2hFQEOjR7pLqhERABERABERABERABERABOoh4IeA1ZNfeURABESgOxOQANSdr47aJgIiIAIiIAIiIAIiIAIi0DQCDNcy8+u2T0sREAER6MkEFAS6J189tV0EREAEREAEREAEREAERKAhAsTQIpi2n0KeAgmSTBBo4uYwU5pitzSEWZlFQAS6AQHFAOoGF0FNEAEREAEREAEREAEREAERaA0Bph9PZ61LW0KaqaeeOt2tbREQARHoUQTkAdSjLpcaKwIiIAIiIAIiIAIiIAIi0JkEZp555jg1OtN34/HD7GLYL7/8Emd2YijYlFNO2ZlVqiwREAERaAkBeQC1BLsqFQEREAEREAEREAEREAEREAEREAEREIHmEVAQ6OaxVk0iIAIiIAIiIAIiIAIiIAIiIAIiIAIi0BICEoBagl2VioAIiIAIiIAIiIAIiIAIiIAIiIAIiEDzCEgAah5r1SQCIiACIiACIiACIiACIiACIiACIiACLSEgAagl2FWpCIiACIiACIiACIiACIiACIiACIiACDSPgASg5rFWTSIgAiIgAiIgAiIgAiIgAiIgAiIgAiLQEgISgFqCXZWKgAiIgAiIgAiIgAiIgAiIgAiIgAiIQPMISABqHmvVJAIiIAIiIAIiIAIiIAIiIAIiIAIiIAItISABqCXYVakIiIAIiIAIiIAIiIAIiIAIiIAIiIAINI+ABKDmsVZNIiACIiACIiACIiACIiACIiACIiACItASAhKAWoJdlYqACIiACIiACIiACIiACIiACIiACIhA8whIAGoea9UkAiIgAiIgAiIgAiIgAiIgAiIgAiIgAi0hIAGoJdhVqQiIgAiIgAiIgAiIgAiIgAiIgAiIgAg0j4AEoOaxVk0iIAIiIAIiIAIiIAIiIAIiIAIiIAIi0BICEoBagl2VioAIiIAIiIAIiIAIiIAIiIAIiIAIiEDzCEgAah5r1SQCIiACIiACIiACIiACIiACIiACIiACLSEgAagl2FWpCIiACIiACIiACIiACIiACIiACIiACDSPgASg5rFWTSIgAiIgAiIgAiIgAiIgAiIgAiIgAiLQEgISgFqCXZWKgAiIgAiIgAiIgAiIgAiIgAiIgAiIQPMISABqHmvVJAIiIAIiIAIiIAIiIAIiIAIiIAIiIAItISABqCXYVakIiIAIiIAIiIAIiIAIiIAIiIAIiIAINI+ABKDmsVZNIiACIiACIiACIiACIiACIiACIiACItASAhKAWoJdlYqACIiACIiACIiACIiACIiACIiACIhA8whIAGoea9UkAiIgAiIgAiIgAiIgAiIgAiIgAiIgAi0hIAGoJdhVqQiIgAiIgAiIgAiIgAiIgAiIgAiIgAg0j4AEoOaxVk0iIAIiIAIiIAIiIAIiIAIiIAIiIAIi0BICEoBagl2VioAIiIAIiIAIiIAIiIAIiIAIiIAIiEDzCEgAah5r1SQCIiACIiACIiACIiACIiACIiACIiACLSEgAagl2FWpCIiACIiACIiACIiACIiACIiACIiACDSPgASg5rFWTSIgAiIgAiIgAiIgAiIgAiIgAiIgAiLQEgISgFqCXZWKgAiIgAiIgAiIgAiIgAiIgAiIgAiIQPMISABqHmvVJAIiIAIiIAIiIAIiIAIiIAIiIAIiIAItISABqCXYVakIiIAIiIAIiIAIiIAIiIAIiIAIiIAINI+ABKDmsVZNIiACIiACIiACIiACIiACIiACIiACItASAhKAWoJdlYqACIiACIiACIiACIiACIiACIiACIhA8whIAGoea9UkAiIgAiIgAiIgAiIgAiIgAiIgAiIgAi0hIAGoJdhVqQiIgAiIgAiIgAiIgAiIgAiIgAiIgAg0j4AEoOaxVk0iIAIiIAIiIAIiIAIiIAIiIAIiIAIi0BICEoBagl2VioAIiIAIiIAIiIAIiIAIiIAIiIAIiEDzCEgAah5r1SQCIiACIiACIiACIiACIiACIiACIiACLSEgAagl2FWpCIiACIiACIiACIiACIiACIiACIiACDSPgASg5rFWTSIgAiIgAiIgAiIgAiIgAiIgAiIgAiLQEgISgFqCXZWKgAiIgAiIgAiIgAiIgAiIgAiIgAiIQPMISABqHmvVJAIiIAIiIAIiIAIiIAIiIAIiIAIiIAItITBGCkDnnHNOWGyxxeLfBx980BLwqlQEREAEREAEREAEREAEREAEREAEREAEmkVgnGZV1J3qGTVqVPjkk09ik3788cfu1DS1RQREQAREQAREQAREQAREQAREQAREQAQ6ncAY6QHU6RRVoAiIgAiIgAiIgAiIgAiIgAiIgAiIgAh0YwISgLrxxVHTREAEREAEREAEREAEREAEREAEREAERKAzCEgA6gyKKkMEREAEREAEREAEREAEREAEREAEREAEujGBbhsD6Oeffw7ffvttRDfhhBOGscceux1GjpNurLHGChNNNFG74+z46quv4v7xxhsv8FfJ3n///TBy5Mgw22yzhemmm65S0pJj33zzTXjzzTfDRx99FKaYYoowwwwzhN69e5ek8Ruk/+WXX8I444wTJphggniIfc8++2xoa2uLwak55o397777bvz76aefYvtmnHHGQi4+n9ZFQAREQAREQAREQAREQAREQAREQAREoFRl6EY8brzxxrDnnnvGFp1xxhlhzTXXbNe69dZbL7zyyitx/3PPPRcmnnjikjRvvPFGWHHFFeO+HXbYIey3334lx23j4osvDueff34UcWzfVFNNFTbddNOw9957h169etnukuUXX3wRTj755DB8+PCS/WystdZasb6ZZpqp3bElllgifP3112H55ZcPxxxzTNhjjz3C448/nqd77LHHQp8+ffLtu+++O5xwwgnhpZdeyvexMu2004add945DBo0qGS/NkRABERABERABERABERABERABERABETAE+i2Q8CYpt0MQSS19957Lxd/OFaUxosqiy++eFpE3L766qvDwQcfXCL+cIBZws4888xw/PHHF+Zj9rCddtqpUPwhw8033xz+8Ic/hM8++6wwPzsRgXbccccS8SdNfP/994c//elP7cQf0uGxdNBBB4WLLroozaZtERABERABERABERABERABERABERABEcgJdFsPoL59+4ZZZ501vPbaa+G+++7LG2wrDz74oK3GJWnM28cOeFGonACEBw/ePggxiyyySByCdfvtt4ezzz47FnPOOeeElVdeOSy66KJWbEwzePDg8PDDD8d98803X9h4443D/PPPH1599dVw/fXXhwceeCCKSngeIdAUDT974oknYv4555wzrL322oFyEJYmn3zyuP/ll18OW221VV7vNttsE5ZZZpk4bIxzw2sJEemQQw6Jw87S888zakUEREAEREAEREAEREAEREAEREAERGCMJtBtBSCuymqrrRYQYBCB8MhBqDG79957bTUub7vttiiE+J0MncKWXXbZsjGCGDb297//PSDCmC244IJxONmQIUPiLmLzeAHouuuuC1deeWU8Rr5LLrkkTDrppHGbvAxNQ6xBBMIL6fLLLw9bbrmlFV+yRLQ5/fTTA3GOvBHbaPvtt8934Ym00UYb5dtLLbVUbJOVu9tuu4Wnn35aMYFyQloRAREQAREQAREQAREQAREQAREQAREwAt12CBgNRLgxe/LJJ201Bn6+55574va2224blwyHev311+M6/7z11ltRNGK9f//+LAoNkcWLP5Zo4MCBthqDM+cb2cq1116bb5577rm5+GM7CeB82mmn2WYUZvKNZOXoo49uJ/6Q5JlnnsmHpW244YYl4o8VgTcQHkYYnkDEPJKJgAiIgAiIgAiIgAiIgAiIgAiIgAiIQEqgWwtACy+8cN5eP5wLjxwEDwwBxzyD/LAwG15FGoSScva73/2u8NCUU06Z7/fCEp45NiSNemeeeeY8nV9hGJcJS74tPg1D3KaZZhq/K1/350vQ6HKGx5FZGiTa9mspAiIgAiIgAiIgAiIgAiIgAiIgAiIwZhPo1kPAGBbFECmGcnlxh6FVGDF7EGEYKnbppZcGvIJsRiwTUDg+11xzlb3K5QQcMjDLFp5F3j799NN8k2FpPlh1fuDXFY5jTBE/atSoMNlkk/165L+L6aefvmTbb3zwwQf5JrOXHXfccfm2X7E62Pf888/H2cf8ca2LgAiIgAiIgAiIgAiIgAiIgAiIgAiIQLcWgLg8DN9CAMK75fPPPw9TTDFFuOuuu+KVW2mlleJyhRVWiAIQ+7///vsw/vjjRzGIg6uuumrZadw5PtZYtTlBIeR48wKM35+uf/jhh+0EoDSN305nD6umnnfffdcXoXUREAEREAEREAEREAEREAEREAEREAERiAS6vQDkh2899dRTgSFPDAHDlltuubhccskl45J/iBU0yyyz5J47yy+/fH6sM1ZSL56hQ4eWLfaHH37IZ/+q5O1TVEDv3r3z3XvttVecISzfkaxYPXgsyURABERABERABERABERABERABERABEQgJdDtBaDZZpstH4rFjFrffvttPAdm7+rXr19cR5RBBHrkkUfC/fffHz7++OP8PL04lO9sYMXHBmJ4GR5KXWFTTz11Xmzfvn27rJ68Eq2IgAiIgAiIgAiIgAiIgAiIgAiIgAiMtgRqG//UIgzE+MGI/WMBmNdee+2S4Vsrr7xyTMMwMIv/s9BCC8UhY/FAJ/0z9thjB6ZgxxiW9corr5QtGSHqnXfeyb2RyiYsOOBjC6VT3vvkeP9QB3/ffPONP6R1ERABERABERABERABERABERABERABEYgEeoQAZEO9CHJ80003xYannjeWBkHGpmm3GEGdfa3XX3/9vMjtttuuxOPIDhCzaPHFF4/D1CwwtR2rZskMaDak64YbbggXXHBBu2y//PJLGDx4cKyD868kFLXLrB0iIAIiIAIiIAIiIAIiIAIiIAIiIAJjDIFuPwSMK4GQYmbTv5sXju1nynWGZOGVY2l8/CBL1xnLDTfcMHoZXXXVVXGGr4022iiss846cUYwRBmGqp199tl5Vbvssku+Xu0KnkaIPng6YUcddVR4+umnw7LLLhuYPv7tt98OI0aMyOMhzTTTTDHgdbXlK50IiIAIiIAIiIAIiIAIiIAIiIAIiMCYQ6BHCECTTjppHuOHS8PwqMknn7zkKvXq1SuKJYgiGDGC5p9//pI0nbVBXQgyzOzFkDSmeT/zzDMLi99xxx2D9xgqTFRm5zzzzBMuuuiisOWWW8YUeD+ZB5TPgvA1fPjwMM44PeJy+qZrXQREQAREQAREQAREQAREQAREQAREoAkEesQQMDj4IV8W7yflw3TwZqTBi6bIvFBSLg35xhtvvJh93HHHbVcM+04//fSAwIPYlBoiFeLNvvvumx7Kt3078p3JCl5MF198cRTAkkOx3t122y3cfvvtYeaZZ04Pa1sEREAEREAEREAEREAEREAEREAEREAEIoFebZmJRWMEfv755+gN9Omnn4YJJ5wwMOX7+OOP31ihBblHjRoVA0ozzKxPnz7xryCZdomACIiACIiACIiACIiACIiACIiACIhACQEJQCU4tCECIiACIiACIiACIiACIiACIiACIiACox+BHjMEbPRDrzMSAREQAREQAREQAREQAREQAREQAREQgeYQkADUHM6qRQREQAREQAREQAREQAREQAREQAREQARaRkACUMvQq2IREAEREAEREAEREAEREAEREAEREAERaA4BCUDN4axaREAEREAEREAEREAEREAEREAEREAERKBlBCQAtQy9KhYBERABERABERABERABERABERABERCB5hCQANQczqpFBERABERABERABERABERABERABERABFpGQAJQy9CrYhEQAREQAREQAREQAREQAREQAREQARFoDgEJQM3hrFpEQAREQAREQAREQAREQAREQAREQAREoGUEJAC1DL0qFgEREAEREAEREAEREAEREAEREAEREIHmEJAA1BzOqkUEREAEREAEREAEREAEREAEREAEREAEWkZAAlDL0KtiERABERABERABERABERABERABERABEWgOAQlAzeGsWkRABERABERABERABERABERABERABESgZQQkALUMvSoWAREQAREQAREQAREQAREQAREQAREQgeYQkADUHM6qRQREQAREQAREQAREQAREQAREQAREQARaRkACUMvQq2IREAEREAEREAEREAEREAEREAEREAERaA4BCUDN4axaREAEREAEREAEREAEREAEREAEREAERKBlBCQAtQy9KhYBERABERABERABERABERABERABERCB5hCQANQczqpFBERABERABERABERABERABERABERABFpGQAJQy9CrYhEQAREQAREQAREQAREQAREQAREQARFoDgEJQM3hrFpEQAREQAREQAREQAREQAREQAREQAREoGUEJAC1DL0qFgEREAEREAEREAEREAEREAEREAEREIHmEJAA1BzOqkUEREAEREAEREAEREAEREAEREAEREAEWkZAAlDL0KtiERABERABERABERABERABERABERABEWgOAQlAzeGsWkRABERABERABERABERABERABERABESgZQQkALUMvSoWAREQAREQAREQAREQAREQAREQAREQgeYQkADUHM6qRQREQAREQAREQAREQAREQAREQAREQARaRkACUMvQq2IREAEREAEREAEREAEREAEREAEREAERaA4BCUDN4axaREAEREAEREAEREAEREAEREAEREAERKBlBCQAtQy9KhYBERABERABERABERABERABERABERCB5hCQANQczqpFBERABERABERABERABERABERABERABFpGQAJQy9CrYhEQAREQAREQAREQAREQAREQAREQARFoDgEJQM3hrFpEQAREQAREQAREQAREQAREQAREQAREoGUEJAC1DL0qFgEREAEREAEREAEREAEREAEREAEREIHmEJAA1BzOqkUEREAEREAEREAEREAEREAEREAEREAEWkZAAlDL0KtiERABERABERABERABERABERABERABEWgOAQlAzeGsWkRABERABERABERABERABERABERABESgZQQkALUMvSoWAREQAREQAREQAREQAREQAREQAREQgeYQkADUHM6qRQREQAREQAREQAREQAREQAREQAREQARaRkACUMvQq2IREAEREAEREAEREAEREAEREAEREAERaA4BCUDN4axaREAEREAEREAEREAEREAEREAEREAERKBlBCQAtQy9KhYBERABERABERABERABERABERABERCB5hCQANQczqpFBERABERABERABERABERABERABERABFpGQAJQy9CrYhEQAREQAREQAREQAREQAREQAREQARFoDgEJQM3hrFpEQAREQAREQAREQAREQAREQAREQAREoGUExmlZzapYBERABERABERABERABESgRxH44Ycfwocfftiuzb169Qpjjz12mGqqqcK4447b7nhHOz7//PPw7bffhl9++SW0tbWVJB9//PHD1FNPXbKvO2/8/PPPAU6dYbAcZ5z/dtk+++yzWO4EE0wQGcPcG9x++umn8P3334cff/wx9O3b1x+ua/3TTz8Nt9xyS3jkkUfCyJEjY9lzzDFHmGeeecJcc80Vll566TDFFFN0WPYHH3wQ29RhwiwB58XfhBNOGHr37l1NFqVpgMDrr78errjiivDMM88E7rFpp502/q288sphxRVXDGONNVZ4+umnw9577x0uvvjiMN100zVQ25iX9f333w8fffRR+PLLL8MXX3wRGU888cRh3XXXbQmMXtmLovQN25JmqFIREAEREAEREAEREAEREIHuTuC5556r2HEZOHBgOOqoo2o6DTpHSyyxRNk8yy+/fBg2bFjZ493tAILJzjvv3CnN8jwPPfTQMGLEiKrKpYPJtarXEAKOPfbYcOWVV5YUgcD3ySef5PuoZ9999w20s5Lwt/HGG4cnnngiz1ftCvUtt9xyYdCgQWGRRRapNpvSVUEAGeCcc84Jxx9/fNnUc845Z7wP9txzz/Dmm2+GO++8M8w222xl0+tAewLcuw8//HDJAe7rxx9/vGRfszbkAdQs0qpHBERABERABERABERABHo4gYkmmigsueSS0ZsDzwEvBnBql156aTjwwAMDwkC1du211xYmnW+++aIXCPX1JMNzZaaZZgpff/11Oz52HnQAvX333Xcxvd/H+ltvvZXvoszFFlsseuE8++yz+X5boczpp58+4DE188wz2+6al/fcc0/Ydddd8/YstNBCYccddwwLLrhg6NOnT/QyeuCBB8IxxxwTXnnllYAwNXTo0DBkyJCyIs28884bPUnwgnjppZfatYk6zNMJLzA8j1577bXIj/uDvwEDBoTjjjsunl+7ArSjZgKnnXZaOPnkk2O+pZZaKvzlL38JCD54az3//PPhlFNOidd3ww03rLlsZfgfAbzlPv7448jyf3tbtyYPoNaxV80iIAIiIAIiIAIiIAIi0GMJMNSJYSJ4BnhDCFh//fX9rrLreCEwzCQt48QTTwwbbLBB2Xw95QBD2xZeeOGS5iKaMFwuNYZvMdRm+PDh4aabboqHEX0QZFJjuI5nvOyyy8Z86bCwNF9H29ddd13A28Nsl112CbvvvnthexlqduSRR4ZLLrnEkoeLLrooLLPMMvl20QrDiA4++OD80BFHHBE9fPIdv64gRFx44YXh3HPPzQ/hBXT++eeHySefPN+nldoJICCut956MSPiD9eNoV7eGK60zTbbhKeeeirfLQ+gHEXNK5dddlkUx8nYSg+g0qtc82kogwiIgAiIgAiIgAiIgAiIwJhIABHDYvMgVJjR0anW6Fwi/qRePrV4EFVbVyvSER/HnwvrReIPbcMDZtFFFw14ZtDxxmCD0JbaJJNMUrJrsskmi3FzSnbWuIEo4MWfzTbbLOy1115l24unEd4/iIBmW265ZTsxz47ZMvV+wmOqyKaZZppwwAEHlLSJYWRnnXVWUXLtq4HAeeedl6eGcSr+cBCRDWEITzxZ4wTw3usOJgGoO1wFtUEEREAEREAEREAEREAEejCBzTffPG89sS3eeOONfLvSyj/+8Y94mBgxsv8R2GOPPXLhiOEjXW14YuGJY4ZI4710bH+6RMxKY8gwNKwWKxIffP5tt93Wb0aPILxTZPUT8F5lDPsqZwz53HTTTcsd1v4aCDTqnVdDVRWTSgCqiEcHRUAEREAEREAEREAEREAEOiLw+9//viQJQ4k6sm+++SbGDOrfv3+MXdNR+jHpOB4+K6ywQjzl9957r8NTb7RzSeBqH6R5p512Csw2Vo0xU9ef//znPOltt90WHnzwwXy70RU8hFKvoTvuuKPRYsfY/KNGjcrjOwGBWF6VbJVVVql0WMeqJNCR0FllMQ0nkwDUMEIVIAIiIAIiIAIiIAIiIAJjNgGGgq2++uo5BIaOFA1dyhNkK7fffnvc3GijjfzuMXKdwMiIMJ6ZDRmpRgBqBBpT1hPLx1sq6PljRetp+hNOOKEoWd37ppxyypK8iBiy+gikQxDtOSxXGkPxNANbOTo9b78EoJ53zdRiERABERABERABERABEeh2BPxsQcwO9uijj1ZsI1OMExNnpZVWqpiu3EHEEmbJYorlF198MSBk9FS7/vrr49Tx//nPf/JTmGOOOeJ6VwtABJ5+//3383pnnXXWONtXvqOKlbnnnrskFfGECIBdjVXjvcSsYN6IeVRkzKZG3XggEV/KZql74YUXOvR0KSrP9n377bdxZjLbtiWzmuHJVqsR4Jo2wp4yqjHu76+++ipPyrA98jJrWi3GM+fjUjETmA/kXVTWwIEDwwILLFCSryjdjz/+GGcQ49zKxa8qymf7OB+u2yOPPBLzExi9GoPByJEjI9PnnnuupncB75HPPvsszm7n6+Jcqr2HfT5bZ5iiF3Rtf6uX47S6AapfBERABERABERABERABESg5xNgyBIdS6Y/x4jvs/TSSxeeGJ1DhJutttoqDjWqRgSwgh566KFw0kknlQxZsmMErN1uu+1C6pHC8fvvvz8MGzYsjDfeeDHgsnlC0JGmE89U58zYtd9++8VtghyThrbRGaRDR4Bm4qJ0ttF5TW3++eeP8W4QZDqyRoaX0Nn2RiDqWg1OzETG9PBm//rXv0JnDB+ic25CjpVNXd4+/PDDOEX8Nddc43fHdYQLRCHutUMOOaTd8aIdeERxnyEAmDjGMLR77703MIvZXXfdFf7973/n9zoeMsTBYmatSvcy7WCGO8+J+gmifuCBB4bVVlstb861114bhg4dGqcQtzZwkOvFzGgMs4QL7Tr88MPDmmuumeftaIV2etHnoIMOCjfffHMM6I3nWb9+/UqCfzMjX6VZ+Xh+4MLzYc+/tYG6iCdFQPRy9s9//jNeP2bIS41ZymhfKjKSDlHsqquuiu+D9B7hPAhwvdBCC5UUSYyyo446Kl5b8lh7EWFhSRB70thzwTuNGGW77bZbxXOgkltvvTVeF+59aw/3BoHSGeraHUwCUHe4CmqDCIiACIiACIiACIiACPRwAuOOO27AU4BpujE643S4i7w1LEaQn8q8mtN//vnnwxZbbJEnpTNNrBrEJDrMHGfacoa1nHLKKSWzG+F1cffdd+d505VNNtkk7nrsscc6nMkqzdvINmJYUUwbuFUroFQSHTpqm/c6Iu3000/fUZbC43379i3ZTwe62vaXZEw2GE7obdCgQWHaaafNdyHSrL322rHDjdjDOqIZXjsjRowoFArzzGVWEHcYlueNDj0ip3XsESbwOMJjhfhJ/CGi4FHjPWysDNrCrGkY7Se4MkPbCKLNPbDDDjuErbfeOg++zT7u59SIt4SQhGhEW/jbeeedo8BZ7bUjsDbPi4kf1MEzxJ8ZogV/AwYMqCh6EqScc3nttddiVsRX2CCWEQ+KehBfEZzmmmsuKz4u8dzZZ599Yhp2IMAgtkw33XQxkDwCGG1idjmeES8iUS/3golGDCVFwOWczj777Cji4JVIPCtmtzPBl3zwS41y/vjHP0aeq666alhrrbXi9aQ8hGM8ixCHrByfnyGJhx12WHznsZ/rDzfeiQTc5hqnwdJ9/mauawhYM2mrLhEQARH4f/bOA96OouzDA0bBAmKMIE0ioEiTohSlI1VKRA2CAqEm9A8IkERp0gQRiEBoUhMgIjXSCYiAoIAifhRFisEQVBAsIMInmu88o+/6nrm75+xp95577v/9/e7dNjs7++zsnp3/vvOOCIiACIiACIhADxNIvQT4Ip4a3SKmT58eGH2IBnsjhueFtyWWWCI21BjBCtHHGt433XRTuPbaa33S6F1BIxJhioajN5bXWmutuIoGqTe2MWz2HXfcUbMh7PcpmqcxeeGFF4bzzjsvei2MHz8+ChZF6ftj/UsvvVR1GDykmrE0aPScOXOaySbbB68eYgkhqJhttNFG0avDlpkiOCKCIB5Qr/AAQ3hCiLjyyivD+uuv75OXmkdYxIPND3HPjhyHUc7oUoagQRo/LD31c8KECQGvMm/URRN/qPd4myBUImyQhwlaCA14j2Bsu+GGG8IBBxzgs4rixWGHHRY9UvwGukOWtaWWWiqKY7XScy54JXFfpGKY7Ud95v4w8QcRBOF1hx12CGeddVYWHBxubEuNNAhEGFy4h/HA49wpoxn7e68pvMI4rok/1AEEFo67xx57hHvuuSe7x88+++x4/1pe1AfibaWj1XEvItggWnF/UjYfzByBj3xTQ8RCvDPvM8Qj0lFvqb8Iyt0i/lB2CUDpFdSyCIiACIiACIiACIiACIhAUwTopuG7atAAT40GEV1amhleeoEFFqjKbsSIEdkyXgM0WM1ocPqGOB41yyyzTFhllVViY9Q37vFQGDbs350jTERiSkMdcYm0Sy+9tGXd0pTuJyeffHLsLkOjkUZ0q9ZKF7A0Bk2zsZTSwMxlvZLozkddsD88QOg6uPbaa1eJK0cccURsyNv1MWbmzYE3TSpewWXcuHGWtPQUbya6Du2///5V+yA0UE5GJjMj+PmkSZNsMXqNIDCYcX191zO6a/l6i1fMQQcdZMmjaMACo6utuOKKfYQevJvw4KGLk7FgXaNd9zi/Sy+9NApn2cFzZig/1ySvmyLdvkyE4Xoh3JjhKYMYhjCHpR5GiCte3ON+5ZzN7H605SWXXNJm471jx0VIS+OIcX0QyYwPAoylZ91yyy0XryNdRr1NmTIlClG2jmeK91Kka1hqiHu+uxj3tj8P7gO8k3wdSfPoz2UJQP1JW8cSAREQAREQAREQAREQgR4k4IUWYqGY0T3m6aeftsU4Nc+cvDg9VQlzFvjCTzczYsDwBT8VZdZbb71sLxquRQF6EQZoFFrjlO42xH1BmCLWB4YHQNpAzDJvYQYBCBEATwe8GKyR2kKWLe2aikepkFM2cx+nhn28SFIrD9jTsLY/PC3ICy54iNGQp+ve7rvvXtWlz/KkSw9GA/+QQw6JAX1tG1MESQSShRde2K8uNU8cKG9FcVzoluiv48UXX5ztRrchE/lIY55mWYLKjB9lCw4+eDBCis+bWD94qiCI4GmCiIjnTCqY+PyL5rlf8Kw57bTTAt2l7H5I01N+7j26UZrRxY57xGzUqFE2m00RP9ZZZ51s+Re/+EU2TxB4M7giIHlDeNlll11idzKEXYRb7Pnnnw94Spl5IdfWMUXwRSgzSz1+WO/rKJ5Babwg0jAKmlkajJzYYN6zia54vpua7cc0L2+/vb/mFQOov0jrOCIgAiIgAiIgAiIgAiLQowS8AEQMFoK+miH4IHZgiAt0eaGbBEPHN2oEYEZASY0AzYyWlYpNtUYR4is9QWtNsKKhTpcbGrt4FRDvpd1GQx4ByxvBp/EiMZHAb2v3/K9//esYj4UuUtbFxjdwOV7qEVS2DC+88EJV0rLXF88Ium01a7CzLkpcP/4QjvAiYsp1TLsOlj1WWS8mhAQfWBkRi25K1DGCSZsh2vg4O7be3z+sQwAriufjRUny994mll8jU0Quys4f9txzz0Uxjq5QnhvdsPDoM4GUuuTrLPN55+a9shD7sDfffDN618WFyj9/TraOLoXWbc7WMU27YeElVWTLL798tolYPAhrPoaPn08FKNvRC6TpdSJ+lmfQqBeWHaM/pxKA+pO2jiUCIiACIiACIiACIiACPUjAN4xokCICEYcH40s/8TVobNGoxOgS0Yrh2UOQWWIMMYKQb4T5fOsNkU2jj+431hWFfPDGSLv++DzbPU93IzyajE278/f54UlDFxUa3CYA0ZXIB6FORTS/f9E8198a95YmDfhr69s9xYuKrlm+DtAtzLqGIboxahaBiRu1sgIQ+abeaMRA4l745S9/mR0WoYry1jMCWxcJQCNHjqy3e0vbqRf8cY9yfxFE2Qwx1wSg9HrjQVfPEJGwNLi1xUCqtz/bff3EY6nWNfIePuyLYEOsITO/b9q91NJ4kcg/59iOCOatyPvHpxnoeQlAA30FdHwREAEREAEREAEREAERGOQE0oYRjUcTgGj08dWeAL542dAgL+pKUwYDXgg0Nn2Dn7wRc8ibWDGNGN02CPBsjVK8E1JPgUbyayYtXZT6wyxYr29w4yFz4oknZoen2x4M0u5PWYKcGeuG5TfhgdMfRjwdBCyuI2VPjXqC6EJw4ka7HXqBIM03XX7Pe95TtYrg2twXvmscIhQBg+tZrfpA969WDG85BEe6R+HpVsu22GKLGMgZAQ1D9LF7A487b3SpTL3J/HbmzSss7ZrZiBeT55nmny577x220U3QC0A+fZrWthWtZ3s6gt573/te263mlNHjBsokAA0UeR1XBERABERABERABERABHqEQCoA0cDk67x98afbF91faKDT8Gy2EctoXD6WB3FLJk6cmMUuIUZJowIQXZdMGOFyIAQxCpQPKN3py8R54HlE0NlOmgWr9UGIaRAjCPmGNQx8XJp6ZbIRkCwdQocXmWx9p6Yc63vf+17suvTAAw/EepZ2FSLuEt3FfJekdpYnjQ/DcRCQPFu6MPo4Vc0cvxFRKi9/gnwjisGnngDE/ttvv330oLK86MaJYJPWVQIrr7zyypas5tR71ZAQUaqs+etXT0hByPQG/yIr4lq0Pi+feuXJ26e/1ykIdH8T1/FEQAREQAREQAREQAREoMcJ0MCz2Dqc6s0335w1ItOh4suiIDaJF3/w6mCYZR+4NhWiyJsGK8N258UDooGI5wgNYi940KWImCH9ZYxORjDb1Iuk7PHrdXUjH7w3rNsOnlLeCJ7szQfZ9evz5mn0Isx5y4vd4rf7+bxr5rfXmyfeFN34qHN4gSFqUH68PfD6MUOMbPSaNtL4T0fJMk8TL4rQLaxVS8WTRvMz3oixPth0UT7WVdC2E1wZS72U8Hgqa2ncHi8+1svDl4f7ttY5mABteabd9Gw900aute1n19iW0+PZ+m6aSgDqpquhsoiACIiACIiACIiACIjAICRgjUpfdD98MuuvvvrqGHvGDxPv09ebTwPMItykljeEOSMV0fUnr3FGQGm8XeiSRtcyH5/lgAMOqBr1KD3WYFs+77zzYpHThjsruVYETDaj+56PtWLr86bf//73q9jCLW0Y5+3XrnU//elPY0Bh68Jn+SKUcN29CJR6hFjaVqeIYMRXMmPEJxt1zHv8EAOollBio52ZUGf5+Wnevea3NzJfJu6U795H3TEBihhPXnxlNLEiQ6RBpLNRw+gq5eOAEbi7SMRkX0S+c889N2afDvnuYyylx/ddtPBK+9CHPlSVxLMsOn7VDskCI4d5SwOh+23dMi8BqFuuhMohAiIgAiIgAiIgAiIgAoOMAMMgY3kNa4LVEmDY25e+9CW/2NB82nC2eCI+kxkzZvjF6B1gZazaUFlAkLrssstiIxZPImJ90O3LxAu8Cw4++OCaHgZpngO17BuyeWW4/PLLw/Tp0+OmvK5ZNOq9dxUJEdgIRlzLaPBaAG3S0cAuE+PG59lMw9vvbx4gBCjOs2WXXTZbXcsDJEvkZlKvkCJR7MILL6wSwXbbbbcsFzzevMfVGWeckW3zM4hIDCmOl1IavNina5WXz2vChAmhnmjBEPNmNlIYy3TF8teaYO+pF5TtRxdQhEIf+4dh5c3ogkkw9zxDpOI+tSHoGQ7ej9hFoOo8475nPzOGlE/N6g7ri7jWurfw2PvsZz+bZYtIVZTPvffem6UbyBkJQANJX8cWAREQAREQAREQAREQgUFIgMYYQV9tpCVGzZo1a1YfsSQVfBgdLM/o3uUtr6uM70pDWt8wZZnG5+mnn85sZnQtMW8KhpX++9//Hh599NFw2GGHZUPTr7POOmH48OFxHxreRx99dLY/MXPwEnrttdeydY3MvPjii1XBqhGV0uC5jeRnaWfPnm2zccrQ7WnDk3PFa2rcuHHhyCOPzNLnCUBsZMhsGupmdKHaY489AueQZ/AeNWpUFjsIkQMPj1riBfnY9bA8WU7LbtsamdLty3vh2L5+KHMT92xbvWna+MdDzIQI2xfPo1NPPdUWA4GTt95662yZuDNnn312towYd84558QA0baS4yCkwYL7youbDCdPvTFLr72tb2ZKvjvvvHMUnfL2Z5QryoNxfYkH5G3MmDGZGGN5pd25OKfjjjsudhnDO8wML6ltt93WFmOw6fvvvz9bZgZxyo7vvfPgZ56EsL3llluq9kPYIeaTceM4m2yySVUaBDfv3ZT3zOG6+PhgpE/rBN5J5glFXUAISw1h6Mwzz8xWUy6EvoGweSonMHcgDqxjioAINEeABxrujPzQ06edoGl8nfnkJz8Z0v60zR1Bew0mArwU8ONo9YG6wFdY4i6Yi26Z83n++ef7JOOrF19DcdOtFTSvz47/WcFXHuoodTbvp2aJJZYo2lXrmyDAdafxRSMF7tQF6gcuz7zUy4YWAeoCAVF/8YtfxHpAg48/YowwWhL39iOPPBKH5uYLaRrMc2jRavxsaeDgjcKzl99h7jUaRzSGe91ofPLF2xpWeefLMOOjR4+Om0hnwg2NMO8tQsNu2rRpNfOC64aV7lk0nvgtQZDwDSeGpOb9B7GCRiHHo2FIVxtvCE9rrrlmlbjjt7MvAYJp4JEuzyjLjjvuWDc4NJ4MeFbQwKzFifwQpeh6VsYzhbhEdGeqlWdeudN1eG0cfvjh6epsmecGcXRMqKGccCZGEvFXELC4br6hi7DCSFE+PkuWYWWG49FIc5QMSgAAQABJREFUr1V2jrPYYouFMt2SfN5cN66/2U477RRWX331QFDm++67LxOF8NLh+deI4fGz2WabVe1COelaxu8rIpj36EFsg1WeCHb99dcHH2sJ0YBnMt2qCFxNveZcqItYvetNOfBcQ3BqxBD0vAeN7cv50KUJzz2CPD/44IOBboN2zYr48fzDW8wCjJMf+ZMfIqTd43gArbTSSna4OEX4I+C6de+yfek2x754rdF1c8qUKWHLLbes2pfzQJCyeoq3ISPP8T5EdzTrEkiA9ZNOOil7L+b+pH7beVVlWlnguhDUnOMVpYE9Qp51mySeEscxo1wIy/xWMMLgQw89ZJv6TAlav/vuu/dZ36kVwzqVsfIVgaFMgB/G9MeiVR64XKKe82PGj0Nq/OBIAEqptGeZxjR9k3m54CWUv24xXrasT78vEy8D/uuR35Y3n/Zh9mlw5+bHstYwmD69zdO3O30Bt21Mfb9sv76b52n0tPPLG/EB/JfJVs6dxjwNk9RoYEkASqn07jINZJ4J9sXUztTuRYbgpqHGyzBdW3hx5iVb1hiB8ePHR88KvxeNhqEgACEu0yiiAYR44c0ED6ZmpKNxc9FFF/V5RlH/ivJif8vPgjfzYYLGMWIQogkNQ9/4psHJ13jETjwNLCYJ7028Q9nvpX2t98ewjybDhv27eVTr/OzciqaUk7KRhx3LmBgzOzfO345ZlJ+t52NNUYPU0pSZ1hOb6GKDd9XUqVPj8PAcM+0eZsfhHA899NAYO6nWeeBFkV5rGHk+bE9H0rLj1JtSDhr11DNEbd/1B9GB512j4g/HTD9gUe+oSzxL+TPjXem0006LwpOtS6e8y/N7jJcUMZY4f4R6M+4TzsGMY3tmxsvqEtvyul7a/vWm/BZwDtwXvE/iLZbG2SIPrhFlXmuttXKzRCxC5IE5eSF6IAaZIITAhTdOKv6QGe+WiIPUSfil+1JGPHzSrqTsyzsU3TgRYhDLEFm80II4g2DMu5vd3+zH/em5ss4MtnBmlEKfxphz/9q96/PEm4lR1agbM2fOjNfVX1tGPkQUY5qa7xaXbuvEsjyAOkFVeQ55AijO3qWxHUAQHfhR48Vrr732il/6eUCZIQDxtUnWfgI0pPyXCcSgbhHb+NHjZcS+ctjZ8yWpEQGIftE0Annx8q6ulh8vCEVfRC2NnyJG5I3ywksAbvaLLLJIFgjQ79ft8/VempspP18PeRlp1RjhhlFXaOjz0mJG/fWBFm29pr1JgMaweVjQGJ40aVIUfOiywHMC7wH/pRwKfJ3sRN3uTcL/Pqvjjz8+EM/Bs6SR5BsfvXz+3XJuNBYJAEujjDrMb4sZjWd+z2gkNjuyluU1lKcIDA8//HAUBhCg8Hrj/QKvQd4L8ED3DeGBYIVogecQ3kd4HeMZjbiIKMTQ5HneOGXLyT3uP7ziEcRvNs9Ufr8JOs5x+WuEA+9b7M+UOsoocDa6VtmyNZsOT2FEbEQx60bFOgQMumLCD68eyoOHEt44fuj1WseFP4zIA+O+xOO7DBv2pcsZ9zXHQzDCC72MIcrwLKCdxPVZcsklI9My+7Y7DYLOk08+Gb1Eee+FAefPteY3YqGFFornBd8FFlgg1tNGP7K2UmYJQK3Q074iUECAl0L6xGJ8EeAhi0siNzwPJR5wCDa4eprhVokXBtsJWob7Pm6PfH3BeAjiOmnGiw19YU1dlwBkZMpNEU4YspQvFbwc1DJ+/LwoQiyAPE+LWnl0elvqetqoAOTL97WvfS0LFGnrceXHpb+sEWsAxt4QIVKvBL+92+f5Qfdfr2hY81K4+OKLx/uWe5I65c9xn332ie7e3Nds54WRYIU0Hs24dmVfcGyfWlOEPJ4lJhBLAKpFq7e2EYvFAnQi/vBFNn2ppLsSX5mpd2YSgIxE41PEcYIGYxKAGuenPUSg2wkgSPguVogb6XO1289B5RMBT2Bev6B5ERCB9hBAfTa74oorYj9hXgxRf/nRwK1wxIgRliROUf9t+3zzzRdFCb7mo85jacBAGpRFrphxB/2rSYD+7XwdKhoZxO+8wgor+MXAsJfdZrhrt8vMcwjx0ox+/mUDYCJAIP6k/cv768uWlbndUxrOZrgj44kHI7tvmda6r9nOF0oa3zYSC/n554Xl38qUL518kZUNPQIIkGYTJ07MbaQgNiIMeTHT9tG0cQJ53RIaz0V7iIAIdCuBdgSn7tZzU7mGJgEJQEPzuuusO0wAt0ls7NixscFX5nBFXxOIzI/xNR8PAll7CKRdpmrlSn9e+mRvt912MfYAQRC7zYrqTyvlJJC0t6JhNn0a5vEmwNKRIuLKQfwP112MhrN3B/enlF6HdNnSIt5a4MB2C0AcA7FJNvQIeK9S4iYUGUHd05GZitJqfW0CfIyRiYAI9C6B9N07Xe7dM9eZ9SoBCUC9emV1XgNKwBqKtTx0yr400m3M98/1J1Y2D7+P5kPsg2sBUcvw4BogADHEZ1HDv0w+gy0NAoXVPcruR/uodS50iaDffTrcZq19BsM2E2rWXXfd2OUrr8yN3JPmIWWCcV5+WicCZQkQrN7HfqIbcS3rtfuz1rl2cluRyNvJYypvERCBzhNgJDJibzJClbevf/3rcT1d7WUiMBgJSAAajFdNZe56AhZ7gwBkZa1Ww9G+5KYNxVr7lD3uUEx3+umnD8XTbvicqV877LBDth+B6wgOWMsIEEkwRobCbCXoYq1jDNQ2u/9817hWymJD5Vq+reSV7qtnQ0qk95dTry9G8KllBMvtRm/GWmXWNhEQARHoLwKXXnppjNd31113VR2Ska6I41fWK7pqZy2IQBcQGNYFZVARRKDnCPzxj3+M5+RHo2jlJIkgj+GB4BuftRp5BKxl5AYLPF32+MTEIXI98U4QsAhwmzYsivKinzTBkoneT7wXgis3MmoAMWZ8MFyWERHqHZ/AugTlw+uEURSIqF9kBOhOgxMXpU3XE7yb0S9gWs9IO2fOnDhkOOkZAcGfW9H+nDNf7jkO50JsqIG0rbbaKo4sZWW4/vrrq4YotfU2nTFjRpylu1yzxv2D0ET9Jt5St4zeYkINwwsXWa17Mt3H7mXzGEy3s9zKPZWXX7Prmn0u8Bxi37Tu8yzjutYaMtiXlfTc44y2wrOFETV4NhAEHy81hqBt1HDjx2MGxj4+Fcvcf+Rf9vnFsdmPe5f7nvuW53aZ/WFEvTHBFF780U2rEeP5x595ATESGLHnGCygyAhmz7HYr5aRptnfBfJ98cUXw7PPPhuIb0ccLOKMlfGc4XoTgJV7j/1gWmY/jsnvH9cxjcsFb6xRvnGnyj9+G6m79X6XLL2mIiACg5MAIRgYzZTnlr/feb/jOdLO2IuDk5BKPVgJSAAarFdO5e5qAgSH3WCDDWoKEY00FBl9gAZFKiilefDCSxBQvlqYFxKgNt100zgSWa3gxfyY8VXjzDPPzBoQBplRZY466qhC4YOX9KuvvjrgWeOPy/4EyCQY6WqrrWbZxSldsBhtivT8WaOFkc5+9KMfxRHPrJvWAQccEA466KA+3W4Y8QbXXNJ7o2HNqCybbbZZtpqGIl2T/EhqbDz66KOrrtNGG22UjeBGQ47j0kCnAWNlZMQ20uUZDZXTTjstV2SikbXffvvF4MH+ZQLRh6GZEVdSfjTgNtxww3D44Yc3NKx7XtmaWcfx6faGKzRGHdl///2rXoYsXxrAiGs00ngx4iWprCH4MMoYAp1xtn3Jb9tttw2MqJU2qBH/GI3LXtDgyn1B4556ydClxDK6+OKLw4MPPhgb2YgOpHnrrbdiYGvyXXXVVe1whVOuOfm3K3guwcX5irjyyiv3OWYz95TPpKiRzBfLa665JjZ+4cD5cJ0I3I2noQWdt7wafS4cdthhgfuSe8bqMqPo8Vy64YYb4hCz9913XxSJOQbdDLnHqON59uijj4ZvfOMb2WiHPg3CD88IAnL7EVp8Gj/PeVIXEJN8+Rid7pBDDgkXXHBBrCM+Phh1f88996zpKUO9hytdRP1ogRwbDxtGDfTPXq75/fffH4eHNUaUf++99w6XXHJJfA6wL/XslFNOqTtKIWnNeFZ7gZvR+G6++eY4jC/PYuqcf/bQuOGvyBq9/j4fRCOCTfO7kN7TpMO78NBDDw3Dhw/3u8V5rg/X49xzz63axjN04403jvd8KsRyLLqpIiDzEcIM4YkRz3j202XDflf4nSAgOwKZZ2L7+SnXF3H7pz/9aVavubbU7aK66/fXvAiIwOAjsOWWWw6+QqvEIlCCgASgEpCURAQaJbD66qsH/tplNHR8LBbL1wtACA+77bZbbCjxok9jFbdVGhgzZ86MDQ4a8XxFTY0XZgKCWuNlm222CQwhfPfdd8eGP8KEec74hgz5sC8v0E899VTMlsYU584LPy/vdBuiO9C+++4bG5f2ok0jzA9DbGVC6OAF3Z8votSyyy4bR1OzdFOnTs08U2gIUH4aEgx5zeheNKZ23XXXKFyxD4GJU/GH9WkZEBLGjBnDpngOP/vZz+K8/4fQlmePPPJI4IuRNXZoPCJ80dC+8sorIyMbIpzymdFoNoGF+DLwfOGFF2KjEn402GmAIGIMxOhOXFMrH/UJMW2dddax4mdTykrDC2GvEaORyTGsMQwbBJnHH3883HjjjbFeIpBRBhrI3ivqjTfeCD7wbXpcPNgwGoF2DmmaXXbZJV2Vu4wXVxoYOzdhyZV4reTl1+w95Q/rnw1+PaLmnXfe6Vdl82lgy2aeCw8//HD2HLGMEUio9zwPEPOo44gs3OeIRTTCibOQNqS590aPHh2zQSBBzEMEZ0REvFusIW/HqTelHNTR1BCv+cMQGLhvGSWQukyd4Y8YYPylhqiEgHXTTTfFTYgCNBqoy+ecc07gHCg79ZfnKvbEE0/0KTvPDu57nh2IruwPo3HjxtWs3zFD9w+xiue1PYPYRJdM/swQLfhDVK3lBdPM9bdj8HuEwGO/Cwh9CDd4QyIA8puEIM9zjuear688k7knOQeuB/kghiEGUk8QEn/wgx+EE088MWPKcZ955pnIzMpgU7rC8UyBK88tPIL4aMDvxDHHHBOvM787eUZcJeJ9XHfddXEz5YEbI3ny3KFe2zM9b3+tEwEREAEREIFuIzBP5YVPwwp121VReYYEAbxivve972XnyldaL3pkG2rM8OU7DU5Ho4MGDEbj5LOf/Wz2Ek5jYsKECVU58pLNF2B7Uedl10YeY3++QJ9//vlxH0Qh/3U5fcnniy0v+WZ4FfCSbvvwkm3CB9tmz54duxWkDav1118/vpj7vGhkHXjggTHra6+9Nn45ZgGvBfI3N3+6CyD82BdgGCOa0JjhZR7zwU/x1rHRmNhGg8i+LOOFgXBAQxMPAbM8jwM8UbbeeutMxOArvzXu4YigYY0yvjzTeMAQP7xHCYGBr7jiiriNf/CDK8Z+CEHzzz9/XE7/0S3GjC/dNpy7rSs7pXF9xhlnxKHKCWTOl3wT9cgDLwO4pcb1pSGNQIRIw3lb/CrS0tA/4ogj0t2iOLnTTjtl62GNlxFGHgiICAUYXcvwtDCjbNQj6hPiAx5dZlzXKVOmxG6MdM3x9YkGMNcLQQIPHN8Atf2bmdL49nXF309l8mvlnvL5c7+Y4HnSSSdlI7K99NJLsUFtYi8NWoRjWHGfWPfGZp8LNKq51/DmSsUW7v3x48dn3hY0vhFyMe4BK6+dB/WM687zjOeaNzjh4YdQknc/+rQ2z+sOIgEM8BqjrGaIA2eddVZkgEiNdxh13HugHHvsscHXU/a1Os88wgB100RunulWj+GM6EBXOEQPnheUOxXjeF7xZ4IU+SKEWvcwlusZAgr3TD2jTHjM5P3uNHv9OSb3LHXKPDO5ZxFJjAsfA3iOmeENZc9chDfrPso6noUjR460pNETE489E+4pv8Uxot7x3Ied1Svbkd8URDjrinjLLbdEb0zbTn62zdYhGHK9eZ5heNJyL1l3Q+oT4rwXj6hHab23/GpNyYu6gzdouw0xzf82tDt/5ScCIiACIjC4CMw7uIqr0oqACNQiQLcnE39Ixws3X4TN+PKaGl16TPxBfDDxh3Tsj2DESy2WfknGM8f2RcTxDWzS02jBu4WGBkYjwNKzDW8ivoqn3aloNCN2+IYJQhZGw8Q38mmUmfjDdvKk8WuGgIWRhpfg9EUYzyJbz9QaIuxDdyPKQEMU8auW0dAzDxY4ElvDLBUXiO1jhseRN3981tMlx9bRYLUYO36fTs3b9wG+duOdYIbIQRwMbzRcaHghrHgPHZ+maN7HXyGN3586aNeQbXyJpxFvRtm4biuuuGKsu9wDZogHJrohmlk9pBFHl6RRo0ZF4SO9Prb/QExbuaeKymvXke0IpCb+cE3x7EOwQhQ18Yd0zT4XuG8RC2mke+Me51lgIgDbvOcV3i4m0LINAcZEP39/sw2jEZ6KMf/eUvyf68z9zr3s9+X5Rt1F7LTy4bVH9yTqsxndYPE+MkM08ELNcccdl+1PGp5ZPDsw6iFdczG8MPEMNHEorqz823777aMA5Y+J90sj4g95kTfHsue25Z9OKRMeVv5+sjTNXn/2R0gz8Yd7DtHXuLKde9aM7Sa8IBx5MQVBxIs/7MOzgY8nZgiKiL8Y9QQhkXXe4ODFH7YhHno+Jij5/fjQYOIP5UTUNPGHdNQnPBcRE1s1xCa8RBGu2v1H11eZCIiACIiACBgBCUBGQlMR6AECXryx0/FeIHwh9caLMy/rZjSIU+Ml13f34QstxmhPl1S645j5RoutY0rj3otQxPNIzTdw8ERgdCRimPACzh+u/zTcMLoNWKOel3IabanZF2HW8zWWhkWrVuR1Q74Ep/VdxWjEeFGBc8GTgEYwXgK+AUPDiJhCdH+hMeHFK/KGDV+vzbzXgq3rj6k1ZO1YfEH3Zl/0rcuO31ZvnkYbTBDOaBTjmeMNLyITwVhP3SsyvIxgaUb8KALBIlBSb/A+oKHdjdbOe8qfnwlAeKTYM4LYMAgWXvSxfVp5LlgeqbBJ7Ct/T5DOP5tY9gKQ3eOsx8OPe4Tuft7wWEJwSgVEn6Zo3pdv+eWXj8+cNC33bSpkea9N/+zkvs4LPu+fT3ioefNlYD0B1zFEfDwEuafwAGzG6C6HCIMXE95AXuzw+cEZkQmPJLNWrj/PWsQjM7w2vWjCeoRAzpHfDDwN7fnPM8U+EPBspytznrHenvE8D/3xSJ9y3WOPPTKRyfLjubvooovaYowLlS1UZvAs5EOEGfU3715hexrfzvZpZEp5uOaINWX/+G3jj7hE/P7YH/UMQcv+uvV51wgfpRUBERABEWgfgWHty0o5iYAIDCQB4mqkL76Ux3955aXWG94AvqHFvI8VYWl94F0TIO655x7bHKd4YBQZDSwzXnJpJPhy+Yahf5lGdEmD89JdwIxRyvLKaw1eS0e3AIsFY+vaOU27caRxkjgWIpoX0vzxEYZSLyg8ICg3f+ZZxD7tELP8sWvNe454QiHUWIBchDgajmZ8vabR5sUX21ZmOnbs2MCfNxqieFz4xinbazGg0Y6nmcVhoUH56U9/OtZzBKY0yLE/3kDPt/Oe8ufCdaSRjAcLVq9bWivPBTsu18Gb72Zp6/0zgHV4QZjhFUIj34RVAinzR/3CwwjxB08enifNWFq+ojw4FiKTPfcQ0RATqYN+aGCekXnPIi9awdVbev7e45Fjtmr8HiDcmnhLoHUEA2Ia+WcWzxfuX+ti28r1x2vLP6/8Odn5EEsr7dLHNh+ji98zvLCKjCDzVjfw0mHgBbP02q655pq2qWrq0/lnHYno+ut/G6lvnTaen/zJREAEREAERKCTBIp/XTt5VOUtAiLQFgL+pbXoK7h/yU0Pao0aW0/cmnpmL/d4vZjxddmLOLbepvaF15Z5ufaxYXwZffcoS++nv/zlL7NFYvP4rknZhmSGgNOtCkC+jEn2MaipreMFvlZgVUuXN2WYZQKWEvjYvoSn6WqJH2nadi8j+FgMHxp6NBQRu7ieNMbwvvFiYaPH59z4+k2AWAK9Wl1L8/FCQbqNZbqC4FlgdYOGHNeF0YjSRnfe/gO1rp33lD8HvEh8YxaPulrWynPB8vX3C+zzGvO1nhnkgzeceSxZvgg+JvogKtFlDiG4k7bccstlAhD3Jc/dVJSkK5jvDpZXHsTcIoNR6hFVlLbZ9XhW8oenId5FeMOZ4WlpAlAr19+6TFm+3nPP1hVNCY5tludNZduY+mcszwyuidUnm1p62OaZfxb431LSpmJdkfdPXr69tC7tMt1L56ZzEQEREIHBQIB37HabBKB2E1V+IjBABPzLrC9C+jLst/l4FqzHcyIdat6nZ94aKbUaM+k+vjHINhpRXgDyZfTxIdJ8eEn3x8UDwIJKp2n9MoF+iyx98S9KV2u977ri49fU2sdv45yIXWMNW7bRcKJLCAILIwyl3iF+/07Np2yIaWICEMckFhDd3SwukQVvbaY8dFuga4jFpyEPGvjElaLRijhZJAjlHY+6YaNLsR0BpGj0trz9B2Kdr9v1jl/vnvLXzos/5ItQQUBb/vKsleeC5efvaVuXTuulwWOOLld0w8q79oiQ1EniQlkX0fQYRcv1ju33e8973uMXY1e1VACim5Hvqlm1w38W0mdbI2XIyy9dR1wuPGfocpsG1k/TMjIZHncW4B/RBwGW35FWrn9a1yy+T3r8vOUXX3wxW+3rb7bSzXh2HJN9i3670nvFsilaz/b0hbvseXiPLzvOYJ6mHAbzuajsIiACIiAC/yYgAUg1QQQGMQH/kuxfiP0pFa0njY+BwDJfuhkRqYx5T496L71pw9t/vU2PVeulnHNBGLGGMvkQ66IV894keGAwHLMNN102X9+w842YMvszmhGjsNk54U2FxwZBee3aWTDcMvlZGl83bF2j0zQPvoIT68RGa5o2bVogxg4j9dDVo1Y3wFrHRvzBK8EM4YdAzb77CN47eSKA7ZNOGcGN2Bje8HBA/MjzRvHpBmq+nfeUr9d0JyIoMEytmw2BnxEc82LDtPJcaIRdrXvd8qHrDeLn3XffHa8n19TfDzT+8QIiyG8jZvdWmX3Sesd1SsUGmLXyLKoVY6xMGUlDnYcHvOoJQKQnNowJQCwjZBOvp5Xr75+FlmczojjdP2tZ+ptS5OVDHkXXukz9szLU+42zdK1MGZ2u3nk3kz/er0UfiJrJT/uIgAiIgAgMbgISgAb39VPphzgB38hrBkXqGcMLaFnDK8OMRod9PbZ1fpo2oFK3ci80FL2sW34IVCaWzJkzx1Y3PfUMaVziiUO8lLSBV+sAeJtYPApY8BKfdnsr2p9GuZ0PaYitU68bHOkYuYdjMKJQfxpBnk0A4lwJJMz1te4jjZYF/n40JESf6dOn1+VHfaMLIPFE8r7OE2wcoYD8SIexTFBcP9JQo+XtZPp23lO+nAy3bl5UBAbmuvGHN1deLJZWngt2XH9P27pGpjS48eAiUDDeNXis8Ifh6fKtb30rBodmme6CxDfKE7PYnmf1njN+H4ZhN4MN910ab61R4Zf8WmVkZbKp5Ufw31rPY0vv6xvrrBtxK9efmEne8JQq652Ft6ONxlVvOHT/W8V1T720fBkauda2n/dQZR3PuE52NeR6+YDhVo52TPmNUSDodpBUHiIgAiLQGwSqozT2xjnpLERgSBKwl/9GTp4Xbt9osqF78/LgBZWYHDbyTTrku4/Nk+7v3cgRS9IAp16ESfdNl/1Xdhr2viGQpiVIK43INKaFT+e52XwjX4bJi1F2vPkAq3498/fdd1/kSEBWjkdQWTNi1uSJP3zZN2MfvIbovsPIYkVm51K0vcz6vOtCIGVfZxCssHTkrjL5k4a64QUwuvvkiWcIFmacG94r22yzTVX8JdsOUxsGGzGPeEBmMGPo8260dt5T/vrb13+uGwKYGd5AxH5JrZXnguWVV3dsW5kpIirxZCZPntyn6x6CH8KjxXgiv9QjpMwxyqQhFowXsG2kLp4RdD8zI25VLUNoQ+hslUutY/ht5unl16XzflRIRB+rJ61cfwKu+7g/NjpgemyWX3jhhThkuz0vCdxuhqDOb06R+Rhpu+22W1UyX/fZ0AzztDsfZe2kwR5Bli7N7f7rjwDWnWSjvEVABERABNpLQAJQe3kqNxHoVwL+RbfoJdenSQtHVwYfQ+eqq66KniVpOpavueaa6Pnx+uuvx82MwoIYYFb0os/IY36Y3l122cV2yaa+jEXnYYnpLuXd/X3j3tIwxYOA0Y4QClJBwQsYXliw2Bd53TFqlYsv6cTeMLvgggviMMK2bFMaNHgq4EHDMWDjj58XqBqxx4tElIMRwjAvVHmGdrxmpzZaXF6jmoZKGpiXRnE61HPZY/vGNfvkMXjggQeqGuEwsDKmx0EUNI8ixMrhw4dHccqPWEbw22Y8NtJjtXu5nfeUr69+HuHQC5aHHnpoYPh5b608Fywff0xbl07TNHl1mPuDezjPECrMvOhg62pNvVcIArG/D/1+fihw1vuuin7UOmJX4YmUZ4gVp5xySuTs71kvcLS7i9GECROiwJJXHltHwHkzGymM5VauP88H/4y//PLLqwReOx5Tup8Rv8nuZWKI2bOd6+FHfPT7cY/baISs9/WZ5TL1Kk2X7oNHkRf4EI7TNOSBtUtQ5mMF3ont/ks9bv9dav0XAREQAREYqgQkAA3VK6/zHlACdGHwwW4pDC+0eQ2gWgU1wYI0eFGYMOD3wdPEjEZG2tAZM2ZMJuSwjca998hgXxpIfHHnKzExX8z4qm1xWs4+++xwyy232KY4pYFz7LHHZsckfgyxbbxRZh9QlW5dRS/a7EfcH45lRgODcnh2zOM5QLkJbG2Bq20fujGZ2ddnjkl8GBogaZcFzsN7Gvl5y4eYKtZ4oasRIkQqoJx33nnxutPYoosZDS0/PDbCkDWGLF+6MvlrBh/7Gu2FqlTQ8F/3La96U+olDTLrFjRp0qRAfJ60ceobi+SZNsDsOKmwQNl9o5d0xJ3yZt3LbB3HplueN87fuv/BgDzpEjdlypSs0YYgsNpqq2W70SA2gyf12PKw9a1OKYfvLkR+NFa9B1e9Y7TrnvJ11M9zfH8Ps7zTTjvF7nH+2rTyXCBP/wyBN0JmarNnz65a5eusv58RYfxzjJ0oq3ndIL56YaUq04IFnz/PCZikz09iW/mh3SmH917k3vUsibvj03NoBHMLnE63NW8po1QM9WkbnbdneZF4hmcTz0aM51baRaiV6/+lL32pKsg/4qs9s+w84DR16tToLUQ3PwxhHo9Ce44i1HrvUdJQjyZOnMhsNH5f0u66niuJ0mOzDj7+vvDzbMd8t0J+n/lAkhrCEDGozMi3iLml0VQEREAEREAEBpLAPJWXoLkDWQAdWwSGAgE8OI4++ujYkOYFsZbZyy8NW7oLIRJ4IzYC3W1otOQZL9EIDbwY+2CpPi3HYMQl+1LLS/V+++0Xu1xYOrx76K5FVwyC/VJuGucrrbSSJYlThAcaD1aeNdZYI9ANAPGDLmX2pRaRgFgE1s0AYYFGRhEPykjD4Wtf+1rV8WyBEagQXcw4bxoSiFR4jPASvvnmm2dihqVjSsNzgw02yFbx5ZUubDRKuE6UC4M/HlJ5ZaR8CFonnHBClg9BpGFqDRDKRNwSKxMNVpjSyLd4G8Qd8o0vGpXEPMEQYzgPH8cmO1hlhtHByPM73/lOYRn5in3yySf73XLnSYdYUWSIZj6fL3/5y7G+cI501bHrSnkQbPLERssbdtTvhx56KK6iEWWNUVbgCbDZZpuFV155JeBNhVhKvbO6ZPnQGGc/791j25juuuuusRHHPHXBdxthnRl5p8KTbas1pc5Tr2udq9/fzpvrX6tbRqfuKeoRz6INN9wwu199+ZgnALnxbOa5MG7cuOi5UXTP0I2UxjbCbVEayofY4hnBjvuU2CyIfQi31AfqH96JXphJzylvGaEhFRbJA282OBFImXwxjs1zgWvtPYfYhhDFM+CSSy5hMRplpDsfYvWNN94Y6x1xmOx5y3HxFio6f+4Ntjfq1US98V6ZVh6eOXRpGjlyZPTUY9h0fiPs+BdeeGHYaKONLHk2beb6286vvvpq/E3x3Yp5xhAjaNasWdErlGuHyJbG2+G5gIhkhtcaYi5CDh8ZTCjzdZW0PCsIBm7nZfsz5RoiFCJe4/WWl8bSPfroo9muxCTyAjfPakan4xl/xx13ZM+wbAc3g/BHnZWJgAiIgAiIQDcRGNZNhVFZRKBXCfCyyEsrL6H88YJfZNaY5AU1T5/lizINz7x82Jfj8CUb4canYT0v3Ja/z5vuO4g8dNWiYUB5adTzhyFgICil4g/bGOEFzxkadLyA8/JuDXu2m6DBy7+JBKzniz3naGW08rHNylj0kk4aXuSXX375GJMIIYT9GTLajBfvopFwCOaJGGVfki+66KK4GyIBwoYZjT1fRlvPlOOlhucQwhSNRWJwkAYuGOdJzJIjjzyyStSjkYvQQ2MGboh2Vm72oRGBVxZd7Gw9DVUa0pw/3TgoI9fWmzGkIVbGEH/sWqTpOY80H8pE/SD+hr+ueHORnrzSMpEv5cI8P0Q2Grt8SUfsgQd/GOeKwIW4R0Obxir2iU98Ioo75jXij2Xn7u8zC9qbniNpGf2oGcNjys41zTfNz5936uWVpm3XPeXz5fjm5WDPD7Z7RpwLzw2zZp4LiKCYvx4s2zUhf55Pvs5yXEvPvPeYQozh2UHsIu9pQZ4IG9w3jYo/7Ouff+RDIx9vO/N+Iw2GcML6dGSsf28Nse7jKYK4gAcaggFCo4mN1Auenf65ggCC+XNm3tcR740VEzfwD0EFgYtnOd2sELZTzyQ7Pt0ki4IPN3P9rZgLLLBAvFe5bpQDQ3y07qzwQrzNE7n4iIDQc/HFF8dnOqIyf2bUB57vacBpPA59vbL0TGHL/Vrmd8fvh/CEGIgHLGXgN8b/zuy5555RdGOamnWXTtdrufcI8FzDS5EPdPye/PnPf47eanwkSj2Qa509H85qeUDX2jfdxrOddxieJbzTIUgzSh/3gBeyeRZyTHtv5N6tFVQ9PU7eMvnxkY/3FgRVfqfJl5FCeabzLuk9dPPyYB33rf3GF6Xx6zkv3kdGjBjRtaN9+vJqvr0E+DjE/Wd/3IcMlGJepu092uDOTR5Ag/v6qfQi0HYCvCzQiDO3eeIHMNKSb+QXHZQfazxpeOjyQ4zQkhfUuGj/ZtfjKcKDnymNZ45pHja18qS8TzzxRPyxQORKR8WptW+9bby00H2Br+gw5K8eQxq+Tz75ZKBrH41aymTCBcejAQPbdpaz3nn093Z+uOlGxbXJq3u8yFK30m4f/V3O/jreQN1T6fm18lxI8yqzzPHwsECc4V6mYYRwRbc94kSVuZ9qHQfPE+uahRhBdySOSSMOgYbGE8egnvnGUq082UYZ8TBEiMi7h+vt38p2Gp/jx48PBx98cNY1l3UIGJwXz3SeR/DkhZiA+qmHadHxW7n+CCE81xAgaQyvsMIKVc+1omOynucdvyk0sHkWIm41M6x8rWOU3ebPg2ez1UF+dxDvF1pooTgiIXxp7CL+Ndo1sWxZBjIdgmZed7hWysRHnGaE3FaO2c59GXDCPHd9vnRXt9EL/fqiee7LNDxAUdp66/G+o/Fb5BlYtP/xxx9fJVgXpStaz3MbUZzfam/cDzwXzfD0pJt56gFo25nihZ3GHPTba83z8REBDnE/b6TQWvtqWz6Bbr73ETB9XEA7A+L2eQ9zWz/UpxKAhnoN0PmLgAiIgAiIwBAjgGce3niYCUBDDIFOVwSaIkA3T++R1VQmyU50tyzjEZLs1jWLeLvgoUpsLS9yNCoA0W2ZPPC49fnYiZrXoC0zxWsyz/DMxksOEZV4WnieIsIiUqeGVw4CDR5CdK333W/TtEXLlNe6t1oaxGi6l5L/sGHDogiN+O7jONLlHiEoT4zGewgPTPsAkJ4roiGiMuXm/PjjY6Bnx3nhObzmmmtasTRtkkA33/t8pMDTlg8wXnyUAJR/sdUFLJ+L1oqACIiACIiACPQoAd8FrEdPUaclAh0h4LvkEECeuEgE88fDlfsKMcTHcELYmT59ehQA2I6XJ10S+SpvYgQiRScMAYFA7QzK4Efwa/exEFoQsRBuiIHoBYhGjuVjiRHPij+zWjGl8PLB88YPGoG3JOXCMw3RBYM/3RXxWDKjS2Mzgo/tz5TzxlPH4k7StfPSSy/t492DRxIxuIjrRd2BE+nwUCQWYCoCrbzyylnZ8fCgLhlbhB3OI/XQpPsZ60899dQY15D0xLWD5TbbbOOLrfkGCXTzvc/z58orr4xnxD2PV6GsmMC8xZu0RQREQAREQAREQAR6j4AXgGhYyERABMoRMC8MPDcsNqDFlqERlnbRIx4LDXu6w7Gd2FLEcZoxY0b0OuGolme5EpRPRSwuRCZEp/4wuv61y5MpjY+F4FFkMMf7gUavpbNu/H4fxBLK6K3VeD/khahj4g/LeeIP681WWWWVGOPLlhnsgq5ntQwPIl+3LMZRug/1jK50eHkaC9IQQ9ELGOl+Wq5PwO7Tbr/35e1V/1pKAKrPSClEQAREQAREQAQGOQFcxAl2T2Bk/6WdYOZ8HbYv0YP8NFV8EegoAfPaOfDAA3OPk3pkFMVBIi6LjYzXKQ8g4kf1txWdb6vlSLnm5UeXKLp7YXgAlbEy+dbK5957763qEogoWCuuj+WF19E+++xji3EQknSkz2xjzgyiYy1DaNxrr72qktigHFUrtVCawGC591ut06WBDOKEEoAG8cVT0UVABERABERABMoRwOuHEfoYATANtIoAxNDzA9FgLFd6pRKBgSdgowQyihMN7FaN0RwxAmm327jfH3jggXZn2/X5bbzxxrGMjIpXxlppLCOqe88dPG4IulzWdq3EPPLGM9h7Z/ptzcwzgIk3RrqVNUdgMN37rdTp5ugMvr0UA2jwXTOVWAREQAREQAREoEECvBTSwKCRwtdjuqNgNgQysSKKhkRv8FBKLgI9SYCRKDFGQCtrtRpjjBSKWdeSsnmWSUd3qEY8SsrkWSZNpzyA8o6NAHPzzTfHIMvmdbPsssvGpMTV6bQR94hudmajR48O73znO22x7pQAzptvvnm47bbbYtqf/exngdHLGKGwHZZ2b+tEPWtHOQdDHoPp3h8MPAe6jBKABvoK6PgiIAIiIAIiIAIdJ4Dg0+yQwh0vnA4gAoOAwJ/+9KdYSoL5FlktwSfdxzw06sVmYVQfvPa4hxlRasEFF0yzqlrG+wWxt1mzUacIrkwZEar6U9gpW+7XX389xrYhuLEFjIYRcYh+/vOfR2+aetej3vZaZbn++uurNjcTTHqNNdbIBCAyY+j3dglAJlpYIfNGUbNtdJmjixM88G5DSKMeIEoR2Ns+GFj6MlMEOgJkzzfffFXCGKOVce0QqBrJl/2efPLJwHlRJxdffPG6++NRRRn48GHHwpuH+ky5ytpA3fvE73r66acDZV5mmWVCGhsrr/yt1Om8/PhINGvWrNitkjhUH/7wh/sELM/bj+tP+Ym7RQwrM64jH5wI0D5Q9t/SDFQJdFwREAEREAEREAEREAEREIGuJjBy5Mg40hRdwNpheIucfPLJhd3J7r777nD66adXBRjmuHi7EN8lHdmLBvzUqVPjaEA2WhTpWXfPPfcwG41GHKOQeaOhzGhZF110UZ8uoqRbf/31Y7Djeufe7sanL2M6bzFZaKB6O/LIIzse8BgBg/hp3uqx8WltnoDQ3rhOEydO9KuanvfeSWSyxRZb9MnrhhtuCJMnT+5zzRGL8BRFfKQrId5K9exXv/pV+NrXvhaIaYV4aHWQukadvfjiiwMj01kXZESZz33uc2HvvfeOYk5R/rCm+9qZZ56Z5Wlp2f+oo47KxAREBwKCI6oiPpjXE4Io58Sob3YvEIz9hBNOCMTjqmf9fe9z7c4444w+o3lxDow8yEhfBALPM38P+i6Fzz77bDzfd73rXVHAQRBj+xtvvBH/vvOd71Rlx3116623xhHl7JpZArqvwu6jH/2orQoPPfRQXMf1h7td/+9///uR/Xe/+92Yxu4brj9ec8RT628xSAJQdtk0IwIiIAIiIAIiIAIiIAIikEcAwcYP8Z6XptF1NIBSoxF72GGHBfMwWXfddcMGG2wQG6oINDS0Dz/88Og5Qkwv8+zAO4LtqSGUmFhi21IBiAY2McIw8qPBTMObEaroZkWjmT/Wd4sn4VVXXWWnUzVdddVVq5ZrLfjGcq106ba8UcbKeGek+SyyyCJVq7i2eJu0GmMKL5np06dX5b3HHntULTP0vNWDXSvxiPCcoo4//vjjmUdV1Q51Fmj443mVGnXVDEYIL9QpBAICU1PPETo32WQTS5ZNEXK450yAwNvrU5/6VEAcpesc+xKIm3wQIxAtECJSgwVs7V5hO2WA83HHHZcm77PcX/c+B+ZeRNTCEM7gRbfTG2+8MQYcP+ecc6Iwg0C04oorxnT+n6/TXhx97bXXwl133eWTFs7zDDrooIMyAQrBZ8stt4zCDsfHMwxBEc87rgnGtfKj4VnmiFm77bZb3HfTTTetuv4MSIEoiDhkHlq2XyenEoA6SVd5i4AIiIAIiIAIiIAIiIAIlCJAg+2QQw4JeGZgfB1nCG9r1BFkmNgzNKrvvPPOMH78+OhZwXa66txxxx1xv2OOOSbGk2GB0cZsxDGW87pz8ZXejK/3G264YcBTAC8jjmMjSiES0QC3WDu2T6eniE905aErDA3Z+++/vy0xjoxro+XPG7ntHe94R6PZ5HalQVxqVgCie83DDz8cvvrVr2YeGBSK0R/xYjFDIDLxh7ri6wdCzDrrrBM9TSx9mSneTHiMIERSZ70hIJxyyilZGTg+I7b9+Mc/juUcO3ZsoA56LyoEoq985SuZ+OPFR4RT8uO8qK9sQwSiq9Htt98eXnrppTBp0qRM+ET8weOEbZtttlnch/L9+te/9sUc8HnOwcQf7sGzzjor3ocUDKEFcW6HHXaITBDtZs6cWdN7xnsAIZDhMWXCMnnuuOOOgWHjEf+8wY44Yti2224bvYBMoEF02n///eM26hnegXhRMb3lllvCI488EtnHBJV/PKMQ/hDsLFbX7373u1jHSIOYxP290UYb2S4dn87b8SPoACIgAiIgAiIgAiIgAiIgAiJQhwANOhN/aDTzFd6LFMwjyiDCYDScrr766jhPAxdPAf6YN2N4dFvP1AsBlsZ3wcBLwsdH+cxnPpN95Sc9jdIiyxOXitI2sh5vDbqcnHbaabHR7wNct3JMz7aR8iBGpYb40qghZqVmDe10vV+maxaeMfaHIEJDfbnllouNevOY+fjHPx69uFLvmmeeeSbLbvjw4dm8zRDPiPrXiOElg8iAUOEb82uvvXa49NJLq+odgsGUKVOqPHIQjbxggSeMdWMjD+95BqMJEyZk+yMk8cf1RJzk/thpp52qio+nD8LaqFGjsvUIIN1iXFO6L5rR5Q0R1hviC13mMISvet5L3gOI9Nb9ithTPGu4p+DBM8IMLy57prCOY/g6iUcSQhKGSMe1xXjmUP+ok17IYxvX2sQflhdddNGw3XbbMRstz2vLtnViKgGoE1SVpwiIgAiIgAiIgAiIgAiIQGkCdLswrwx2oqFVZPYFnu3HHntsDNhblLbM+iOOOCIg9NCtA4HHN/jY3zfoCQjb30aDkyHXKSdCAYLAQFqe6JQn5tQrI54qqZX1JKLRbH94USCK0QjH2wJedPGim5xv3NuxvAcTXmZ0o6L+eeOalw346/dj3guIBLVOhQzSIDr6bmmIViZQ4OnlhUYv2rAvhtiDp5LZL37xC5uN0zRGDt2PMLxW8G7Bi8yEjLhhgP8hkphRVi/i2nqmY8aMyRavu+666HGTrSiYQUjjXBGZEOimTZsWg0rnJffcERUJ4pyaHzEUj7PUEAPN8AxKPYzY5rs/vvLKK5a8X6bqAtYvmHUQERABERABERABERABERCBIgIEaTXPDdLQNaPI+NJuxld4ut3g7dGsLbXUUiEvCCxxPWg0Ujaz//u//7PZPlPvcdBnYwsrEHwIfuuN+Ed0AerUMf2xiCGDqPH5z38+rh4xYoTfHOfxCmq06xbBklPzcWrSbX7ZXxO/vsx86t2DqIDggAhIVy6EFbpo8deM5Qlkefkg7HjRk+6GeO/QNYt6bcY8Hj6pebEsjXPly4CQZYIK65dffvk0qwFf9l2zvLCVFozR0/CmMe8oxL+iuFd4VCHQcH1hiMCLF10q8NoxEAF9nCD45nEncLRZXjc6n3+RWOuvj/f8snw7OZUA1Em6ylsEREAEREAEREAEREAERKAugbRBT0OvyFLvBrw/WhGA7Dh/+MMfYhwhulzlNfwsXTdMEQ8QgDptNIoZ3YqGrAlAfvQjO/7s2bNzvW1se940FYAQf8qMSpWXVyPrOAaeVATxNUMgIA6PxYOiqyHxgfK8d2yfomnZrnVp4GwYYqmYg/dXPaOLkzdfhm4UfHxZEVq94FWPuX82EHOnyH7wgx9kXUpJg1CMgOs9dPy+3P/e6Armu4P5bTaPQJyaZ5/nQUR6LxJJAEoJalkEREAEREAEREAEREAERKCnCaRiQK2T9Q0s0uV9ha+1f7rtzTffjEF1/ShieEww8s/KK68cnnvuudwRxtJ8+nN5ySWX7JfDEbAWW3zxxbPjMUT6VlttlQXKZQOxU2p5bmQ7u5nnn3/eLeUP1V6VoI0LCEB4Mvm4Mz57Gv4Ii3Qz8l26fJpW56nHiF4m3hhrm1r+eAn5LkO23k/Toer9PUJw6G42BKBm7Yknnqja1YspXlQiER6Gp556auxKWbXTfxZSAYguenThqmXcC7XMe/r4dEXrfZpOzXd3bejUWStfERABERABERABERABERCBriGQNqR8N4u0kGk3rFoeA76LFKMvEfz1Yx/7WBaole3EFKL7jRkBdhm62brYMAR1GfONTz9fZt9aafLy4pzptpY2/Gvl08w2G9p64YUXrtqd7lI2UhIbHnzwwart9RZef/31Pt4VxFzpT2OULUbFwlMEAYuYQr4bIqNnXXvttTGwdCPlKtu4x7vKxB/yt3uAIMHe6PKIENmseW+TZvPo5H6pQIUgW8uIkWSWetik9wqiLh5VeHNhLFN3LZB8XPmff6nIxnUghlMr5oU4n0/Rep+mU/MKAt0psspXBERABERABERABERABESgFIHUoyX9eu8z8Y1m1tcalt0LQAQdtiHkLb8ZM2ZUiT90Cxo3blwm/pAubVSyjq4fFoeE5U5a3vERGWjIttL1LS/f9Dx++MMfxlVp4xjvKB9g+Uc/+lFDnljXXHNNVbcfRkVidKb+sEcffTR8+ctfjoGQEdAYuYmYSoiAjCy3+eabZ8W45JJLsvmyM2Ub96kHlF1LYvZ4ywuW7bfnzftrW1aQysunP9YttthiVYfJG2XOJ/A80u6I/rwZMYzh5BkRzQs+DM2ed4y0S14jXom+fH6+bF3w+3R6XgJQpwkrfxEQAREQAREQAREQAREQgZoECMxrgWpJWCu2B12yvPkGO+t9o8sLQNY49NvvvvvuLCsEDUYJSu2tt97KVtloUbvvvnvYa6+9svXM5B2rKkGTCz7fJrNoajc8JywGShr4mW5RRx99dFW+jLxVxuB5zjnnZEm57pMmTcqWOz1DVx9G3Lr44ov7HGqJJZYIDEFuIkyeUNBnpyZXIJp523jjjeMiooYPhp2m8/tQHw866KCqUcPYbnWd+YGqPxy7jOHN5kfaI7BzkeHF5wXgNDi638+EL6Y+2Dbibd4Q8qTzow/iLVjLqMN4D6Z8u529BKBaV1XbREAEREAEREAEREAEREAEOk6AwM5jx47NjnPLLbf0GZrbNuI9YoYQ44Uj1vtluhqZWcBWHwTWf+X3Hi22D405E0FYZ2IQ3VTSrjVpQ9DyaHXqG5St5uX3r1Ve4rLgQWGWdgFjPY32L3zhC5YkMJITI4bVs7PPPjt6UFk6hrdPBSbbVjRthYnti8ePv/52LLokmWdJK12vyC+NUWPHYCh6vI7MGNnKRoyi66Fnz3D2zzzzjCWtmnIvELja13MS+Gtr51u1Y5ct7LnnnlmJuC5/+tOfsmU/c8MNN2SLMEtHdCs6b2JYeRGIe/q2227L8rIZ/wyiO6A/nqVhivffKaecEvDiMqHJtptIzLIvj21nOpDXRAKQvxKaFwEREAEREAEREAEREAERaIrA448/XrUfjaNXXnmlal2thf322y8w+hKGF8AJJ5zQJzkxWRilC6MB6BvKlth/xaeRZ6KNxazxjUY/hDSeFukITDSw/YhgCAZ//etfo3DggwMjCPlgtr6bipWrzJSGYerhNGvWrEIxrEyepKF8aXDh1LuFY5OG0cXo4kUMHLMigQYRw8fuYcQwL5jZ/kxpDNMInzx5crZ6hx12CKNHj86W82YQA2DuzUbM8uvKzvvG98SJE/uIJ9RZ87pZbbXVymabm446N2XKlKptCAR4oPhujgQnthhAJGbochOESLfzzjtXiWakoa6SD95KBxxwAKsye+GFF7L5OXPmxNGvshUdmGn13qeLlhdoEIRSUYug3CeffHJWeuqe9+Zjg6/jqbhHN0PvWbXPPvsE4nv5mEJ0w/MsCRbu73+OQbkQLbFvfetbcWr/iF3mnwOwT43652NNkd7XyTR9u5fnqRxsbrszVX4iIAIiIAIiIAIiIAIiIAK9TYCGvzVkfGM276zNK4fGlf/KnqalcbzvvvvGYM1sQ+RhJJ4FF1wwdgu766674i4Ecr7sssvC8OHD0yyiWEJ8HBNzNt100zi8OMIE8+edd162D+ICgYCtWwkNRLrUIHjQ8Js6dWogNghiSXqONL5HjhwZRah0mx0AryKLo2Pr8qbEHbr//vv7HMOnhSGeUpQ3TxzzaZl/7bXXwtZbbx3Prah86T5FywSD9sNv+3Rcs2984xtVI6VxzRAtlllmmUCgXrrTELTa6gv7E4uFa5024tmG+MT+NKiLym48aIyPGjWK3UrZ7bffXiUcUpcQB7jOBIO+9dZbo9iy7rrrxrriPcbKHID6Y8PJW3pER7oqLrTQQuHKK6+MAifbqB+nn356yBOaqJuIonRXM0MUQixBtJg2bVpkw7FWWmmlWO+pG56x7ccUXohFadl8mrLznbj3OTZ1hLqEcS/iZbb00ktHjxtGZMM4j8svvzyLf0X9q3feeBRy37NfnnH9EeEw8uP+8vGfeA7RRY/uaohGeAARWHqXXXaJ+xBIHLGoqK5yLpQfYbUoTXpeMeMO/BvWgTyVpQiIgAiIgAiIgAiIgAiIQI8T4Is8RsPFf1lPT9tG9KLh47+2p+lYplvVGWecEbsT4YlCQ8sHW6aRTrcvAvemIwBZfuRBo5rGM92+LJYHjTj7cm9p3/e+98UGHY1Oup4gBPmhwRkp6uCDD44eP3gbISpxvqwnkDAiEefFOsQZMxMuTISy9UXTp59+uk8+lMW4GkPWmUdTUV62Hk+Fsse3ffKmlKFI/CE9vOGK9xaiGEwIpsxfntGox/OG61FknCd/vm4ZA+PMMmnqjRpVdAyGskeQQRQw0YG0HBNB4Pjjjw+Nij/s7/0rqDN0KTvrrLMy0Yc0GMOMH3LIIYXHoG4i8iB0Il5QlxGDTBBCzDn22GOzEe04LuKPr4vw4fpZffTeKf8uRXP/O3HvUxLialEvGK0LL6zUm4x7H9HFd9fMO287KztvRB3zivJ8SEcaxFIz6vNRRx0VEADx3kIU9M8h9oc7978ZImbec4DtVk/x8PJpWI9Rn62cHLvTJg+gThNW/iIgAiIgAiIgAiIgAiIgAg0ToGH35JNPxjtHjQQAAEAASURBVIYv83jlrLDCCn1i7xRlTKOPhhvdQhCOiOtSq4FFFyW6WyHGMDoU3it4HpkhNND1CK+fdOhqS6NpiIzwZkIkQHCAFUNqwxPxJy+eUH9yQxQhyDhlIX4L3l1cd7p+IT6ko1I1Wja83Ky74WGHHRboaoTw+eyzz8aYMZw/4g3iU1mjLlMvTcTAK4aA1bXqc9m8uzUdXUgRtBA8ESC59xFf+tsQUbnvEW8Qnrh2vvtnf5en1eNJAGqVoPYXAREQAREQAREQAREQAREQAREQgQqBPAFIYESgWwgoCHS3XAmVQwREQAREQAREQAREQAREQAREYFATwFtNJgLdSkACULdeGZVLBERABERABERABERABERABERgUBGgu5aZn7d1morAQBJQEOiBpK9ji4AIiIAIiIAIiIAIiIAIiIAIDGoCFmzcDyHPCTHyEzGQGD2K4e6bCSo9qMGo8F1HQDGAuu6SqEAiIAIiIAIiIAIiIAIiIAIiIAKDhcADDzwQdtxxx5rFJQ3BxWUiMJAE5AE0kPR1bBEQAREQAREQAREQAREQAREQgUFNYKmllgrHHXdcHKUKjx9GF8MYWe4f//hHoCvY8OHDB/U5qvC9QUAeQL1xHXUWIiACIiACIiACIiACIiACIiACIiACIlBIQEGgC9FogwiIgAiIgAiIgAiIgAiIgAiIgAiIgAj0BgEJQL1xHXUWIiACIiACIiACIiACIiACIiACIiACIlBIQAJQIRptEAEREAEREAEREAEREAEREAEREAEREIHeICABqDeuo85CBERABERABERABERABERABERABERABAoJSAAqRKMNIiACIiACIiACIiACIiACIiACIiACItAbBCQA9cZ11FmIgAiIgAiIgAiIgAiIgAiIgAiIgAiIQCEBCUCFaLRBBERABERABERABERABERABERABERABHqDgASg3riOOgsREAEREAEREAEREAEREAEREAEREAERKCQgAagQjTaIgAiIgAiIgAiIgAiIgAiIgAiIgAiIQG8QkADUG9dRZyECIiACIiACIiACIiACIiACIiACIiAChQQkABWi0QYREAEREAEREAEREAEREAEREAEREAER6A0CEoB64zrqLERABERABERABERABERABERABERABESgkIAEoEI02iACIiACIiACIiACIiACIiACIiACIiACvUFAAlBvXEedhQiIgAiIgAiIgAiIgAiIgAiIgAiIgAgUEpAAVIhGG0RABERABERABERABERABERABERABESgNwhIAOqN66izEAEREAEREAEREAEREAEREAEREAEREIFCAhKACtFogwiIgAiIgAiIgAiIgAiIgAiIgAiIgAj0BgEJQL1xHXUWIiACIiACIiACIiACIiACIiACIiACIlBIQAJQIRptEAEREAEREAEREAEREAEREAEREAEREIHeICABqDeuo85CBERABERABERABERABERABERABERABAoJSAAqRKMNIiACIiACIiACIiACIiACIiACIiACItAbBCQA9cZ11FmIgAiIgAiIgAiIgAiIgAiIgAiIgAiIQCEBCUCFaLRBBERABERABERABERABERABERABERABHqDgASg3riOOgsREAEREAEREAEREAEREAEREAEREAERKCQgAagQjTaIgAiIgAiIgAiIgAiIgAiIgAiIgAiIQG8QkADUG9dRZyECIiACIiACIiACIiACIiACIiACIiAChQQkABWi0QYREAEREAEREAEREAEREAEREAEREAER6A0CEoB64zrqLERABERABERABERABERABERABERABESgkIAEoEI02iACIiACIiACIiACIiACIiACIiACIiACvUFAAlBvXEedhQiIgAiIgAiIgAiIgAiIgAiIgAiIgAgUEpAAVIhGG0RABERABERABERABERABERABERABESgNwhIAOqN66izEAEREAEREAEREAEREAEREAEREAEREIFCAhKACtFogwiIgAiIgAiIgAiIgAiIgAiIgAiIgAj0BgEJQL1xHXUWIiACIiACIiACIiACIiACIiACIiACIlBIQAJQIRptEAEREAEREAEREAEREAEREAEREAEREIHeICABqDeuo85CBERABERABERABERABERABERABERABAoJSAAqRKMNIiACIiACIiACIiACIiACIiACIiACItAbBCQA9cZ11FmIgAiIgAiIgAiIgAiIgAiIgAiIgAiIQCEBCUCFaLRBBERABERABERABERABERABERABERABHqDgASg3riOOgsREAEREAEREAEREAEREAEREAEREAERKCQgAagQjTaIgAiIgAiIgAiIgAiIgAiIgAiIgAiIQG8QkADUG9dRZyECIiACIiACIiACIiACIiACIiACIiAChQQkABWi0QYREAEREAEREAEREAEREAEREAEREAER6A0CEoDacB2PPPLIsMYaa8S/uXPntiFHZSECIiACIiACIiACIiACIiACIiACIiAC7SMwrH1ZDd2c/vznP4eXX345AkAAmmeeeYYuDJ25CIiACIiACIiACIiACIiACIiACIhA1xGQB1DXXRIVSAREQAREQAREQAREQAREQAREQAREQATaS0ACUHt5KjcREAEREAEREAEREAEREAEREAEREAER6DoCEoC67pKoQCIgAiIgAiIgAiIgAiIgAiIgAiIgAiLQXgKDKgbQP/7xjzBr1qzw+9//Piy11FJhiSWWCPPOW6xhvf766+Ff//pXGDZsWJh//vkjuX/+85/hV7/6VXj11VfDyJEjwyKLLFIqZs+bb74Zfvvb38ZjjxgxIu77zne+s71XQ7mJgAiIgAiIgAiIgAiIgAiIgAiIgAiIQAcIDAoB6KmnngpHH310+MlPftIHwUYbbRROPPHEKOSkG9daa63wt7/9Lay//vrhrLPOChMnTgw333xzVbIPfvCD4ZRTTgnrrLNO1Xq/cOGFF4bJkyfHvPz6vffeO+yzzz5+leZFQAREQAREQAREQAREQAREQAREQAREoOsIzFMZtaqrxy2fMWNGOPjgg2uCQ8SZNm1aWGaZZarSrbzyylG0YYh2vHXuueeequ1+AZEHMSk11p9wwgnp6myZvBdaaKEwc+bMuO7pp5+u6ZWU7agZERABERABERABERABERABERABERABEegnAl0tAP39738Pa665ZuZ5s8suu4T11lsvdr/6wx/+EC644ILwwx/+MKLafPPNwznnnFOFzQQgW4nA87nPfS4st9xy4Xe/+10444wzws9//vO4+UMf+lC44447YncxS3/vvfeGMWPG2GLYfvvtw4Ybbhg+8IEPhPvuuy9897vfjV3CsgSVGQlAnobmRUAEREAEREAEREAEREAEREAEREAEuoFAVwtAt956a9h3330jp3HjxoUJEyZUMSOez3bbbRcee+yx8O53vzs88sgj4W1ve1uWxgtAm266aTj77LOrtr/11lthk002ibF92Om2224LH/nIR+L+xA5aZZVVMvGJ7mNjx47N8mbm+eefD1tuuWWWhnUSgKAgEwEREAEREAEREAEREAEREAEREAER6CYCxRGUu6CUW2yxRXj22WfjXyr+UDzEno033jiWlFg/pC0yYgh5cYh0BIfeeeeds11mz56dzSPukCeG189ee+2VbbMZglB/+9vftkVNRUAEREAEREAEREAEREAEREAEREAERKArCXS1AFSPGB5A3t544w2/mM2///3vD4sttli27GeWXHLJbPHll1/O5hkpzAwvoXnmmccWq6Z0SZOJgAiIgAiIgAiIgAiIgAiIgAiIgAiIQDcTGDSjgN1///1xFLA5c+aEP/7xj3EYd/PQqQf4ox/9aGGSBRZYINvm42F7Aci6hWUJ3czb3/728LGPfSwOLe9Wa1YEREAEREAEREAEREAEREAEREAEREAEuoZAVwtAxOE5//zzwze/+c2WgKVdv8pk9txzz2XJGGWsluFF5AWjWmm1TQREQAREQAREQAREQAREQAREQAREQAT6m0BXC0AXX3xxlfjzxS9+MXrbLLzwwgHPnQUXXDBMnz49XH311W3n9uEPfzjLE68j31Us2/CfmVmzZqWrtCwCIiACIiACIiACIiACIiACIiACIiACXUOgqwWg22+/PQN12WWXhU9/+tPZss3MnDnTZts6XX755bP8GNlr7bXXzpb9zJtvvhmeeuopv0rzIiACIiACIiACIiACIiACIiACIiACItBVBLo2CDQBnR966KEIC2+cPPGHjQzd3glbbrnlsmxvvvnmkAacto2dEqAsf01FQAREQAREQAREQAREQAREQAREQAREoFUCXSsAzT///MFi7/z1r3/NhmT3J3zuueeG3/zmN35V2+YXX3zxwOhh2E9+8pNw5pln9sn7mWeeCQceeGCf9VohAiIgAiIgAiIgAiIgAiIgAiIgAiIgAt1EoKu7gH3mM58Jl19+eWB49h133DFst912YdVVVw2//e1vwx133BFuuummjrFk2PfzzjsvEHcIO+OMM8KTTz4ZNt544xh7CO+kGTNmdOz4ylgEREAEREAEREAEREAEREAEREAEREAE2kWgqwWg3XbbLdx5553h97//fXjsscfinz9xPHS22mqrMHXqVL+6bfOrr756OOmkk8LEiRNjnnQ3S7ucbb755gGx6NZbb23bcZWRCIiACIiACIiACIiACIiACIiACIiACLSTQNd2AeMkl1566XD99dcHPIFS22KLLeLoX6Qxm3fe/NMZNqxY5/Lb8vbffvvt40hk1h3NjsV0woQJYfLkyeEd73iHX615ERABERABERABERABERABERABERABEegqAvPMrVhXlaigMARhfu6558Jbb70VllhiifCud72rIGVnVv/rX/8KL774YuyOxvDziy22WHjb297WmYMpVxEQAREQAREQAREQAREQAREQAREQARFoI4FBIwC18ZyVlQiIgAiIgAiIgAiIgAiIgAiIgAiIgAgMKQL5faaGFAKdrAiIgAiIgAiIgAiIgAiIgAiIgAiIgAj0NgEJQL19fXV2IiACIiACIiACIiACIiACIiACIiACIhAkAKkSiIAIiIAIiIAIiIAIiIAIiIAIiIAIiECPE5AA1OMXWKcnAiIgAiIgAiIgAiIgAiIgAiIgAiIgAhKAVAdEQAREQAREQAREQAREQAREQAREQAREoMcJSADq8Qus0xMBERABERABERABERABERABERABERABCUCqAyIgAiIgAiIgAiIgAiIgAiIgAiIgAiLQ4wQkAPX4BdbpiYAIiIAIiIAIiIAIiIAIiIAIiIAIiIAEINUBERABERABERABERABERABERABERABEehxAhKAevwC6/REQAREQAREQAREQAREQAREQAREQAREQAKQ6oAIiIAIiIAIiIAIiIAIiIAIiIAIiIAI9DgBCUA9foF1eiIgAiIgAiIgAiIgAiIgAiIgAiIgAiIgAUh1QAREQAREQAREQAREQAREQAREQAREQAR6nIAEoB6/wDo9ERABERABERABERABERABERABERABEZAApDogAiIgAiIgAiIgAiIgAiIgAiIgAiIgAj1OQAJQj19gnZ4IiIAIiIAIiIAIiIAIiIAIiIAIiIAISABSHRABERABERABERABERABERABERABERCBHicgAajHL7BOTwREQAREQAREQAREQAREQAREQAREQAQkAKkOiIAIiIAIiIAIiIAIiIAIiIAIiIAIiECPE5AA1OMXWKcnAiIgAiIgAiIgAiIgAiIgAiIgAiIgAhKAVAdEQAREQAREQAREQAREQAREQAREQAREoMcJSADq8Qus0xMBERABERABERABERABERABERABERABCUCqAyIgAiIgAiIgAiIgAiIgAiIgAiIgAiLQ4wQkAPX4BdbpiYAIiIAIiIAIiIAIiIAIiIAIiIAIiIAEINUBERABERABERABERABERABERABERABEehxAhKAevwC6/REQAREQAREQAREQAREQAREQAREQAREQAKQ6oAIiIAIiIAIiIAIiIAIiIAIiIAIiIAI9DgBCUA9foF1eiIgAiIgAiIgAiIgAiIgAiIgAiIgAiIgAUh1QAREQAREQAREQAREQAREQAREQAREQAR6nIAEoB6/wDo9ERABERABERABERABERABERABERABEZAApDogAiIgAiIgAiIgAiIgAiIgAiIgAiIgAj1OQAJQj19gnZ4IiIAIiIAIiIAIiIAIiIAIiIAIiIAISABSHRABERABERABERABERABERABERABERCBHicgAajHL7BOTwREQAREQAREQAREQAREQAREQAREQAQkAKkOiIAIiIAIiIAIiIAIiIAIiIAIiIAIiECPE5AA1OMXWKcnAiIgAiIgAiIgAiIgAiIgAiIgAiIgAhKAVAdEQAREQAREQAREQAREQAREQAREQAREoMcJSADq8Qus0xMBERABERABERABERABERABERABERABCUCqAyIgAiIgAiIgAiIgAiIgAiIgAiIgAiLQ4wQkAPX4BdbpiYAIiIAIiIAIiIAIiIAIiIAIiIAIiIAEINUBERABERABERABERABERABERABERABEehxAhKAevwC6/REQAREQAREQAREQAREQAREQAREQAREQAKQ6oAIiIAIiIAIiIAIiIAIiIAIiIAIiIAI9DiBYT1+fjo9ERABERABERABERgUBN58883w0ksv1SzrvPPOG+aZZ57sj+V3vOMd4b3vfW/N/Qbjxtdffz389re/Da+++mr8e+WVV8Jf/vKX8PnPfz68733v6/gpPfDAA+G6664LzzzzTODaLLroomHJJZcM2223XVhxxRXj8adNmxZuvPHGcOWVV3a8PEP1ALoOQ/XKlzvv3//+92HYsGHxOciU56PZ3LlzA39vvfVWeOONN2K697///bZZ04TAP//5z/Dss8/G5+1f//rX+Lz985//HD75yU9mz7xkFy0OQgLzVG6KuYOw3CqyCIiACIiACIiACPQUgZ/97Gdh9OjRTZ3Thz/84TBq1Kiw2WabhY997GNN5dFtO916661h33337VOsCy+8MGy00UZ91rdrxWuvvRaOOOKI8P3vf78wyy222CLsvPPO4Stf+UqgQfnQQw/1Sfvzn/88zJw5MyDSjR07Niy44IJ90mhFMYF2XYfiI2hLLxD4zGc+E37zm9+UOpWtttoqnHnmmaXSDsVEfIBYa621+pz6uHHjwoQJE/qs14rBSUAeQIPzuqnUIiACIiACIiACPUbg3e9+d1h77bXDP/7xjzBr1qzw8ssvV50hIs/w4cOjoMCGf/3rX9Ez5bHHHosNoMmTJwf+xowZEyZNmhS/iFdlMMgWFlpoobDaaquFX//61+Fvf/tbv5QeTwFEpx/96EfxeLvuumvkifcPX8YRdU488cSAOMVfkf3pT38KX/jCF7LNTz31VDjvvPOyZc3UJtCu61D7KNraCwRWXXXVMGLEiOi18qtf/arPKdlz8+1vf3tYc801+2zXiv8SgNEnPvGJ3N+f/6bS3GAnIAFosF9BlV8EREAEREAERKAnCOC5c8UVV8RzwRV/vfXWC3RvwD70oQ+FO++8M86n/+bMmRMOP/zw8OMf/zhuuvTSS8Pzzz8fzj///KruEOl+rS4/+uij4YADDgj7779/+OIXv9hqdn32Rwy75pprAl0QYNEfIhDsTPw55JBD4rlZwbg+/NHg3H777WuWx66F7Xv//ffbrKYlCLTrOpQ4lJIMcgKnnnpqdgYXXHBBFGhtxaGHHprrRWjbh9K0zPMa0f2qq66K3ebwbvzJT34ylBANmXNVEOghc6l1oiIgAiIgAiIgAoOFwNve9rbAy7jZu971LpvtM1188cXDRRddFEUi24hYhHjSScOrhRg9xIropMGhP7q14Xl17rnnxlPBG4tuD3m2/PLLhxtuuCFvU7Zu2WWXzeaZwZNJVo5AO69DuSMqVa8QWGCBBapORd0u/4ujkec1cZTyuoL9NzfNDWYCEoAG89VT2UVABERABERABIYEAYKb1rL55puvz5fuWjFsauVVdtsvf/nLskkHRbrnnnsu63b30Y9+NNAdoshGjhwZiCdSZOxPrCI8o/bee+9w2mmnFSXV+oRAO69DkrUWhxgBHxB6iJ16n9Ptted1nxPUitIEar9NlM5GCUVABERABERABERABAaSACNUeSNeTaeMMUQYnam/jEDKnbbZs2dnhyDuEN3w8MQqsi233DLcdNNNRZtjoOpOBqsuPPAg39Du6zDIcaj4ItAygWae1xLPWsbetRl0/te0a09dBRMBERABERABERCB3iHAUOXe0u4Qflur8wgfBJ/uL6slxLSrDF5kIt5Q3she/ljrr7++X+y5eQQ+4jv94Q9/aOjcaGyec8454ZRTTmloP0us62AkNBWB9hBo5nktAag97LsxFwlA3XhVVCYREAEREAEREAERaJBAGiR6k002qZvDH//4x8Dw8w8//HBg2O0yRoDpr3/962WSFqbBu4b4Qffdd194/PHHw1/+8pfCtPU2sG/ZstfKi1hK3vbaa6846pdf5+ff8573BEYJW3311f3qPvN///vfw+uvv95nfTtXvPrqq+GnP/1p9Mp68cUX25I1Q2vffPPN4Utf+lJ44YUXSuXJyHTUDcQfrm0z1qnrQFla5US9pb698cYbfU4N7nnrLSEjm9Wr5+TPCHJwrGcIczB+5JFH4nnVS8928qUMaX1EtHvllVdKHTc9DkzxNiRgMPc051nGWr0WZY7RThGjW3gTI4s64o3rx8iR119/fbj66qur6lmzz+ta7Kg/lIHjygYfAXUBG3zXTCUWAREQAREQAREQgSoCM2fODJdffnm2jlHD9ttvv2zZzxBj5eSTTw733ntvn5GsGDJ52223Dfvss0+fYeRp3E2dOjVceeWVVfux7p577skOsfDCC4dvfvOb2bKfodFAPBxfVttO4GXKjPCSevykjRFGR5syZUps8NjoYOyPWEEe73vf+yzb0tNlllkmcP4IHxj5MpT7NttsE0ch++QnPxmI/ePtqKOO8otx/swzzwy33HJLHL3MRnFbaaWVQhqT6ayzzoqiTZ8MClYcd9xxIe3mZxxSnrAg9hB/KcuC7PushuUTTzwRLrvsshjL6Hvf+15YYokl+qSzFYgLxxxzTExP/Wt22Pt2XQcrF9NWOCHqcO7cL15k5T7ZY489wsorrxwYfvyzn/1s2HHHHcMJJ5wQDz1t2rQ4ohJB0l9++eXsnuFeMY6MDse9wkh3Pg11g/zy7H//93/Dt771rWy0OksD869+9aths802s1VRCNhzzz2juGPlYOMRRxwRGOWJMuLpRjnsPtp0003DYYcdFtJA5lmm/5n5wQ9+EJ8jBBdO7VOf+lQ48sgjc4O3t3It0uPUW06fG/XS523vBt6Idt/5znfitfKeicQh+9znPhfrJ78BZgSdP/3001t6Xqfs8DClDIzQR101o76MHz8+EPdMNjgIzFNR7iTdDY5rpVKKgAiIgAiIgAgMIQI0AGlYYnkCAuvxLkFQIeCw2Sc+8Yk4BHyeCMKX2w022CB7gUcgYFhzvHBuvPHGTPxg1K1LLrkkIOaY0cAoGhnL0tj02WeftdlsiqfCzjvvnDU0N9988zg6FgGuEZWsIcmQ9pTLG41VG1qdximjntEIofFBsGY8Vcw4/+nTp4d6gbMtvZ/edtttUfzy6/z8+9///hjbh0Y28X3yxJUDDjigT2wghCUvHpCnPyc7Bvkj3mAIbt5ocHsBCq8tgkyb4Y20wgorxO5XJmLREKSRX2sUOds/b4qoQ0Menh/84AfDd7/73arR5mwf0h199NFR2EOIIB3pm7V2XAc7diucqJN0g7O6SZ7ci4ssskh2Pb/97W9HLzqE0O222y7YsOSIYaxL7Y477ghLL710XM1ocv/zP/+TJokCz+c///k+68mPfDH4ItINHz48ikgm4FAPTJjEK2nttdeO6f0/jvnggw/Ge2qNNdYISy21VLjrrruy5wJ1kPs97xpyrRleHW8TjDo7evTosOiiiwbEZe5NW08efjTDVq5FzLTOP54jkyZNylKdeOKJYYcddsiWG53pBt48B3bbbbfs2fzxj388XvMf/vCHVafD7wXdNk2cQQA6+OCDq9IULeQ9r88+++xYD9ln++23j88jvLyK6gv37GKLLVZ0CK3vJgIIQDIREAEREAEREAEREIHuIlAJMjy3IhxkfxXRYS5/G2+8cfyrCDnZNtJVPFTmVrw15lZEnsITqXQZqdqn4q2Spa103Zg7atSobPshhxySbWOm0s1q7jPPPBP/KkJOlq7S8M/Ws70iPlTtx0Llq38sn51PxWMlS8NxK43qLD/OK7Uvf/nL2XbyqHgYzK0Eas6SVbooVW2viCXZtkZnKsJXVV5W5nRaaaDPrXyZ75P97373u7mVhu7ciudFlg/XLDW7vpxLpfE0Fw5mFW+hbF+OWxEVbFOcVkb0qWLG8cwq3iRzPa+Kp5Rtampa6ZY0t9KojuWhjlUa+VX5sL3iURK3c+04/3ZYq9eBMrTCqSKeVNVZzt3XuUqXm3gf+nrh7xn257p84xvfqLqW3CNmlW5QsYzctz6fa665xpJkU9ZZGp4DL730UrbtySefjPeEba94icRt1CnKXPE6qqovlu7WW2/N8iAt+dq2k046KdvmZyqCV5aG9JWuY9nmimCSbSOfisCVbWvlWmSZ1JmpCI9Vx2e5WesG3jxzqXd2Ta666qrsdCpdu7L1bOeaW5krAnpLz2sOwnPDjmvTZupLVmDNdA2BebtJjFJZREAEREAEREAEREAE8gnwpZ0/vA9GjBgRPvCBD0QPGvMY4csv3YxqjUy14IILVmXuPXzwZvGBe6+77rpQaaxm6TkOngv82THZiMeHrWfqvVRsZ7wo7Ms0Hgl0lTFLuxrQBaie0f3rIx/5SJYM7wO8L8x8NwlbV3Y6ZsyYMHHixLrJiXvCl/k0ngpeE3je1POWotsPRneeSkM68ybii7/3CiGvAw88sKo8lcZ55knFV37SmL33ve8NdBczI3+6/zRrBGUmPzwpuIZ0izPvpNTzxzyFmj2W36/V60BerXDC08zqLPWdrnC+zuE1A9sis/uTul9kxJHC2w5vMKZFhncPHlZmxx57bHwG2DLdbw466CBbzO5j7mnKvN5660XvuyxBZYbuYnjhmZGW7mJmeTGcWDd58mRLEuM9eU/D1OvOd1ls5VpkB2xwJn22lN29W3hfe+21WR3kOnqvMGJleU9Jug2yHW8egrC38rzO49RMfcnLR+sGnsCwgS+CSiACIiACIiACIiACIlCLAN1OrrjiitwkxGaofPmNcT0QPvijewDdH1LBh3wQN9he+bIctt5666o8aWQgYBCnAyOAaBlBpiqTZOHpp5+OXWRsNV28fMMMgeHcc8+NXUcYuawodpHtz+hbXvCw9QhjZgS0bcXGjh0bhY4ZM2bEbjJ0fbAuNj5fRCBiFtHNyo9eRRq6ptUyGCPoffrTn86SEeDViz004mhw+4Y1MUl8zKW8WDGVL/axAWhl5hrUC1adFSJnBnHARCW6dyECEWz2ggsuiN2+qDPUT4S4dlor16EVTnSJ9IwRRpZbbrk+p0Y9pCsg3aeKrF49sP3e+c532myfKcztWlIn1lprrT5p6PpoxjOAgNJcN7P555/fZuN0l112qVpmAdHKjADxqVU8ULJVG264YZ/uZYiwFW+k2GUOLqusskpM38q1yA7YjzPdwpt6aMZzOH3G+DhNBPPvpNF9N7V69SVNr+XuICABqDuug0ohAiIgAiIgAiIgAk0RmG+++UKly0+MtWHeBsTEYdQa32CzzGlU8+eNWEKVrjt9hvymEdmqpbFv8oKFrrPOOoG/MpYX04T9fOOo4mtfJquaaRBndt999/gHh0oXlhhjA7HNYjORAbGJiL1B4FtvXuTy65k3riuuuGLVJuJ20Fg2I1i396JgPbFbvDFCF7FeUmM/K+fs2bNbEoDIOxWBaOBjiD/Us07F/2j2OrTC6fbbb4/nZv8ItFtkla58NQUgL8IU5cF6X3/TdARpNuO6WjwsW8c0rfMIjH5ENV8f11133T5B3snDlxUx0htCsw9kjpicGiKTxSjy21q5Fj6fTs0jiOPtiCcW59ANvDlXf01TT0O223OEeRMImW+3UV/4nUmtVn1J02q5ewhIAOqea6GSiIAIiIAIiIAIiEDTBPAEwQvAvgQzvfvuu2PQ5zRTGg40ygjSSiBa6+qSpqOLT6vmu5LgvdBsQGIrB15CeeYbI77hlJe20XXkTYOXv10rQXYRZvB+MWPUr0YEIPbDE8p7V8EJTygzGqN53j0W4NnS0VWqnll3s3rp6m2HAw186ow1OPE080JDvTxa2d7IdWiFE6OfeaO7V7PmhRfyaKZuIj6aIepRN+oZ19xfFy8wpZ6BlpdPY+ts+thjj9lsnCL8lbVWrkXZY7SSrhJvKnp8mVdUN/DmfAjQbyI+An1qfp33AEvTNbPs62kz9aWZY2qf/iEgAah/OOsoIiACIiACIiACItBxAsT0MAGIgzEUN6N+eWMkHuKb+EYZI8tUAhXH0YCOP/74QkHI51N23sef8TGHyu6fpitqpBatT/cvWmaY70oQ3ziiknm35KVFhKAbHd3CrFFcCQicl7RwHXn4+B10t/ExXOiKR8wNDO8sGDKaEl/hfaMPQY3ReuoZ+bXDEA4Rrkz8IU/qEo3UvNhPzRyzXdehFU5z5szJik6Mq1YsFYAaFVVpiFuXTMqB0OjrTlHZ6AbozZeD+pdnPk26PfVA8bF/0rTpcivXIs2rE8uVQNmxOybd9bqFN+fJM5l7nPuNkeh4tpvQg8DHsOxmdEXtlDVTXzpVFuXbOgEJQK0zVA4iIAIiIAIiIAIi0BUE/JDLFIjuQd4Qf/zQ4Qg/BGf1AWjphlTkEeTzsnnfoK2MihW9isjPuoj4GCh5XZUsn1pT/zW6qJFatL5Wvn4bjSzOm7g+tQQg9kFsIibGhAkTYhZ0t2vW4Ieo4plXRmcLFhOG4MOVkaRiEGLiBfk4O5SZAL/9YYg/48ePj92AEEUI+HzppZeG888/Pw4DTkygVjxl7BzadR1a4YRQad3n/HWxMjYyLStM+vvI50+99nG58KBr9ZoX3StF6ylPKgJwr5e1Vq5F2WM0m457F4GNZyHWLbwpC3HN8PAzkXf06NFhp512CpUR26q88L7+9a/HQPLsU898Pct7Xtv+/fHMtWP9f3vnASdNVeXt0iWoC5+iiAooyKooICiKoCIGgiBBAQUMoCSRjCBIRhGQnCRKBlGCSJCkICYUlV0MRBUUFF5FXSQtArLyvc9dT3m6prtmpmfeYbp5zu/Xb1VX3bp173Or+53773POdTu1BFwFbGp5ezcJSEACEpCABCQwywhkbxtuksOt+MM/cgRxDpGGSXwWfzjeNCb+JCPtNeHLE4qZS1MXMSPn/cmhUUzu8WgZr9GGsLZJapTpZxsTnvDqGa2OLHbkCe5o1zXPn3rqqSUpdxwnpCrnSQpPrec///mlSE78yoFe4xL1Tca2m/hDn/GEIp8UIgnCYqwONpF7TtY4TIRTzrvEMztzOe6JdKnj2vx5ySdyzp1mmde+9rV10eydVB8cw05wHUPRrkWa+aqyV1LXC9LBiYxFqmbcu2Ppc4So5s/wdOBNZ2n/ueeeW/odqxwiCEeSahJx8/3RLUFzL1j52er2fR3X5XJxzO1wEFAAGo5xtBcSkIAEJCABCTzNCfAHO14Y2QghCGN54Dxp23LLLWsvkyjDlglvGBMQEqSuueaaVUyUOJdFmDxRiAlXPs+KUdmyOJSPs889CIW66667mqfq9/l+9cFJ3KG/YxEy8ipJ/YY/kfAZwSeMnD8st56NVZWwCLnJghrHCUXrZYgFJLJuY97r2jjeS/yJ81kEykvEx/l+txMdh4lwaoZNtq3y9eijj46ri/EZyRc99NBDdThhPh772eMHzyQm7r2MtjLmzWc4f266taFXfXH8uc99bof3IHmgcp1Rji3PzN57713ntJrIWOR6J3ufdh577LGl2ryK4HTgTaPwTkJcZbW5ww47rCJU7Zprrqm+8Y1vlJAwxB9EoNEsfx/nMYvnIJ/vVleU63bOY4NHQAFo8MbMFktAAhKQgAQk8DQjgMv/aEYoToStRNn1118/djtCjDiYE8RGIVazyiEvTBayZ0KUIy9FWM4NEgJThC9RBk8ZVpEJI3lytzpj0shKQ80lq/OkJe9HnWwnc5LCUuyjMWcCHMZKUE0brT1M+vOS74T57L///h3VINoRkoaFAITHVg5RYwKbxyBXwKQRIaUZvpPLtO0zJuT4YUwI+8LzIHtKxLWEwoUnECIQq45Nhk1kHCbCiUk1q4+FnXnmmR0rLsXxv/71r9VRRx0Vb8e0hWnTGKNszTLrrLNOyQUTZY4++ujY7dgiRhEORH35M0ih/Dz2+xnK4iSeaYgR3QyBAk+VCI2cyFh0q3+sx3r1k+thTOhleNjl/GTThXd8rvkOwDNxttlmK7m2yOk1ns/0eL6vg+1kPC9Rl9vpRUABaHqNh62RgAQkIAEJSEACJawnr9zERKA5KQxMeMswAT/44IPjUNkyScyhLIsuumjH+bykMyeYPEbi4ShIDqEIOcmiTF6disleiCWXXXZZuTQSlUY9JFeOSQheL4Sisax0NhJWMxljye38azztuu++++qi0Z76wMwdJisxkeM43jl5ApPLjmWfNm622WblV/Zu5RF/6DdG7pA3velNI4plLw1C85qhb3vttVeHlwZCDl4WYbfffnsdsge7OeaYI04VoSh4MjHcdtttq8cff7w+zw5ePxdddFHx2hiLl0DHxTPf8LzttttupQ4SChOK0mvlJzwIsicQwmO3cWreY7T3Ex0HBLV+ODHRziILyXd5PrMh4H3qU5/qEEzz+by/3HLL1W+bebAQ+cjxlI3PUfYsIpQz8sBQ7uyzz66OP/74jmec5/3II48szxTfBS984QtzlR35wBBq4zObC2XPO+6fvQEphyfKWmutVV+C6JeXTOcE3xnxXZRXK+t3LOqbjbJD/3P7Kd4tPJJjfH4JqbrwwgvrWrMANF145zBTuK+44oplZUD2EVr5nPHZZ/XAttDV8X5fAyUn7u73eanhujOtCDxj5oflyWnVIhsjAQlIQAISkIAEnoYEmAjyB323idd4cCC+kNg5LzEe1zNRiMkZx5gErbLKKkVgwTMHEYXkzc3JBN4fTEpjMo04wGQkwkxWXnnlIl4QgsZ+c7LMvRA0WGY5vITwsFh11VUrxAU8j1iSnlARJrYsO4x3wfbbbz9iEkpdGNczgcP7pjlR/b8SVWkvk+VI8BrHu21Zyn3rrbcecQpGSy21VPGAIaH1lVdeWSbgFIQH77M3FZNehItubaL8xRdfXEI5ttpqq457hVcPbPGgyYIWjJphXIwRE/DgSWWsAsfS0UyE8dZBsEGomnvuuTvuNZY3eHAQxsO9yRWVJ8ht1/N88ZwhFlxwwQVtRbuem6xxiMonwonVzSLRN/XBl0S8d9xxRxGImmPMs4LXVdN4trfYYotymDHhc44gi1hC0vVmPXE9z8uNN94Yb4sYh5gaxmeAz2F8hvD8oY18hjByF62xxhr15zSuiy3X81ndd999yzMbx/OWNuAFFkuk41Vz6KGH1uFdlEXgImwKkZNnBS9CBM2mZ9xExiK3Ke/DFRGqF8Nctm2/WzgVAupTzTs+T21tj3MIvYSUNoXasX5fz4rnJdrmdvoQcBWw6TMWtkQCEhgAAvzRxy+58eIX+vnnn7/8ATYAzbeJk0iAsWdywx+e/FLG6kuERiy99NIV7uO43/NLIyt4MKlkUqyNnQDs7r777jKB4fMGb/44/dCHPlSWwh57TYNTknCSHH41npYzScMLhQkXz1+vlYdYPprJAatMITAgoMSv4Ig8LCvMhJJf60855ZTSBAQlhADuEUb4ARNXnm0ECCa4GKEJe+65ZxTr2JIIlgnVPvvsU0QJ+oo4g1E3wgleMeHpglcJkzrOZe8jyiOScT2CTC4TXhOUDyFtPKES1L3eeuuV0KzPfe5zpZ2ZEefD4ILHRRZ/OIcnTm5TlI/24F2Sf12P8215ZrrlGEKoQ5Rjss+km3si9oRnEoISPPsRf2gTSX8ROxBAIgF1tLVtS1gNzxgeMhOxiY5D3HsinOg/4iGfl8svv7yDL58Xjt9yyy1FEIn7ddvy/X/QQQcV8ZXPSw4b4znab7/9yjg2vfIY02x4x73mNa+pjjnmmDL2fAbOO++8ugi5fxBNw/AcRKRt+wzhCYRwk8tQL+JQPLPZX4DvFsZ4kUUWqQ4//PDy+ScPVeSi4jsAb6VlllkmmlFvJzIWdSWNHYTlJqdGkTG97fYZe6p5s/Q7z91YDQGQ72Seify9N9bv61nxvIy17ZabOgJ6AE0da+8kAQmMgQD/0eVf28ZwyahF+MPqve9976jlRivAH0l5ZZYoz8on+Rf1OO52eAnwRxZu173+6OQP6UMOOaTil2xczfnDn4mENnYCTCD4lblpV199dZl4NI/7fvwEENZY3YtJHpO5BRdcsGPSwEQVESaHYzXvwi/LTFIQNJj08x2ZJx7N8vGeEC08nhC9uDevsVwX18+K7c9+9rMievF5jdXT6BeJqQln4sUECdEfoQ1Pm9GSp86Kdnarkwk8CWIJL5prrrkKz7Zx61bHdDk2K8dhIpzwqgqvLMSxCLHK31UIBogivYzcVzz3PP8IhdSx2GKLFcGWPC8I34QB8sILjlcIos06CYvkRym2eGfh8Uf5qTQ+/zx3fFfQTgSeHMbY1paJjEVbvbPq3FTz5llYaaWVitDN3xQ8Z295y1vq70meHxjyQwlCMF53YaeddlrVTGTOuX6/r6Net8NBQA+g4RhHeyGBoSFAwsBek+p+OxlJCPu9Pq7jD31+0cI1nz92tKcnASaD/MqK8Qsw3gw8F+Qzwb2dPBmEhDTDO56etPrvNd5U/PJOKI02awgwWWyuzpPv1AwjyOdiH9GGBK+8xmPzzjtvxWs6GYIOHh3ZeA4R+ae74XFImNow2Kwch4lwIh9LzskSrLN3TBzrtcVjjdCvZj4uyhMyNx7DK2s8nlnjqXusZfn845HEa7w2kbEY770mo/xU8+ZvDTyxMLwR88pkHENw44XghiCJ9zEhoditt97aVQDq9/u6VOo/Q0PAJNBDM5R2RALDQYBfg8OYmJCDgEk1Lr68+GWQX0KykZwxzhMrjyv8CiusUBfJddYH+9jhP04m94T8rL766n3U4CWDToBf2wihwXgOCQ0hzIJf3HGX5xc3JpAf+chHBr2rT3n7yaVBuFCEszzlDbIBEpCABEYh0Lbq1CiXeloCHQRyEnnCZ0ez1772tXWREI7qA+5IIBFQAEow3JWABJ56AiHW8Gsyy67i7oorPjHnvPjFupkLgqVx4zyT8mWXXba48ccv27PiP8JuK7489fRswawm8LWvfa32UPvkJz9ZL8uc74tQyDK8efWTfN798REgn0RT9B1fDZaWgAQkMOsIEFYTlvfjmFsJ9EMAj54w8qrxA1Qv47nLudfGkvS+V10eH34CCkDDP8b2UAIDRYC4eIylVZlI92tcG66ws0IAmi55H/rl43X9Ebj++uvrC7u58MdJno8NN9ww3rqdIIGm6DvB6rxcAhKQwIQIkAuKH6nIu8IPA2HkhyNB8xlnnGGoeEBx2xcBPHo+9rGPlWsJhWbZd7yOsxBEbkq8ZFkcIVYJxEM9L/ve1829aKgJmANoqIfXzklg8AiEAPTGN75xwo0njwCW3WgnXOk/K1AAmiySg1UPyTvDSAb61re+Nd6O2JIMl6V5I2noiAIekIAEJCCBgSTACmef+cxnRrSdHIaRBJq8OGPJozWiEg9I4J8EWH0RIYjtbbfdVu20007lhWcsP3SSkzLnzcT7mBB0/0b1EWojoADURsdzEpDAlBNArCHcYzJWsiAxHnV1W253yjvmDYeCAKGGYazwxa9u+Vici+1aa63VsdxvHHcrAQlIQAKDS2Duuecuob7kfyOxc/w/QA4gvDLwEGJFLE0CEyVAPjy8er73ve9V3/3ud6sZM2aUHzZ5zliAgpXkSHmwyiqr1KsXTvSeXj/cBBSAhnt87Z0EBo7A7373u0n9o4lcQiSJZpWOXr+IsBQySaRxq2UZ1bH8YterrokAZ7Uy2oFoRTv4A3M0I+6b9lN2ttn+9ZXOUrP8KvS85z1vtCrKef5oZTlZlhCec845y5KyrHDFHxq0a7yrk8RN+QOF9iHG5ZA+WHNuLH2Mutjyq+svf/nLspQp3jUsfTuawejhhx/uWJqW96xAkts0Wj2cX3jhhetVqa677rpq5513Lku8Z/a5Hv4g44+2WC44n8v78L/zzjvLMtP0ib71Wvo3Xxf7LAeLdxLhjiz9vMACC5T+xfm2LSva4aUECz4vYxVfaTPjweQnlszmPnzWyOXFsxeTorb7N88xceI6w76aZHwvAQlMFwJ85xnmO11GY/jbwd8DLAnPS5PARAn8a7Yw0Zq8XgISkMAkEDj22GNHnfgx4RyrbbPNNmVS3U0A+vWvf10dffTR1WWXXdZRHas5rbfeetW2227bsy1ZAMpLwDIJ33///cuEmP+wmVRz/tFHHy2vk046qeNevCG2+9BDD62uvfbajnMIMLvvvnv5VSdOkIOG+u+///4y2Q/X30suuaSsQnXOOedUlPnRj35ULkFM+sAHPlBtt912XcUgli4nhwGrrTVzJeFijACEIBGx5dGOXltWbTr11FOL6EN90b6rr766uC9fcMEFZXlSRAeMPrLE8qabbtoqWFCeZ+Pss8/uuDX9Y1UuXiHm4Ca9xx57lP7kNsAIxmwpgzHGO+ywQ09xsONmM9/wxxfXhxGPz8p0a665ZkVicMIOsxhCCAB97mWIKCwZf9hhh40IFXvDG95QxppQsl72q1/9qjrggAOKyNQsg4j06U9/uuP5yWX4JfGII46oBa04x7hvvvnmI5a+fuCBB6rNNtusuu++++rx5RoST5Lw+qyzzirPHqvkxbivvPLKRSQbbQWTm2++ueTMQKyNkDnawa+aW221VTTNrQQkIAEJSEACEpDABAg8Y+bE5MkJXO+lEpCABKacACuDhYDAzXNelrE2BsGDmGqMiSYJ8xZZZJHq0ksvra666qpynAk0AtHiiy9e3ud/EFoQZzDcc5nAY4g573vf+8p+t3+abSWJZOQRwPNo/fXXr57//OdXBx98cD2JJglgtJWwo6233npE1dwfIQDBg0k3Itnll19el0NMoM0hknCCr3+EF5JWInoxiUdsQLgiqWAIF3AYqwAEryOPPLK+b+wg1IQogJcJHiq5Tu7xxS9+sXg+xTWxveGGGzrECHgstthi1fHHH1+LBXgoIUAgviB+EZrVNO6L8BPbOH/UUUcVASfet20RzBgjxrmXwfpd73pXeQ5e8pKX9CpWvJgQn0KA5LrVVlutjCF9C+vVPsSwvfbaK4qVuH88xxAbDzrooPr4+eefX1F3GB5ReC4h1mHLL798Wb4eLy3EuxDHVlxxxerAAw8szwbl8A5bbrnl2O2w7bffvvrJT35S4RGFO/pCCy1Uffvb364FRcaez1Q3zzrawj0///nP13VyX8oiJIUYVJ+cuYOYyGdVk4AEJCABCUhAAhIYHwEFoPHxsrQEJDANCExUAMoT53e84x1lxY7stYE3wgYbbFAEC4QRJq/NUKosACH4RNJHJt8IQzG5BtcHP/jB4h2CSIHHSxgrh7DaGYYIRbvmnXfe8h7PDoSOELrOO++8isTYiCh333138TrZbbfdStn4h0kzK49QF0buo5yk+JRTTqne+c53RvHq+9//fvXRj360vP/6178+QujCMwghajwCEKE/eA1985vfrL7whS/U92KHxIQIHghcGGIYYkp4HsHm4osv7gjVQozAgynEI0SpCEfDIwXvEIQHDJa8J7yMxIiEiiFOZFthhRWK4IZAE0ab8JAaq+EBs84661SEK45mPBe9BMFddtml+upXv1qqIFcQIl4IdIh3eK9hCCh4LiHQhCGOwDMMr6TINwGzvAIIwt7nPve5UhSPI5avZ7wx+g2j8GhDFIQxbcPgddppp5XziDWMGc8knGNMSsGZ/yBavfvd7y5vKUsb8LLDtthii+KNVN6kf7JgyHN23HHHVXl1tRtvvLGIefle/QpAsL7pppvS3Sdn9+1vf3vH52pyarUWCUhAAhKQgAQkMPkEDAGbfKbWKAEJTGMCTF6z1wQiRRZ/aDoeP4QUMSFHnGDyHB4+3brGpDqM8hF+hTcEXjl4ZTSNCe0+++xTH953331r8YeDeOIgTOy6666lzCGHHFKde+65RQxggswLwShPaAmRCvGHi/A+wTuJMCWM0LAsACF0hYXwFO/ZIg4hAI3H5plnnooXXjZZAOomAODFgdcPS5tiCCqEJIVHFMfwQInJP8JFiD+cQxBhbCImnjA6RBFy2MCPF0Ic3ihhrJDx0pe+tMMLKIslUa5ti4CF5xbiSZsnEHXsuOOOJacSnj3ZfvrTn9biD8fpR4g/vKdNCEe0n/4j7IVIxTMGzzCekxB/OJbr4T0eOWGImSH+4BXEtdkQggjJ45lBWCN/EcIJIhz18nzxIvcFAmEYomeIPxyjLOFihKBhP/jBD8o2/4M4lL3FCG3M4g9lWf0E8ZMEmBO1H//4x7VX20TrytcTjpk/V/mc+xKQgAQkIAEJSGA6EVAAmk6jYVskIIFZTgCRJIxQKbwruhniR4g+TIaZ8May8t3Kc4wJLaFHTNDJCYNo0yuRLx5EIWzQhmWXXXZEtTlsB/EGr4o8uSeJcRieGlkcieMkBA7DcyUbE9cw2o2HEEmOw6ifiW0/iXxzO6kvRJqoO7a0mbYjNGAIK4gmiDiIK3Gcc92EGrxG4BcsSaK99NJLU7xYZrTkkkvWYgjeV3jKIGb0egaijm5bvJV4LvDEQWDCmyq8XZrlCdlDrCOfTdgxxxwTuxXeP92SYfNMhCcZYXBhiDjRX9pOvp5s9AkRjTA+chAh3mA8P1nQ68Yz6sH7KDyrECdpI8nBw5oJmjfaaKM4VW9z4uu//OUv9fHYyW3hGegWXkZZhLzJsP32268WpMZaH4JYvOKa5vt+np+oy60EJCABCUhAAhKYSgIKQFNJ23tJQAJPOYGYUNOQHB7VbBhLuzKRjkk9yWl7CUCEzTBBRzRiYr7qqquWkLCmCJLvgXAQhkdKTLbjGNtmija8l8idE5br7zV5zuJNsz5CV/DAwci1QlgUwgaTccQSziMK9WtZmGmrAw+gLPTgqYE4R16ZbISWkYemafCLvDWEfmUBiMl6WBbIEDB6jWeUH21L3TxD8RwhsCHUEa6F4JMNT5cQgBBislcSImG38SecMIyQwDCSRochjmSRK44jyDRFGcK3ck4dklb3suyJwzNNOB3PRFjmSg6hbkJnfj5ZlS4bz2J4ynG8rS35uonsI2BlEWsidXmtBCQgAQlIQAISGEQCCkCDOGq2WQIS6IsAXgjhOUEFzdCvZqWIQGGs9NTLrrnmmjqshjJMllmWu9vEPOq49dZbY7eIF+RpGc3w2MkCUJ6Ed/Mgob48CW8KQIhGhKkhWoQRhkWC7DBWeNp4443rHDFxfDK3ePFkI8cRlsUK3ke+IvZ7WfZqokwWwLqF4vWqp5/jhIYRBsULZu9973vr5w3G9957b1minW02QqwiF1A+nvcjF9QTTzzRIZbNP//8uVjrfjMBeX6+mxc2PXwINcwCUOYWUR89AABAAElEQVTaa9n4XKZZP/mp8mcx8kI1yz0d3pvQ+ukwyvZRAhKQwNOXQPPvj6cvienRcwWg6TEOtkICEpgCAt3CUMZ621tuuaWjaBZT8kSWQggXhI8hnnQzro0JPefxDCHn0GjWFEpy+V6T7V7HuRYBidwy5J/5yle+kqur9wmboT+UmVXWFBDCyweRIAxvIhIEj2Z4bWXLIhkro03UCJXDg4d8TG3GpJ7Vu8iDE4awRUheUwBiJTa8rtos2o6wmI0k5WO14DqW8pkb5bMHEu/z+Swyci4sl4ljsb3zzjtjt2ybSdY7Tg75G/8wHvIBtnsSkIAEJCCBaURAAWgaDYZNkYAEZi2B2Wbr/MpjSe82YzWpsKaHTRaAKMNS1njPkHsl3rOcdYT9lIP//IeJMSt2hQiEJ9Lb3va2XGTc+70m272Oxw3w9CD5LiuOffe73y2rixGCRR6jMMKZCCdqiitxfqLbfC/qinCivIQ6IttEGbWJYWPtA+INgtgjjzwyqgcZK8wh0ET/IgdTzsvEfennWPvW7EPT46mtHyEiRZkcYhbHYtsUmtq85Xo9Y72Oxz3ytq0tudxE9h966KGKVeom20ig3sZnsu9nfRKQgAQkIAEJSKBfAp2zoX5r8ToJSEACA0CgGS7DhLDN/vznP9enm4loswCE9w6TfVYDI/Fu5HPZaaedyvumeESlrG4UAtA999xT36ffnfFMtuMe559/fkkyTH4axJ0s8LBKFcuqRxgWHi+9PJqivn63d9xxR8elJC7GXvGKV3QcZ9n3vBR6x8keb/I49cOoR7UlzC/nFOpWDrEGpiEAxUpriH/ZxuOZg2DHfRkfbDzPDrmSsjU91/K5aHMca45F5hplxrNthuPlz9po9fR7b55nEmhPtrFa2+GHHz7Z1VqfBCQgAQlIQAISmHQCCkCTjtQKJSCB6UqAX+lZ1SoS8JLYuZchNuRJ8HrrrderaJ1nhgk/KxuFNwcCD6FTebWjqIQyMRklgTET4LxqUpRjS3vPOuus4l1EkuawPBHOS9HH+dG2hPUgVrEs+CabbNJRHJGBFbmiL9kbqqPgJLzB8yhbJFVuek+RNDgvNZ6vQQjZa6+9KnIp4XkV1g+XuLZte/HFF3ddda15TQ73ivxNPCeswHX55ZeX4jwHu+66a/PS+v3xxx9f3XzzzdXRRx9dnjX6GAIQzzChctlbqr5w5g5j+POf/7ysSMeqcjkxN3mtcsLsfN1dd92V347gnrnm57DjopY3eEHRnvgMkrx7rNbP/ah7/fXXr5rC01jv2VZuKhJYt93fcxKQgAQkIAEJSGCsBBSAxkrKchKQwFAQICdLCEDf+ta3SkjIPPPMM6JviCJheHHkJdk53msCzCQfwWeXXXYpl5PcF0GiKVyss8461UEHHVQnwmVy3y3PDqExn/3sZ0t4WTOpNLlownJ74hjbtslynMO7pykAcW0IFuw3PaA4Nh5D5Goy5HqSI1922WV1VYgb4TH16le/ukOwO/bYY4sg1S3chpxL3/nOd0asfBV95Aa9GNU3H8cOwgp5e1g5rZeR6Ds8qEi4Pd9889VFP/7xj9cCEGV43tZcc836fOywCt0hhxxSEjBH+BerzOHNEkb44R577BFv6y3CECGJ5I7iWryHuO8RRxxRylxxxRUlsXa3HD4XXHBBXQ/PRnOp87FwzWXqytIOSbJDACLx+NZbb11yJKUiZTevmMeBfseRsWobr+Z9fS8BCUhAAhKQgASGjcAzh61D9kcCEhhuAiSPbYZuNRPUthHAqyR75CAIkc8lGyseIc6EHXjggR1JbzmeExQ3Q3jWXnvtkvslrt9yyy2rSy+9tMpeNIgYOakxeXbw9MiTZvYJzyK3EG3OHkIIQzmpdbdQIK4PAYK2UD7XH+1DZOA+TcvLsBOyNhHDOydC46IecuLksDJCoz796U/H6bIlP1GID4zLtttuW1ZYy4UQ8i666KLq/e9/f/WOmaF4YayYlT1wYNSveBB15u32229fPLOaS5xT5sEHH+zoG8JLNlbUoi9h1NXkw3MZfA499NAoWvLNkJw77JRTTinPTrxny/Ox9957l0NbbLFFfQqRBU4Y4gt8m/a1r32tFqcQP7slKJ8xY0Z9GZ5usG5a9iKiPc2Qsw9+8IMdya95xrOoSX0waa7+xmepWa55b99LQAISkIAEJCABCYwk8IyZk4EnRx72iAQkIIHpQYCJbqy41JxANlsYQgHeFieddFLzdMd7zn/+858vx0jUS2gYKzchhlx44YXlOPUhzMTy10w6V1lllQ5RJVdKebwqTjzxxHJdPhf7iEN4q4QhXOy4447xtghHeAzhtUEyZrxa8B5CHMJYch6xoBcL+kL7V1tttZ5lol+XXHJJSV4dN+e+eEiQLJtwq29+85uljq222qrD4yTKj7ZFNGq2c+WVVy4eUSTgxuspwuwQbg444ICSHLtZL8IPAkrkTOI8TF73utdViAznnHNOuY78S3gP3XDDDUU0aN476qX/G2ywQVevmSjTawujLKpRjrA8xnXhhRcuHiyEM51wwgl1OQSU8AjL9fI8IcCcfvrp9WEEF8YAgRChg+cRLx6ScDeN/iIuhnEt7WNVNcLL4Ib4s/POO9dhipTlvoxphCByHd5MXEdYWHjI4YGFZ04s0f7www9Xa6yxRhEk4555y7PHs7/vvvtWv/jFL/Kpeh/2tCf6Q1Jm2CFyYnx28Y6jjYQGXnnllfW1zZ38uWie870EJCABCUhAAhKQwEgChoCNZOIRCUhgGhFggs9EnokjE8w2Cy+DsayMtPnmm5cEvYTPXHvttRWhWtkIe2GS2sy5w+SfthBOky3uzcQ1vCOa5SjDJDobCWRJenzMMceUUCgEkfPOO68uQjsQfMJIZBw8urWB61ntKZfhvhjlo5057Ge77bar8PbBk4ZXGH1HKMgiQ5wb75YkuVdffXURJkJ4iDrwtsIrpVeS5iWWWKKwQQRjuXr6hvjBC0O8w8MoQscId8r9h0k8O9F/zk/EEMfwoMEzB/GCJd+7GWIIYW3djDHAS2f55ZevCG8jrw+CDy+M54frWXq+myGAEKpFiCCCS76W/nJ8ww03HHEp90V8Q3z84he/2HEdhfHE4rkjZ04w5TgeSfS1+VxzDq5wxhMIT7dcJvgH+/y7E+GXiFU8/4hmCI+8whC0dtttt2qllVaKQ/WWPF2aBCQgAQjg4cl3DR7CfDcgLvM9SMisJgEJSEAC/yKgB9C/WLgnAQk8TQncfffdxVuDyetcc81VLbbYYmUCO9U4CIliRSy25IshYS1eGbPKCJ1DkIpEwCSiJsQOEQvvj+c973kTunX2AGLFMXIA8Yc5fSQcjVWp8Jpp5jZquyniAu0m7I6xwmuruax62/UTPYcgQ4LsyNcDK3LUIL4g/BFyhgCHJwveYuNhiLiC9xDiFOIbXmBzzjnnmJqMUMpzjMiCoNhc8a5XJYgxv/zlL4t3FfusVMbznwXCXtdO9nFY3n777eUZJKk1K4/hCUW7wruLVeD4TPBCnHoq2jnZ/bY+CYyHAIJpM1R2PNd3K4unLTm5BtnWWmut4vWY+8B3aP5RI5/rtT8VfAkRJu8b/2/g/cpLk4AEJDBVBPQAmirS3kcCEpi2BBZccMGK11NthNpEuM1UtKWZ2JkcQznP0KxoAxP4EJz6qR+xaKmllurn0km5JvLqRGUIEKyUFqulxfF+tog+2eNsPHUstNBCFa/xGl5XiH28nmqD5aKLLlpeuS200V/xMxH3n84EEJkn6sHY5JdzpTXPDcp7hGu4NEN0x9v+qeCLtyMvjAUFEIMWX3zx8TbV8hKQgAT6IvDMvq7yIglIQAISkIAEJCABCUhgSgkQ2hTGogbk6SLfF95zvMjjRQhmNsJV4/yNN95YQmnJ+xWW64xjk7XdaaedSm6yyaqvVz0s1oC3z6677tqryJiOZxazim+EL0eDeuVMi/NuJSABCUwmAT2AJpOmdUlAAhKQQE0g/0pNeI8mAQlIQAITIxACBV57eI80wyAJjyTfW/7+JddWGOLQsssuW73xjW8see5YaY/cObPKvve9783S+pvtJtR4IjYVfPFWyp5KTW/cibTfayUgAQmMRkABaDRCnpeABCQggTET4Nfnn//85x1/3HIx7u4cJ8SMxNeaBCQgAQmMnwD507BPfepTI8Sf8dSGcMTqirNSAEJMmZXiUrf+9lpMoFvZbsemgu/nPve5kuOMvG/kipuoaNWtHx6TgAQk0IuAAlAvMh6XgAQkIIFxE/j+979fHXHEESOuYzl7XiTlVAAagccDEpCABMZEIAQKPHgmaq973etKFSwAMCuMlQ2n2iZLAJqVfFkcIK/uOdWMvJ8EJPD0JqAA9PQef3svAQlIYFIJsKQ5Xj6EGeTQBELAHnvssXo59km9qZVJQAISeJoQQKzh+3UyVogkKT91/eEPf5h0enznH3TQQZNe76yucFD4zmoO1i8BCQwvAQWg4R1beyYBCUhgygmwRDovTQISkIAEJp8AYUNLLLHEpFVMLiGSRD/55JNVL++Zxx9/vPrVr35VEdI1//zzF0/OZz6z9zoy1HXMMceUZc77bSieTnfddVdpEzly5pprrjFV1asPY7p4ZqGp5ItI9tBDD1V4BPWyf/zjH6XM7LPPXj3nOc+pi8H4vvvuK0Ig57oZ9d9///2l/vyDTLey+Rj3vPPOO6t77rmnmm+++cp4zzHHHLmI+xKQwAATUAAa4MGz6RKQgAQkIAEJSEACTx8Cxx57bEny3NbjXoJAt2u22WabMtHvJgAhMJx88sn1kuVxPV5D73rXu6rddtutevGLXxyHy/b888+vvvrVr1bXX399x/GPfexjHe8/8YlPVMstt1zHMQQfvIYIJc5JrClE+PBaa61VbbnlllWbGDFRAWhW8p0xY0a1ww47FOHmT3/6U93HU045pXrnO99ZWDzwwAPVZpttVso8+OCDdQ6lPffcs/rwhz9cnXXWWYXtD3/4w/r6DTbYoNpkk01KXiEqYVl5EoQj7IXxw8x2221Xvf3tb49DI7YIP1deeWV12GGHjcjjR56i/fffvzJh9QhsHpDAwBF4xswv/CcHrtU2WAISkIAEJCABCUhAAhIYQeAtb3lL9cc//rE+/pvf/KbeH+sO+Xs22mijIjIg+CAy4HnEMvKnnnpqqYbjBxxwQLXmmmvW1b773e8ek+fPXnvtVW288cb1dY888kgRJyJpNAIROYpuvvnm6tJLL60FCTyWTj/99OKZUl+cdlhSPfLMIRqxNPxkW7988aJaddVVRzTnuOOOq48jDDWFMS4gZ9BPfvKTkrR7mWWWqRZaaKHq29/+di0QveAFL6guu+yyap999qlYZv6Vr3xltdRSS1U33XRTddttt9X3POOMM6q3ve1t9fvYwVsIcYo6MASf1VZbrdR//PHHR7HqqKOO6hjv+oQ7EpDAwBBQABqYobKhEpCABCQgAQlIQAISaCfQr0ARtbJi49prr13e4uHz5S9/uVp44YXjdIVIgSdOJHnG6ydWsvr9739f/f3vf69uv/32ChEn7Oqrr47dskWwIAdRGB4tH/nIR+JtteOOO1Z4J2GIE+uuu26FuIPRNrxUutl0FoAIpUOMQ5Chf2FZAKKvlEHA22qrrWovnyiLGIPIhlH2Pe95zwjBbdttty3ePhH2hdh29tlnl2vwBLrgggvKfv5nl112KZ5bHMPTCr5x/eWXX16PBaLftdde2zF2uR73JSCB6U+gdwDv9G+7LZSABCQgAQlIQAISkIAEJokAogJiQBhCQBZ/OE5emF133TWKVDvttFP1t7/9rbx/6UtfWi2yyCLVAgssUJ9nh2P5lcUfzjeTWnOPMISIQw45JN5WF154YXXHHXfU7/POREPAcl2TvU/oGh5MeCi9+c1v7lo9fcV7By+dDTfcsKPM7rvvXos/nKAs4WLZEIc++clP1uIN5/DkCkO0w9sqG8cI2wtjmfoQfziGyBReVYTm4UWkSUACg0tAAWhwx86WS0ACEpCABCQgAQlIYNIIXHHFFbVHCd4ehBt1M46H1w+Jk7/0pS91KzbmY4SXISoR/oTnzxprrNFxLaJIzjd09913d5wftDfPetazRm1ys0wWcuJiVt3MhmdW0+add96OQ+QWykbC7jC8f+aee+54W2+XXXbZev+GG26o992RgAQGj4BJoAdvzGyxBCQgAQlIQAISkIAEJp0A+WPCll9++Wq22XpPFcgxE4mGf/SjH1Wbb755XNrX9uMf/3jFKxueRSxTf++99+bDJfyp48A/3wxTatPszcRYdEt+nT11QLD44ouPwNJcsS0zwuOLXEJh3OO6666Lt/X20UcfrffJZaRJQAKDS6D3t/rg9smWS0ACEpCABCQgAQlIQALjJHDLLbfUV3TzBKlPztzJy5KToBhhIYsWuexY9xEkqOuqq64qq1lFUujm9axYNcjWFGW69SWXaYbIRflcBo+tpiBEuVyG91kAagprhILlcDDKNy0nGG+e870EJDD9CSgATf8xsoUSkIAEJCABCUhAAhKY5QRI8ByWhYI4lrdZ7CE3DNe+6EUvykXGtU9o0c4771yv+MXFSy65ZFlynlWv9ttvv3rVq14Vj9bmXtdNx+OZbzdhhzbnMs2QsehTUwCK42ybAtCmm25arbDCCrnIiP3ZZ599xDEPSEACg0NAAWhwxsqWSkACEpCABCQgAQlIYEoIRGLnXjd77LHHOk7hgTIWI8TonnvuKat5hbCB+PP+97+/vhzh58ADDyxJk+PgEUcc8bQSgKLfbLPQM5bjYy3TFOxe8pKXdF0mPtfnvgQkMNgETAI92ONn6yUgAQlIQAISkIAEJDApBF71qlfV9Tz88MP1fredP//5z/VhlnWfa6656vdtXifnnntuWWmM5eIxwrliyXfes1LWV77ylQ7xh+NNI1zs5ptvrh544IH61DB5AE1FX3JibSBmD7AaqjsSkMBQEVAAGqrhtDMSkIAEJCABCUhAAhLoj8Bqq61WX0iCZ0SWXvbrX/+6PrXxxhvX++w0PVaymBH74f3zm9/8psp5ZVjJ6tnPfnZHfbwhzCyMOr7zne9Ua665ZvWDH/wgDg/VNuc5CmaT3UGEOpZ5DyP3Upsdf/zxRazLbWsr7zkJSGD6EVAAmn5jYoskIAEJSEACEpCABCQw5QTWXnvtKkK5EFx++MMfdm3DbbfdVt100031uXXXXbfeZ6cp4ORwsljCPVYYayZ6XmCBBTrq4s2Pf/zjjvAvBIjwIMqFs1DSJl7la56K/bEIKLkvvcrnMr360SzTfJ9XXvvtb39bkm93qwvB75BDDqkYvzYPr27XekwCEpg+BBSAps9Y2BIJSEACEpCABCQgAQn0TeDOO++sHnrooY7rx7NsN6Fc55xzTi0CbbXVVhUeOtn++te/Vrvuumt9aN999x2R/JmkzUsssURdBm8d7He/+13105/+tGJZ8/ASWnTRRcu5+OeSSy6J3bJlCfLdd9+949iMGTNKHiEO5uTH2ZMIYSkLTx0V9Plmony5LcJUDp/L+7lZ9DGMfj3xxBPxtt7edddd9T79vf/+++v3sQPzbPfdd19+WxJtb7vttvWx7bfffsRS8I888ki15557ljKHHnpoXdYdCUhg8Ag8Y6YK/OTgNdsWS0ACEpCABCQgAQlI4OlNgJWxyKmD5RCpblTCs2e55ZarTjrppG5F6mPXX399tf7669fvV1555er1r399hShxxRVX1N44BxxwQLXBBhvU5fLORRddVO24447lEPf+6Ec/Wl166aVFBELkyQLRCSecUB188MH15XgirbLKKhVixcknn1xWBqN89jqi8Mte9rLqsssuqwgbQ1jqxoB777333tUHPvCBuv6x7kwmX0LVPvGJT/Rs41prrVXttttu1RprrFEYdWsjAt2JJ55YIbr94he/6FakiHespobww7PRiwljevjhh5c6EKX233//6vTTT6/rfOUrX1lWYHvOc55Txg0PoM985jPVRhttVJdxRwISGDwCrgI2eGNmiyUgAQlIQAISkIAEJFDhAcIEH5EDcaDN8KShbDcvkeZ1yyyzTBF6TjvttOq8886ryA2T88OQN2aTTTapll566eal9fvVV1+9+tnPfladeeaZ5b7HHXdcObfLLrt0iD8cRBghIfEXvvCFIvZceOGFFS8MkQfBasUVVywixSmnnFKOv+ENbyjCDn0PT58mg+gz235sMvni8RRjlb2WaFeEweFpg3BDn5pl6APl8ASiv7kMx+l79Jff9ynH/YJJlIn75eTZ5GNCJMMz69hjjy1iGoJP5HniXohOH/rQh/rB6DUSkMA0IqAH0DQaDJsiAQlIQAISkIAEJCCB6UQAwejWW28tosOcc85Z4Rky33zzjbmJhIzdcsstJeSLVcbmnXfe1msffPDBsroXYsYiiyxSLbjgglUkjOZCwqEQU5pLmLdW6slxEUCE+v3vf18EJAS4l7/85RVjr0lAAoNPQAFo8MfQHkhAAhKQgAQkIAEJSEACEpCABCQggVYCJoFuxeNJCUhAAhKQgAQkIAEJSEACEpCABCQw+AQUgAZ/DO2BBCQgAQlIQAISkIAEJCABCUhAAhJoJaAA1IrHkxKQgAQkIAEJSEACEpCABCQgAQlIYPAJKAAN/hjaAwlIQAISkIAEJCABCUhAAhKQgAQk0EpAAagVjyclIAEJSEACEpCABCQgAQlIQAISkMDgE1AAGvwxtAcSkIAEJCABCUhAAhKQgAQkIAEJSKCVgAJQKx5PSkACEpCABCQgAQlIQAISkIAEJCCBwSegADT4Y2gPJCABCUhAAhKQgAQkIAEJSEACEpBAKwEFoFY8npSABCQgAQlIQAISkIAEJCABCUhAAoNPQAFo8MfQHkhAAhKQgAQkIAEJSEACEpCABCQggVYCCkCteDwpAQlIQAISkIAEJCABCUhAAhKQgAQGn4AC0OCPoT2QgAQkIAEJSEACEpCABCQgAQlIQAKtBBSAWvF4UgISkIAEJCABCUhAAhKQgAQkIAEJDD4BBaDBH0N7IAEJSEACEpCABCQgAQlIQAISkIAEWgkoALXi8aQEJCABCUhAAhKQgAQkIAEJSEACEhh8AgpAgz+G9kACEpCABCQgAQlIQAISkIAEJCABCbQSUABqxeNJCUhAAhKQgAQkIAEJSEACEpCABCQw+AQUgAZ/DO2BBCQgAQlIQAISkIAEJCABCUhAAhJoJaAA1IrHkxKQgAQkIAEJSEACEpCABCQgAQlIYPAJKAAN/hjaAwlIQAISkIAEJCABCUhAAhKQgAQk0EpAAagVjyclIAEJSEACEpCABCQgAQlIQAISkMDgE1AAGvwxtAcSkIAEJCABCUhAAhKQgAQkIAEJSKCVgAJQKx5PSkACEpCABCQgAQlIQAISkIAEJCCBwSegADT4Y2gPJCABCUhAAhKQgAQkIAEJSEACEpBAKwEFoFY8npSABCQgAQlIQAISkIAEJCABCUhAAoNPQAFo8MfQHkhAAhKQgAQkIAEJSEACEpCABCQggVYCCkCteDwpAQlIQAISkIAEJCABCUhAAhKQgAQGn4AC0OCPoT2QgAQkIAEJSEACEpCABCQgAQlIQAKtBBSAWvF4UgISkIAEJCABCUhAAhKQgAQkIAEJDD4BBaDBH0N7IAEJSEACEpCABCQgAQlIQAISkIAEWgkoALXi8aQEJCABCUhAAhKQgAQkIAEJSEACEhh8AgpAgz+G9kACEpCABCQgAQlIQAISkIAEJCABCbQSUABqxeNJCUhAAhKQgAQkIAEJSEACEpCABCQw+AQUgAZ/DO2BBCQgAQlIQAISkIAEJCABCUhAAhJoJaAA1IrHkxKQgAQkIAEJSEACEpCABCQgAQlIYPAJKAAN/hjaAwlIQAISkIAEJCABCUhAAhKQgAQk0EpAAagVjyclIAEJSEACEpCABCQgAQlIQAISkMDgE1AAGvwxtAcSkIAEJCABCUhAAhKQgAQkIAEJSKCVgAJQKx5PSkACEpCABCQgAQlIQAISkIAEJCCBwSegADT4Y2gPJCABCUhAAhKQgAQkIAEJSEACEpBAKwEFoFY8npSABCQgAQlIQAISkIAEJCABCUhAAoNPQAFo8MfQHkhAAhKQgAQkIAEJSEACEpCABCQggVYCCkCteDwpAQlIQAISkIAEJCABCUhAAhKQgAQGn4AC0OCPoT2QgAQkIAEJSEACEpCABCQgAQlIQAKtBBSAWvF4UgISkIAEJCABCUhAAhKQgAQkIAEJDD4BBaDBH0N7IAEJSEACEpCABCQgAQlIQAISkIAEWgkoALXi8aQEJCABCUhAAhKQgAQkIAEJSEACEhh8AgpAgz+G9kACEpCABCQgAQlIQAISkIAEJCABCbQSUABqxeNJCUhAAhKQgAQkIAEJSEACEpCABCQw+AQUgAZ/DO2BBCQgAQlIQAISkIAEJCABCUhAAhJoJaAA1IrHkxKQgAQkIAEJSEACEpCABCQgAQlIYPAJKAAN/hjaAwlIQAISkIAEJCABCUhAAhKQgAQk0EpAAagVjyclIAEJSEACEpCABCQgAQlIQAISkMDgE1AAGvwxtAcSkIAEJCABCUhAAhKQgAQkIAEJSKCVgAJQKx5PSkACEpCABCQgAQlIQAISkIAEJCCBwSegADT4Y2gPJCABCUhAAhKQgAQkIAEJSEACEpBAKwEFoFY8npSABCQgAQlIQAISkIAEJCABCUhAAoNPQAFo8MfQHkhAAhKQgAQkIAEJSEACEpCABCQggVYCCkCteDwpAQlIQAISkIAEJCABCUhAAhKQgAQGn4AC0OCPoT2QgAQkIAEJSEACEpCABCQgAQlIQAKtBBSAWvF4UgISkIAEJCABCUhAAhKQgAQkIAEJDD4BBaDBH0N7IAEJSEACEpCABCQgAQlIQAISkIAEWgkoALXi8aQEJCABCUhAAhKQgAQkIAEJSEACEhh8AgpAgz+G9kACEpCABCQgAQlIQAISkIAEJCABCbQSUABqxeNJCUhAAhKQgAQkIAEJSEACEpCABCQw+AQUgAZ/DO2BBCQgAQlIQAISkIAEJCABCUhAAhJoJaAA1IrHkxKQgAQkIAEJSEACEpCABCQgAQlIYPAJKAAN/hjaAwlIQAISkIAEJCABCUhAAhKQgAQk0EpAAagVjyclIAEJSEACEpCABCQgAQlIQAISkMDgE1AAGvwxtAcSkIAEJCABCUhAAhKQgAQkIAEJSKCVgAJQKx5PSkACEpCABCQgAQlIQAISkIAEJCCBwSegADT4Y2gPJCABCUhAAhKQgAQkIAEJSEACEpBAKwEFoFY8npSABCQgAQlIQAISkIAEJCABCUhAAoNPQAFo8MfQHkhAAhKQgAQkIAEJSEACEpCABCQggVYCCkCteDwpAQlIQAISkIAEJCABCUhAAhKQgAQGn4AC0OCPoT2QgAQkIAEJSEACEpCABCQgAQlIQAKtBBSAWvF4UgISkIAEJCABCUhAAhKQgAQkIAEJDD4BBaDBH0N7IAEJSEACEpCABCQgAQlIQAISkIAEWgkoALXi8aQEJCABCUhAAhKQgAQkIAEJSEACEhh8AgpAgz+G9kACEpCABCQgAQlIQAISkIAEJCABCbQSUABqxeNJCUhAAhKQgAQkIAEJSEACEpCABCQw+AQUgAZ/DO2BBCQgAQlIQAISkIAEJCABCUhAAhJoJaAA1IrHkxKQgAQkIAEJSEACEpCABCQgAQlIYPAJKAAN/hjaAwlIQAISkIAEJCABCUhAAhKQgAQk0EpAAagVjyclIAEJSEACEpCABCQgAQlIQAISkMDgE1AAGvwxtAcSkIAEJCABCUhAAhKQgAQkIAEJSKCVgAJQKx5PSkACEpCABCQgAQlIQAISkIAEJCCBwSegADT4Y2gPJCABCUhAAhKQgAQkIAEJSEACEpBAKwEFoFY8npSABCQgAQlIQAISkIAEJCABCUhAAoNPQAFoGo7h3/72t+rJJ5+chi2zSRKQgAQkIAEJSEACEpCABCQgAQkMIgEFoGkyaldddVW16aabVq997WurxRdfvFpyySWnScuGqxnvfve7q2WWWabaYYcdhqtjM3tz5513lr7Rv7POOmtc/dt8883Lteuuu+64rpsOhU888cS63/fee+90aNK0acNFF11Us7npppumTbtsiAQkIAEJSEACEpCABCQw9QRmm/pbescmgcsvv7zaZpttOg7/z//8T8d730wOgRkzZlSwve+++yanwmlUy+OPP17993//d2nRww8/PK6W/fnPfy7Xzj777OO6bjoUfvDBB+t+//3vf58OTZo2beBZj2fisccemzbtsiESkIAEJCABCUhAAhKQwNQTUACaeuYj7njYYYfVx/BQWX311av555+/PuaOBCQgAQlIQAISkIAEJCABCUhAAhKYCAEFoInQm4Rr+YX+t7/9banpla98ZXX88cdPQq1WIQEJSEACEpCABCQgAQlIQAISkIAE/kXAHED/YvGU7P3+97+v77viiivW++5IQAISkIAEJCABCUhAAhKQgAQkIIHJIqAH0GSRHGc95GvhRf6SsGc961lV5G75t3/7t+rZz352nOrY/uEPf6h44T0033zzVS996Uur5zznOR1l8htyf5Ab5ZnPfGZd7n//93+rm2++uXrggQeqJZZYovp//+//Vaw+hnFf7t80znNdrqdZJto/xxxzVLyaRjtIVvzHP/6xWmihhaoFF1yw1Ncsx3tWQqOPGGxmm+3/Hlfy1dx2223Vc5/73K7Jsh966KHqrrvuqv76178WNvDp1p9ScZ//kFflN7/5TWnTq171qurf//3fe9bUjT+Ff/e731UIgAsssEBp51jb+Kc//am6++67K+p9+ctfXr3oRS+qnvGMZ/S8f78nnnjiidLGe+65p3r+859fLbzwwq39zPcZzzjn62I/nnH6uOiii5b7x7l+to8++mhFf7A555yzItfRI488Uv3jH/8oz0a3zxrPenwm8vOX7x+fY47NNddc+VS9P9FnpflZnWeeeeq62aEPPA+ME337j//4j/LZ6Cg0zje9Pnt8X+CxCDueWz6/Y31uueaOO+4o33GveMUrqhe+8IVjbhXj8Otf/7rcl/6N9dp+rxtzwywoAQlIQAISkIAEJCCBASKgAPQUDdaee+5ZffWrX+24+5FHHlnxwl796ldXJIfO9q1vfas66qijqm6r+WywwQbVTjvtVL3gBS/Il5T9T33qU9Vll11W9hFOdtttt+rCCy+syxF2xgT5k5/8ZDl27LHHVquttlp9Pnbe9773lUkY72+88cYRYgCiyzvf+c5S/BOf+ES1yy67xKXlun322af60Y9+VB+LHa454IADipARx9gy4Vt11VXLIepihbR99923bgPiB0zCEJ8OOuig6uyzz45DZYs4A+/3v//9HcfH+4aJ+EknnVTBJ4SpqIO2sIrbhz70oThUbzP/22+/vYzxV77ylTo5bxT87Gc/W67vNaFm8rz//vtX3/nOd+KSsuVZ2XvvvScskkSl9JP2wbLZz0022aQ8Z90EE65nzMY7znFftt/+9rfLM/6LX/wiH65e/OIXV+TH4jnode+OC9KbW2+9tVpvvfXqvpx88snVu971rmqllVYqQmTzOYpLr7766mrLLbcsb7fbbruuK8ftscce1QUXXFDK/PSnP62Fl8l4Vnp9VuEQxrPw+c9/vv5MxHE+N7vuumu8Hfe2+dlbe+21q4MPPrjje4NKX/ayl5Xvk9ym5s34jPL5jlDXOM931RprrFHtvvvuRZCL43n7n//5n+Uz3/zO4zNN4vzNNtusqwDV73X53u5LQAISkIAEJCABCUhg2AgYAtYyooccckj1tre9rVpkkUXKlveTZfzC3mZMILNdc801FUt1NydCUeacc84pAgS/sjct34uJWBZ/oixLh4f95Cc/id16i0cGk8KwbmWuv/76OF296U1vqvcvvvjiMnnvJv5QiEk/E0wEjmy53dwbUSm3IZeFFwJYU/yhDCIGohfiWb9GHSyRziS4KYpQJ5NbRCaekdxuzuX3xxxzTMUrVmbifBjCSU4IHsfZ4s204YYbjhB/OIdQgPDEMzIZhqCAoNStn6eeemqF6JH7FPfsd5zjesQMRLSm+MN5PMbOOOOMav311y/eb3HNaFvYZPEHsRPxBwuxkrHDq6xp1157bX2oF9sQ4/CiwyMNm6xnpddnNRp1ww03VAhy3T4TV155ZUkmj1dQP5bHl2cV7t2+N/BiQyT7wQ9+0PU2n/nMZ8r3VlP8oTD1MqaMeXgO5kq+9KUvlbHr9p0HYwTKjTbaqPbsimv7vS6udysBCUhAAhKQgAQkIIFhJaAHUI+RxaMmixxMpJg8/td//VeF2DJR22GHHcrk5Ze//GXtKfPhD3+4THioO3s54FnAL91hTGhXWGGF6iUveUnFL91MzJjoMnHedtttqxNPPLEOl4prYnvmmWcWz50PfvCD1ete97oSpoVnDWFEeEIwUfve974Xxettc4JHmZhAR6HMKwQgQjAQRsKYsCGqEU507733VnhjMIlmgn/ooYf2TIIdk893vOMdtShHKFoYospVV11V3uIdgFiy/PLLlzA72nr66acX4SXKj3d77rnn1sIEXg+IcXAjzO3HP/5xaTuTUp6R97znPdXiiy/e9RZ4eMGZiTv88bw677zzqvPPP7+UP+GEE8ozAJ8wQpfwdoARRrJwBLNll122hP7gqfL1r3+9iFNxTb9b7oHIA0M+Azxn2Pe///3iFUQfL7roouo1r3lNYRD3meg441EGkzD6R04snkuEmEsuuaQ8m4gBCH1f/vKXo2jPLZ+tD3zgA7WQdcopp3Q8s/QNTycMMSV7sSCAIKKEcV9Eohx6hPgRQl7O3zVZz0qvzyptYpy22GKLaF4ZJ7z28AbjewBefFfxPE3U4IYhcuEF+IY3vKGITt/4xjdqDzzEWbwM+WyEwYw+hOG9xTM/77zzVr/61a+K2Mn3DeP7ta99rXwfRlnCOBEhw/B8i+8bhGY+R1x73XXXlc99eCz2e13cx60EJCABCUhAAhKQgASGmYACUJfRxYsjixm5CMc5v/POO+fD494nfwavLGIweUJUyIZny8c//vH6EN4X/GIe9vrXv778Or/WWmuVfC1408Sv6lEmb7kHk7I8UYvzq6yyShGPmFgxsc3hZN/97nejWNky+cNjJRv3xhBeIicR1yEaYExYP/3pT5d9/iGXByIGk30mi0wE6W+vEChEM0JxmsZkMnv30P+ll166LoZo9Na3vrVDsKhPjnEnwvVg0uTHpJsQpQgXQkzoJQDBHdGB3E1hTKgRHOIeP/zhD4tAFucRiJjoYtyf68nJgzH+a665ZhFKENMmy774xS9Wb37zm+vqEO3e/va3F2GNg3gJEWZEfiVsIuPMmGfxh1BEhMww+PDM83wifOBJxpiTe6mX4RVDyF88e2eddVZ5BnJ5nr0wRIUsABGqF+JOlOG+sA5DYAnjmQ+LcZyMZ6X5rMU9EESifQgjhCbGd8lSSy1VvhMQeRGPJ8MQHRG+43PNPeC74447FkEQzgg2CK1hCIUYYuIRRxxRQu7iHDmAeHb5XGI834jDYfn7Zq+99qroSxhjwGcOrzcY8F0UAlC/10XdbiUgAQlIQAISkIAEJDDMBP7lQjHMvRxn3/j1vM1GO9927XjPITjFRA8vgzxRjrpI4MyEPYxQnF7Gr/DdxB/K50ksIkYYE3S8dLDwRGIiTjLnMJIZRzsRXMIQCUiWzCuLP3EesSdCcphEUq6b0eZu4g9lEY/CuEcWf+I47LKQFsfHuiUfE21DKOjGLzxlqA+vrF6G90oWf6LcRz7ykdgtQl79ZubOz372s/ot4xziT31w5g79XnLJJfOhvvcR2rL4ExUxWc/CzC233BKnihjU7zjDNJ4dnsGtt966rjd2SLB8+OGHV8stt1x54d3TyxBv1llnnVr8wSMnhIZ8zfOe97zizcIxPJyyIcJhjHUIQ/EZiHJ4foUhiIRN1rPS9lmNcEpEJriE+BNtwDONXFWTZTx3If7kOvfbb7/684CnHQmpw/D845nAu4t8S03DgxFxD8vhdrzPIXndkskjSPHcUH/kTZvIdVyrSUACEpCABCQgAQlIYNgJKAB1GeHR8maMdr5LlX0fykIMQkmv1Z7whsALBUMQCc+H5o1zrp/muSycZA8oQkqiPrx4mHRiOSwse0N0m2w37xXvEZeyERLVzSL8o9u5LESEmNStXLdJaLdy/RzL49ItD1PU2csziNWUwvLkl2M///nPyyk8KfCa6GYIaXjITIblcKZmfXkcSK48Vmsb5/zsILY0xYy4B+IPoV+8sidOnGeL+IO3CM8rvAgtanvmoz94DJFnKSy82WAaZb75zW8WD7UoE6GShPzFCnVxrm071melV7vvu+++WjCDSeQeat6T74NuQl6z3GjvCf1ixb5uhiiEd1gYq5GN1QhtZLU4LL5f4lpCxcLwAELMGkvd/V4X93IrAQlIQAISkIAEJCCBYSZgCFiX0SU0q03k4fxUWRYD+NW7zQgfwzMHw6OCCXDTyL/Ry8g7xGSXyW8Wd+LXeX6tR/xhUkwYEh4R5C3CQjDifLfQHCbYeFXguQDbv/zlLxX5OpoTv15tIxdML8PDICznzoljsSXkbCJGnhtY4PmBKMNE/MEHH6wn42Opu9dEOi8hnhPwxjLW1D2ah0837mNpU7MMSc97WWaYuUf5fsY5P+MT7UP2kMObKAsC0ca8Rawk9xSG2Ir4BfMQdwh7i2eKZxXRC0GEZzg+a5Rp2mQ8K70+q9n7iVCoNltsscXq8MG2cm3nyPfUZnnMyEWWPeR4lvHU4XOPZxx5v7KA1atennW8ByMPE8nReVE3ghPjxPg2hbd+r+vVDo9LQAISkIAEJCABCUhgmAgoAHUZTfLpkMy3l3F+quz++++vb9UmglAoC1MIE/0Y4VsIQEzkuDdhMrHUenjXMOFFAOL4Y489Vs0555xFDOJ+K6+8coeXEiEhhI+wetasMsJAMDweZp999p63mWeeeXqeG+0E4W5bbbVV4TJa2bbzvbxbel3DhDks8u3E++aWkJqJGgJeTkDerG/uuecuwiJiSA4BnMg4j+cZb7an7T25YRAy2zzSEHMQSukPQgXCQg7hQ/R81rOeVRJvI24hAHJN9sx7y1ve0tGMyXpWOipNb7I4nT/zqUi9O9ozUxds2cnead2KzT///PXh7KXDyl6svkdy6PEaHm1HH310ddxxx1Xkb4oQQRJvs9IfL55VwuRI9B3W73VxvVsJSEACEpCABCQgAQkMMwEFoC6jS4JnwlLCqyUXYXWriSaAzvWNtp/zvcyYMaNOutvturvuuqs+3CsspC7QYydPlkkgiwdFLMsdoR6EnYQxEcZDIrwhci4cypx22mkd4g+JY/FaIA8OYgL5ixCTInFu1DueLZ5RTBBpQwhS3a6PSWS3c23HqJOQo/BW4n6RABnO9AEPnl5hSW11j3Yuizok526zPPluK9d2DkaEsHXL98J1DzzwQM2BRL5hExnn7OlCLqnsQRL1j2dLCBjPFNZtdapcF4IBoiUJiyPvT3j/cBzxB2MfAQhxlDrju4EV3bIIMxXPSuaDINJmo51vuzbOjVZHfu6yh9v2229feFEPIhtLyeNdxncanxk+/4SUxndH3C+2ePeQ94ucUIhyeN7hSRT5j3hWyX1FGBkJocP6vS6udysBCUhAAhKQgAQkIIFhJaAA1GNkWfGG1b5I+Mwv7kzy8PyZSvGHpuVlp8lvklcuajY9hBqO8+t4P8YEDU8aJmV4RBDKgjGBI5wEY/KGCMREjOS5hHOFZXGIY+RNCfvSl75UNb0lOBfLt0e58W7xyIhJISJJr7AY+PVjiFwh/pCXBXGh6cmDMDIrDO8q+oNHFrmOCKnJOWTyPVkZazIMjyqYdrM77rijPpzzGU1knPMzTnhTFiHrm41xJ1b7evzxx6sLLrigjNvmm29eXXjhhT1FLURLBCByZzGO11xzTblb5P7hDWXwRuEzgXddJI1GGMo2Fc9KDrkabcxzfqzczvHs33zzza3Fc0hatA0RMfIocTG88CZsGuJfLwEoyiLS8b3HC0EIoRuvwhD5WKY+C0ATvS6udysBCUhAAhKQgAQkIIFhI2AS6JYRRexh4sKEmO1Uiz80DY+jMFYXaibTjXPkpAkPFxIF9/LgiPJt20gmTLhLeEOsvvrqHaJHJAomDCy8IbhvnuSR0JkJM4anRDfxh3OE6kzEQpgara5LL720r9tEH7j4Yx/7WAeHqDAEqHg/mdvI/YMI1es+eJ5cccUVk3JbnrNelu8RuWEmOs5ZNERwjcTAzTbQdyb6eJL0embCA2XfffetRSw8d/AUybmVct05UTIr6IWnVRaicvJtxKLwigmvuKhvKp4VPmOR8J1lz3MOpWgHW9rY63nJ5UbbR3zMIk8uj2AWAi4icYSLReJyyrK8e/5eiOtpd17BL46zJT8YoYEhvOZzjDHjGwwYryjX73W5fvclIAEJSEACEpCABCQwrAQUgKb5yBKCFROd6667rjrmmGNGtJikqrE8OydZAnsiFpNaJmeRvyMv7U7dUYbJNRNiLHIElTcz/yF8JtqO10RM0uI82xNOOKGecOfj49kPgYRrjjrqqI4E1lHP17/+9ZI3JN6PZ5vzqPzhD38YcSkhMLMyx9Eb3/jG+p4sZZ/zAsUJJsRM1CfDGJPI+5TrY6KPt0UYScexiY4z44dAiOHFdsABB5T9/A8rdLEEPYIGIstoCdHJY0QeL0QJjOcYr5FuRm6t8BrD6w+jPXncyS2FCIpFGfbzynm8z9fMymclRCs+U4RaNYVhPPcIVZssI1SrmVeMvE/k4AnhGSEvvNNyWFzOWRTtoX177713vB2xRWiFLc8Y33tNw8MLsQdjrGKc+72uWb/vJSABCUhAAhKQgAQkMIwEDAGb5qNK+AP5Vcidw2QPgYOJPomYCZ0hTw+eLTEJI0yNHCgTsex1FKJNTDijXibghJlx3yiTPSaiHJ5CJGylHO1ae+21S14hvBOuvvrqWmCK8v1sCVvbfffda+Fgww03LPeizXh9sFoZIUD9Wu77fvvtVzwr4I/wgacDokjw7/cebdfBDI8XRBlY8/5973tfmSAjBiHMhKdWWz3jOUfYFMl1WWkJwxvs/PPPr6vYf//9a3GPgxMZZ0QDGEaepTPOOKOE+ay00kpFUCH/S37GWSq+baWyaCQiBKJPrFR30EEHlTDGEC+jHFvESz5X8Sxzj6YREoaQFGUQRZsJs6fqWdljjz2KMEL4FKLYuuuuWwQq8jIRsoXgiTg7WcbnleeO7xcEOxJds0JXeDwhwCBChpGniBfX8dwiIK222mplOXnC0niWcshqXBdbviv4bsMQPXfYYYcKIZRE7oRyMpYxDnwWwvq9Lq53KwEJSEACEpCABCQggWEmoAA0AKO76KKLVieffHIt7CAGdAuBYfKJJ0ozP814u0hy1sjxw7XkvWkmlWbSjkfEmWeeWapnAhgeIfl+G2+8cZkAMlHFo6gZ8oGIlOvJ145nf9NNNy1LdIfQQ36QyBES9ey5557VEUccUU8c4/hoW7yY8KbAMwajz9HvuJYVwsgRMysMEfDwww8vog/hLrCMtuT7IcogDEzE6CuTaDgxSc+iT9SLoEKZbBMdZxKJwxQhA0O049U0VuX67Gc/2zzc8z2fCcYd4Q5jnBBxciJljiMK5fHrJhI1Bc6cI4g6sKl6VkikjGgWXkmIKU1BhbZssMEG1ZFHHvl/jevzX8Qbcjzx7CFAd7PTTz+9ygnLKcOzyLUYImWEipUDM//hO4aEzYiLTaNfhCLyDCD08Gx3M4RHQszC+r0urncrAQlIQAISkIAEJCCBYSZgCNhTPLpM7sPyfhyLLQlQETTCIyOOs0V8QaAg5GWOOebIp8p+W70jCv/zQA75inw/zbJ4wYRRptt98NQgRKxbHaykxepf2Zsji1e99uOeeYsgxSSfCX6Eg8R5Jvuw2WSTTeLQuEUyQl0OPPDAOlQpKkLAImRpxx13jEMj6u7GpS78z50IneEtk+KmIcohkGRvhyjDRBqPD4S6sMwujrVto408P9tss02Z6DcTicMVT4xuoTsTGedoF3l2eB7ysxfnCPPhGcebjBXksmVe0Y98HnEquCEmdAuNyjl+uBahqWmEiuXk2L1yWs3qZyXaRQ6m8847r2tb11tvvYp8RpnVeJ+JuA/iL+Py0Y9+NA7VW3jgsdWNFwmyScSdQzTjQsbgxBNPHPFZjfN4ViFw8ZmO8MA4x5aQvX322ad4eGVxut/rct3uS0ACEpCABCQgAQlIYFgJPGNmiMyTw9q5Ye0XuS/wAiEPBiERTEy7TXynW//JU8IKPk888URJFjuRRNVtfSOJ8IwZM6qHH364TIDzKlNt1431HIlvyfsDe7ws+p1Yj/V+zXKssBRLb88///xlCfpmmcl6T4gZq7whQHGvLLb0usdkjDNjRw4d8syQV2dWPSu9+jBZx6fqWSFH0p/+9KfyLJIkuZsQPJ4+kfSZkC0MQStEMz67fIZ5BnkemiJhr3uQKJxwMJ4fxpOcSuMxkpxzPUIpgu5Y+9fvdeNpm2UlIAEJSEACEpCABCQwKAQUgAZlpGynBCQggSki0EsAmqLbexsJSEACEpCABCQgAQlIYBYQMARsFkC1SglIQAISkIAEJCABCUhAAhKQgAQkMJ0IKABNp9GwLRKQgAQkIAEJSEACEpCABCQgAQlIYBYQGJltdhbcxColIAEJSGBwCJCjJ/L7NJOqD04vbKkEJCABCUhAAhKQgAQkkAmYAyjTcF8CEpCABCQgAQlIQAISkIAEJCABCQwhAUPAhnBQ7ZIEJCABCUhAAhKQgAQkIAEJSEACEsgEFIAyDfclIAEJSEACEpCABCQgAQlIQAISkMAQElAAGsJBtUsSkIAEJCABCUhAAhKQgAQkIAEJSCATUADKNNyXgAQkIAEJSEACEpCABCQgAQlIQAJDSEABaAgH1S5JQAISkIAEJCABCUhAAhKQgAQkIIFMQAEo03BfAhKQgAQkIAEJSEACEpCABCQgAQkMIQEFoCEcVLskAQlIQAISkIAEJCABCUhAAhKQgAQyAQWgTMN9CUhAAhKQgAQkIAEJSEACEpCABCQwhAQUgIZwUO2SBCQgAQlIQAISkIAEJCABCUhAAhLIBBSAMg33JSABCUhAAhKQgAQkIAEJSEACEpDAEBJQABrCQbVLEpCABCQgAQlIQAISkIAEJCABCUggE1AAyjTcl4AEJCABCUhAAhKQgAQkIAEJSEACQ0hAAWgIB9UuSUACEpCABCQgAQlIQAISkIAEJCCBTEABKNNwXwISkIAEJCABCUhAAhKQgAQkIAEJDCEBBaAhHFS7JAEJSEACEpCABCQgAQlIQAISkIAEMgEFoEzDfQlIQAISkIAEJCABCUhAAhKQgAQkMIQEFICGcFDtkgQkIAEJSEACEpCABCQgAQlIQAISyAQUgDIN9yUgAQlIQAISkIAEJCABCUhAAhKQwBASUAAawkG1SxKQgAQkIAEJSEACEpCABCQgAQlIIBNQAMo03JeABCQgAQlIQAISkIAEJCABCUhAAkNIQAFoCAfVLklAAhKQgAQkIAEJSEACEpCABCQggUxAASjTcF8CEpCABCQgAQlIQAISkIAEJCABCQwhAQWgIRxUuyQBCUhAAhKQgAQkIAEJSEACEpCABDIBBaBMw30JSEACEpCABCQgAQlIQAISkIAEJDCEBBSAhnBQ7ZIEJCABCUhAAhKQgAQkIAEJSEACrk7JyQAAAQpJREFUEsgEFIAyDfclIAEJSEACEpCABCQgAQlIQAISkMAQElAAGsJBtUsSkIAEJCABCUhAAhKQgAQkIAEJSCATUADKNNyXgAQkIAEJSEACEpCABCQgAQlIQAJDSEABaAgH1S5JQAISkIAEJCABCUhAAhKQgAQkIIFMQAEo03BfAhKQgAQkIAEJSEACEpCABCQgAQkMIQEFoCEcVLskAQlIQAISkIAEJCABCUhAAhKQgAQyAQWgTMN9CUhAAhKQgAQkIAEJSEACEpCABCQwhAQUgIZwUO2SBCQgAQlIQAISkIAEJCABCUhAAhLIBBSAMg33JSABCUhAAhKQgAQkIAEJSEACEpDAEBL4//2gmFum6VI4AAAAAElFTkSuQmCC)"
      ],
      "metadata": {
        "id": "UMipGnsK-CWz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Theoretical max flops per second provided by the GPU manufacturer\n",
        "\n",
        "flops_per_second = {\n",
        "    # https://www.techpowerup.com/gpu-specs/h100-pcie-80-gb.c3899\n",
        "    \"H100\": {\n",
        "        torch.float32: 51.22e12,  # 51.22 TFLOPs for FP32 on NVIDIA H100\n",
        "        torch.float16: 204.9e12,  # 204.9 TFLOPs for FP16 on NVIDIA H100\n",
        "        torch.bfloat16: 204.9e12\n",
        "    },\n",
        "    # https://www.techpowerup.com/gpu-specs/l4.c4091\n",
        "    \"L4\": {\n",
        "        torch.float32: 30.29e12,  # 30.29 TFLOPs for FP32 on NVIDIA L4\n",
        "        torch.float16: 30.29e12,  # 30.29 TFLOPs for FP16 on NVIDIA L4\n",
        "        torch.bfloat16: 30.29e12\n",
        "    },\n",
        "    # https://www.techpowerup.com/gpu-specs/tesla-t4.c3316\n",
        "    \"T4\": {\n",
        "        torch.float32: 8.1e12,  # 8.1 TFLOPs for FP32 on NVIDIA T4\n",
        "        torch.float16: 65.13e12,  # 65.13 TFLOPs for FP16 on NVIDIA T4\n",
        "        torch.bfloat16: 65.13e12\n",
        "    },\n",
        "    # https://www.techpowerup.com/gpu-specs/a10g.c3798\n",
        "    \"A10G\": {\n",
        "        torch.float32: 31.52e12,  # 31.52 TFLOPs for FP32 on NVIDIA A10G\n",
        "        torch.float16: 31.52e12,  # 31.52 TFLOPs for FP16 on NVIDIA A10G\n",
        "        torch.bfloat16: 31.52e12\n",
        "    },\n",
        "    # https://www.techpowerup.com/gpu-specs/a100-pcie-40-gb.c3623\n",
        "    \"A100\": {\n",
        "        torch.float32: 19.49e12,  # 19.49 TFLOPs for FP32 on NVIDIA A100\n",
        "        torch.float16: 77.97e12,  # 77.97 TFLOPs for FP16 on NVIDIA A100\n",
        "        torch.bfloat16: 77.97e12\n",
        "    },\n",
        "    # https://www.techpowerup.com/gpu-specs/geforce-rtx-3080.c3621\n",
        "    \"RTX_3080\": {\n",
        "        torch.float32: 29.77e12,  # 29.77 TFLOPs for FP32 on NVIDIA RTX 3080\n",
        "        torch.float16: 29.77e12,  # 29.77 TFLOPs for FP16 on NVIDIA RTX 3080\n",
        "        torch.bfloat16: 29.77e12\n",
        "    },\n",
        "    # https://www.techpowerup.com/gpu-specs/geforce-rtx-3090.c3622\n",
        "    \"RTX_3090\": {\n",
        "        torch.float32: 35.58e12,  # 35.58 TFLOPs for FP32 on NVIDIA RTX 3090\n",
        "        torch.float16: 35.58e12,  # 35.58 TFLOPs for FP16 on NVIDIA RTX 3090\n",
        "        torch.bfloat16: 35.58e12\n",
        "    }\n",
        "}"
      ],
      "metadata": {
        "id": "AEF4Aakg-JQc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import time\n",
        "\n",
        "def get_gpu_model(flops_per_second_dict):\n",
        "    device_name = torch.cuda.get_device_name(0)\n",
        "    for model in flops_per_second_dict.keys():\n",
        "        if model in device_name:\n",
        "            return model\n",
        "    return \"Unknown\"  # Default if no matching model is found\n",
        "\n",
        "\n",
        "gpu_model = get_gpu_model(flops_per_second)\n",
        "print(\"GPU Model:\", gpu_model)\n",
        "\n",
        "if gpu_model != \"Unknown\":\n",
        "\n",
        "    for size in model_configs:\n",
        "        print(f\"\\nProcessing {size}\")\n",
        "        config = BASE_CONFIG.copy()\n",
        "        config.update(model_configs[size])\n",
        "\n",
        "        min_batch_size = 1\n",
        "        max_batch_size = None\n",
        "        max_possible_batch_size = 4096\n",
        "\n",
        "        while min_batch_size <= max_possible_batch_size:\n",
        "            batch_size = (min_batch_size + max_possible_batch_size) // 2\n",
        "            try:\n",
        "                input_tensor = torch.randint(\n",
        "                    0, config[\"vocab_size\"],\n",
        "                    (batch_size, config[\"context_length\"]),\n",
        "                    device=device\n",
        "                )\n",
        "\n",
        "                model = GPTModel(config).bfloat16().to(device)\n",
        "                model.train()\n",
        "\n",
        "                # Start timing\n",
        "                torch.cuda.synchronize()\n",
        "                start_time = time.time()\n",
        "\n",
        "                # Forward & backward pass\n",
        "                output = model(input_tensor)\n",
        "                loss = output.sum()  # Compute a dummy loss\n",
        "                loss.backward()\n",
        "\n",
        "                # End timing\n",
        "                torch.cuda.synchronize()\n",
        "                end_time = time.time()\n",
        "\n",
        "                total_time_seconds = end_time - start_time\n",
        "\n",
        "                # Calculate FLOPs for forward pass\n",
        "                macs, params = profile(model, inputs=(input_tensor,), verbose=False)\n",
        "                flops_forward = 2 * macs  # Assuming one MAC equals two FLOPs\n",
        "\n",
        "                # Estimate FLOPs for backward pass (typically 2x forward FLOPs)\n",
        "                flops_backward = 2 * flops_forward\n",
        "\n",
        "                # Total FLOPs for forward + backward passes\n",
        "                total_flops = flops_forward + flops_backward  # Or total_flops = flops_forward * 3\n",
        "\n",
        "                data_type = next(model.parameters()).dtype\n",
        "                max_flops_per_second = flops_per_second[gpu_model].get(data_type, 0)\n",
        "\n",
        "                # Compute tokens per second\n",
        "                tokens_processed = batch_size * config[\"context_length\"]\n",
        "                tokens_per_second = tokens_processed / total_time_seconds\n",
        "\n",
        "                # Compute FLOPs per token\n",
        "                flops_per_token = total_flops / tokens_processed\n",
        "\n",
        "                # Compute theoretical max tokens per second\n",
        "                if flops_per_token > 0:\n",
        "                    theoretical_max_tokens_per_second = max_flops_per_second / flops_per_token\n",
        "                else:\n",
        "                    theoretical_max_tokens_per_second = 0  # Avoid division by zero\n",
        "\n",
        "                # Compute MFU\n",
        "                if theoretical_max_tokens_per_second > 0:\n",
        "                    mfu = tokens_per_second / theoretical_max_tokens_per_second\n",
        "                else:\n",
        "                    mfu = 0  # Avoid division by zero\n",
        "\n",
        "                print(f\"  Batch size {batch_size}: Tokens/sec: {tokens_per_second:.2f}, MFU: {mfu:.4f}\")\n",
        "\n",
        "                # If successful, try a larger batch size\n",
        "                min_batch_size = batch_size + 1\n",
        "                max_batch_size = batch_size\n",
        "\n",
        "                # Clean up\n",
        "                del model, input_tensor, output, loss\n",
        "                torch.cuda.empty_cache()\n",
        "\n",
        "            except RuntimeError as e:\n",
        "                if \"out of memory\" in str(e).lower():\n",
        "                    # Try smaller batch size\n",
        "                    max_possible_batch_size = batch_size - 1\n",
        "\n",
        "                    # Clean up\n",
        "                    try:\n",
        "                        del model, input_tensor\n",
        "                        torch.cuda.empty_cache()\n",
        "                    except NameError:\n",
        "                        pass\n",
        "                else:\n",
        "                    raise e\n",
        "\n",
        "else:\n",
        "    print(\"Unknown GPU model. Please update the flops_per_second dictionary with your GPU information.\")"
      ],
      "metadata": {
        "id": "2M_PZESv-SpM"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}